---
title: "Épidémiologie 2 - Labo informatique R (PTM-6675)"
author: Simon Dufour (Professeur à la Faculté de Médecine vétérinaire de l'Université
  de Montréal)
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography:
- book.bib
- packages.bib
biblio-style: apalike
link-citations: yes
description: Chapitre 10
---


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```


# Régression logistique  
  
## Généralités  
  
Il existe aussi plusieurs procédures dans `R` permettant d’effectuer une régression logistique. Nous travaillerons principalement avec la fonction `glm` qui comblera la plupart de vos besoins de ce côté. Notez que nous utiliserons cette même fonction pour d'autres types de modèle que nous verrons plus tard (e.g., Poisson, binomiale négative). Puisque la fonction `glm` peut être utilisée pour plusieurs type de régression, il faudra donc indiquer la famille de régression qui nous intéresse, dans ce cas-ci l'argument `family=binomial` indiquera que notre variable dépendante est binomiale (i.e., elle prend seulement 2 valeurs). Dans ce cas, la fonction de lien par défaut sera la fonction logit. On aura donc une régression logistique. Notez que, à part l'ajout de `family-binomial` la syntaxe est identique à celle de la fonction `lm`.  
    
Le jeu de donnée *Nocardia* sera utilisé pour cette section.  

```{r}
#J'importe ce jeu de données
nocardia <-read.csv(file="nocardia.csv", header=TRUE, sep=";")
head(nocardia)
#J'indique les variables catégoriques dans mon jeu de données
nocardia$dbarn <- factor(nocardia$dbarn) 
nocardia$dneo <- factor(nocardia$dneo) 
nocardia$dclox <- factor(nocardia$dclox) 

#Je fais une régression logistique

modele_1 <- glm(data = nocardia, casecont ~ dcpct + dbarn, family = binomial)
summary(modele_1)
```
  
Plusieurs éléments sont présentés. D'abord, des résultats sur les résiduels de déviance (on y reviendra). Puis les coefficients, erreur-types et les résultats des tests de Wald qui permettent de tester chacun des coefficients, un à la fois (l'hypothèse nulle est que β=0). Notez que le résultat Residual deviance (135.49 avec 104 degrés de liberté) correspond au -2 log likelihood.  
  
## Effectuer un test de rapport de vraisemblance
Pour comparer le modèle complet avec le modèle nul (i.e., avec juste l'intercept) il faudra faire un rapport de vraisemblance (likelihood ratio test). La fonction `lrtest` du package `lmtest` permet de réaliser ce genre de test.

```{r, message=FALSE, warning=FALSE}
library(lmtest)
lrtest(modele_1)#teste le rapport de vraisemblance du modèle
```
  
Ici, la conclusion serait que au moins un des coefficients (*dcpct* ou *dbarn*) est différent de 0 (*P*=0.003).  
  
Pour comparer un modèle complet *vs.* un modèle réduit ont utilisera la même fonction du même package, mais après avoir créé les deux modèles.

```{r}
mod_red<-glm(data=nocardia, casecont~ dcpct + dbarn, family="binomial" )
mod_comp<-glm(data=nocardia, casecont~ dcpct + dneo + dclox + dbarn, family="binomial" )

lrtest(mod_comp, mod_red)#likelihood ratio test
```
  
  La conclusion serait que au moins un des deux coefficients (*dneo* et/ou *dclox*) est différent de 0 (*P*<0.001). **C'est aussi à l'aide de la fonction `lrtest` qu'on pourra réaliser un test sur l'ensemble des variables indicateurs d'une variables avec > 2 catégories, l'équivalent du test de *F* en régression linéaire.** 
  
## Ajouter des IC95  
Vous pouvez ajouter des IC95 avec la fonction `confint`:
```{r, message=FALSE, warning=FALSE}
confint(modele_1, level= 0.95)
```
  
## Choisir valeur de référence pour les variables catégoriques  
Vous pouvez choisir les valeurs de référence pour les variables catégoriques avec la fonction `relevel`:
```{r}
nocardia<-within(nocardia, dbarn<-relevel(dbarn, ref=1)) #Dans ce cas, ça ne changera rien puisque R avait déjà prit la valeur 1 comme catégorie de référence
```
  
## Produire des tables de résultats
Le package `jtools` vous permet de présenter des tables de résultats plus jolies:
```{r}
library(jtools)
j <- summ(modele_1, confint = TRUE)
j$coeftable
```
  
  Ou encore, si vous utilisez `RMarkdown`:
  
```{r}
library(knitr)
library(kableExtra)
kable(round(j$coeftable, digits=3), caption="**Table 7.1.** Résultats du modèle.")%>%
  kable_styling()
```
  
### Présenter les rapport de cotes plutôt que les log odds
Si vous désirez obtenir les rapports de cotes, alors vous pouvez simplement demander l'exposant de vos résultats comme ceci:
```{r}
#Je demande de présenter les coefficients du modèle mis à l'exposant
exp(coef(modele_1))

```
   
Pour obtenir rapports de cotes et IC95 des rapports de cotes:
```{r, message=FALSE, warning=FALSE}
#Ici j'ai demandé de créer une colonne représentant un vecteur de nombres (que j'ai nommé OR et qui seront les OR) et d'y juxtaposer (fonction cbind) les IC95 du modèle. Il ne reste plus qu'à exponentier les valeurs contenues dans ces 3 colonnes pour avoir des OR et leurs IC95
exp(cbind(OR = coef(modele_1), confint(modele_1)))
```
  
  On pourrait même arrondir pour faire plus joli et sortir ça en utilisant `RMarkdown`.  
```{r, message=FALSE, warning=FALSE}
kable(round(exp(cbind(OR = coef(modele_1), confint(modele_1))), digits=2), caption="**Table 7.2.** Résultats du modèle.")%>%
  kable_styling()
```
  
  Dans ce cas, on voit qu'une augmentation de 1 unité de *dcpct* (le % de vaches traitées au tarissement) augmente les odds de mammite à nocardia par un facteur de 1.02 (IC95: 1.01, 1.03).  
  
## Spécifier pour quelle augmentation d’un prédicteur continu le rapport de cotes est calculé      
  Si vous voulez produire le rapport de cotes pour une augmentation de 10 ou 20 unités de *dcpct* vous pourriez mettre à l'échelle la variable *dcpct* afin que celle-ci représente une augmentation de 10 ou 20 unités et utiliser ces nouvelles variables dans le modèle. Par exemple, pour une augmentation de 10 points de pourcentage:
```{r, message=FALSE, warning=FALSE}
nocardia$dcpct10 <- nocardia$dcpct/10

modele_10 <- glm(data = nocardia, casecont ~ dcpct10 + dbarn, family = binomial)

round(exp(cbind(OR = coef(modele_10), confint(modele_10))), digits=2)
```
  
  Donc une augmentation de 10 unités multiplie les odds de nocardia par 1.21 (IC95: 1.08, 1.37).  
    
Vous auriez aussi pu simplement multiplier le coefficient et ses erreur-types par 10 et ensuite les mettre à l'exposant:

```{r}
#Créons un objet avec les résultats du modèle
library(jtools)
res <- summ(modele_1)

#Dans l'objet res$coeftable la première colonne est pour les coefficents et la 2ième est pour les erreur-types. Et la 2ième rangée est pour dcpct. Le coefficient de dcpct est donc en rangée 2 et colone 1 ou res$coeftable[2,1]
OR <- exp(10*res$coeftable[2,1])

#Et les erreur-types sont en res$coeftable[2,2]
L95 <- exp(10*res$coeftable[2,1]-1.96*10*res$coeftable[2,2])
U95 <- exp(10*res$coeftable[2,1]+1.96*10*res$coeftable[2,2])

#De là:
round(cbind(OR10=OR, LowerCI=L95, UpperCI=U95), digits=2)
```
  
Comme vous le voyez, il y a plusieurs manières d'arriver au même résultat!  
  

## Évaluer une interaction entre 2 variables
Comme pour la fonction `lm` vous n’avez qu’à indiquer dans votre modèle la multiplication des effets (`dneo`*`dclox`). La fonction `glm` se chargera alors de créer toutes les variables indicateurs nécessaires.
```{r}
modele_inter <- glm(data = nocardia, casecont ~ dcpct + dneo*dclox, family = binomial)
library(jtools)
inter <- summ(modele_inter, confint = TRUE)
inter$coeftable

```
  
## Comparer rapports de cotes pour une combinaison spécifique de prédicteurs
La fonction `pairs` du package `emmeans` vous permet de comparer toutes les combinaisons possibles d'un ou plusieurs prédicteurs catégoriques et/ou quantitatifs.   
```{r}
library(emmeans)
contrast <- emmeans(modele_inter, c("dneo", "dclox")) 
pairs(contrast)  
```
  
  Rappellez-vous, si vous utilisez la fonction `confint`sur votre fonction `pairs`, vous aurez alors aussi les IC95.  
```{r}
library(emmeans)
contrast <- emmeans(modele_inter, c("dneo", "dclox")) 
confint(pairs(contrast))  
```  
   
J'ai maintenant tous les contrastes pour les différentes combinaisons de *dneo* et *dclox*. Par exemple, la première ligne compare ceux qui n'utilisait aucun des deux produits (0 et 0) *vs.* ceux qui utilisait *dneo* mais pas *dclox* (1 et 0). 
    
  De là, si on voulait avoir les rapport de cote pour les différentes comparaisons plutôt que les log odds, j'utiliserai l'argument `type="response"`.
```{r}
confint(pairs(contrast, type="response"))

```
  
Dans ce cas, les odds de nocardia étaient 15.5 (95CI: 2.1, 112.7) fois plus grande pour les troupeaux utilisants seulement neomycine (1 et 0) *vs.* ceux utilisant seulement la cloxacilline (0 et 1).    
  
## Présenter l’effet des prédicteurs sur une échelle de probabilité  
Présenter vos résultats sur une échelle de probabilité (plutôt que odds ou log odds) permettra de mieux illustrer l’effet de vos différents prédicteurs. La fonction `plot_model()` du  package `sjPlot`vous permet d’obtenir une telle représentation graphique de vos résultats. L'option `type="eff"` permet de rapporter les résultats sur l'échelle d'une probabilité (plutôt que odds, log odds ou OR).
```{r, message=FALSE, warning=FALSE, fig.cap="**Figure 7.1.** Effet de différentes variables sur la probabilité de nocardia."}
library(sjPlot)
plot_model(modele_inter, type="eff")
```
  
 Ont voit alors les graphiques pour chacune des variables du modèle. Par contre, souvent on voudra voir tout ensemble dans un seul graphique. On peut alors ajouter l'argument `terms=c("var1", "var2", "var3")`. La première variable apparaitra en x, la deuxième en y et la troisième séparera la figure en 2 figures. 
```{r fig.cap="**Figure 7.2.** Effet de l'utilisation de la neomycine et du % de vache traitées au tarissement par niveau d'utilisation de la cloxacilline."}
library(sjPlot)
plot_model(modele_inter, type="eff", terms=c("dcpct", "dneo", "dclox"))
```
  
## Linéarité de la relation (pour prédicteur quantitatif)  
La linéarité de la relation est une supposition importante du modèle. Dans le modèle logistique, la relation entre le prédicteur et le **log odds** doit être une ligne droite, ce qui complique l’évaluation. Pour les prédicteurs quantitatifs, vous devrez toujours vérifier si cette supposition est bien respectée. Vous pouvez le faire simplement à l’aide du modèle polynomial (en ajoutant le $prédicteur^2$  ou le $prédicteur^2$ et le $prédicteur^3$ dans votre modèle). Si les coefficients de ces termes sont significativement différents de zéro (i.e. *P* < 0.05), ont concluera que la relation est une courbe, ou une courbe avec un ou plusieurs points d’inflexion, respectivement.  
  
## Test de 'fit' de Hosmer-Lemeshow et de Pearson 
La fonction `hoslem.test` du package `ResourceSelection` permet de réaliser le test de Hosmer-Lemeshow. Il faut simplement indiquer l'objet "modèle" avec lequel vous voulez travailler (par exemple, ici *modele_inter*). Dans cet objet, il y a toujours une variable nommée $y$ et `hoslem.test` voudra l'utiliser, vous n'avez donc pas à modifier *y* dans le code. Il s'agit en fait de la variable réponse. Ont indique ensuite d'utiliser les valeurs prédites (*fitted*) et, encore une fois, l'objet "modèle" où elles se trouvent. Finalement on peut ou non indiquer le nombre de groupes utilisés pour le test, ici `g=8`.
```{r, message=FALSE, warning=FALSE}
library(ResourceSelection)
hoslem.test(modele_inter$y, fitted(modele_inter),g=8)
```
Dans ce cas, le test ne rejette pas l’hypothèse nulle (i.e. le modèle « fit » bien les données).  
  
C'est beaucoup plus demandant de réaliser les tests de fit de Déviance ou de Pearson dans R. Si vous trouvez une manière simple de le faire, indiquez-le moi! En théorie, ont peut générer les résiduels avec la fonction `augment()` du package `broom`. Puis, la fonction `distinct()` (du package `dplyr`) pourrait être utilisée pour ne conserver que les profils uniques de prédicteurs pour un jeu de données. La fonction `dim()` permettra de rapporter le nombre de lignes dans ce jeu de données réduit (i.e., le nombre de profils). Ensuite, ont pourrait faire la somme des résiduels de Pearson de chacun de ces profils après les avoir mis au carré avec la fonction `sum` et `^2`. La fonction `length()` permettra de calculer le nombre de coefficients dans le modèle. Puis, finalement, on cherche la probabilité d'observer cette valeur dans une table de *chi-carré* avec le nombre de degrés de liberté approprié (i.e., le nombre de profils unique - le nombre de coefficients) en utilisant la fonction `pchisqr()`.  Ouf! 


```{r, message=FALSE, warning=FALSE}
library(broom)
diag <- augment(modele_inter, type.residuals = "pearson") #Je viens de créer une nouvelle table avec les résiduels, etc. 

library(dplyr)
#La fonction "distinct" me permet de ne conserver qu'une seule fois (i.e., une seule ligne) les valeurs prédites qui se répètent.   
profils <- distinct(diag, dcpct, dneo, dclox, .keep_all = TRUE)

#Dans ce cas, on voit avec la fonction "dim" qu'il y a 30 profils uniques.
n_prof <- dim(profils)
n_prof[1]

#Je calcule la somme de ces résiduels au carré. Dans ce cas, j'obtiens 37.75
s <- sum(profils$.resid^2)
s

#Je calcule le nombre de coefficients avec la fonction length. Je dois enlever 1 pour l'intercept.
nb <- length(modele_inter$coefficients)-1
nb

#Finalement, je vérifie à quelle probabilité la valeur 37.75 correspond dans une distribution de chi-carré avec 25 degrés de liberté (30 profils - 4 coefficients-1).
1-pchisq(s, (n_prof-nb-1))
```
Dans ce cas, le test rejette l’hypothèse nulle (i.e. le modèle ne « fit » pas bien les données). Rappellez-vous, c'est normal de parfois obtenir des résultats différents avec les test de Homer-Lemeshow, de Pearson ou deviance.     
  
## Évaluation des profils extrêmes et/ou influents
Comme pour la fonction `lm`, vous pouvez demander de créer une nouvelle table contenant, en plus de vos variables originales, les différentes valeurs (e.g. résiduels de Pearson, de déviance, probabilité prédite, leviers, Delta-Beta) qui serviront à évaluer votre modèle. La fonction `augment()` du package `broom` vous permet de le faire. Vous pourrez ensuite trier cette table pour identifier, par exemple, les observations avec les résiduels, leviers ou distance de Cook les plus extrêmes et essayer de comprendre si ces observations ont quelque chose en commun.  
```{r}
library(broom)
diag <- augment(modele_inter) #Je viens de créer une nouvelle table dans laquelle les résiduels, distance de cook, etc se trouvent maintenant
head(diag)
```

Notez que les valeurs prédites sont sur une échelle de log odds. Les valeurs prédites sur une échelle de probabilité ont cependant été conservées dans votre objet modèle. Vous pouvez donc simplement les ajouter à votre table de diagnostic, si vous le désirez.
```{r}
diag$pred_prob <- modele_inter$fitted.values
head(diag)
```
  
La table suivante est un extrait des 10 premières observations de cette nouvelle table lorsque classée des résiduels de Pearson les plus grands aux plus petits. À partir de cette table, vous pourriez produire les graphiques qui vous intéresseront à l’aide de la fonction `ggplot`.
```{r}
#Je pourrais maintenant ordonner cette table pour voir les 10 observations avec les résiduels les plus larges
diag_res <- diag[order(-diag$.resid),]
head(diag_res, 10)
```
  
Notez qu’une valeur prédite et un résiduel sont calculés pour chaque profil de prédicteur (et non pour chaque observation). Il est donc normal que les observations avec un profil de prédicteurs identique aient exactement les mêmes valeurs prédites et résiduels (e.g. les lignes 8, 9 et 10).  
  
## Sensibilité, spécificité et courbe ROC
La fonction `roc()` de la librairie `pROC` permet de créer un nouvel objet dans lequel la sensibilité (Se) et l’inverse de la spécificité (1-Sp) sont rapportés pour tous les seuils possibles de probabilité prédite par le modèle. Pour ce, vous devrez utiliser une table dans laquelle les valeurs prédites par le modèle sont rapportées (par exemple le jeu de données créé avec la fonction `augment()` de la librairie `broom`. 
```{r, message=FALSE, warning=FALSE}
#Valeur prédictive du modèle
library(pROC)
roc_data <- roc(data=diag, response="casecont", predictor="pred_prob")

#Présenter les sensibilités et spécificités des différents seuils dans une même table.
accu <- round(cbind(Seuil=roc_data$thresholds, Se=roc_data$sensitivities, Sp=roc_data$specificities), digits=2)

#Voir la table
kable(accu,  caption="**Table x.** Sensibilité et spécificité du modèle pour différents seuil de probabilité prédite.")%>%
  kable_styling()

```
    
        
La courbe ROC peut également être présentée de même que l’aire sous la courbe (l'AUC) à l'aide de la fonction `plot.roc` de la librairie `pROC`.   
```{r, fig.cap="**Figure x.** Courbe ROC.", message=FALSE, warning=FALSE}
plot.roc(roc_data, print.auc = TRUE, grid = TRUE)
```
  
J'en profites pour vous émoustiller avec la même figure, mais interactive cette fois. Déplacer votre curseur sur la ligne pour voir les valeurs de Se et Sp apparaitrent. Avec le bouton de gauche de votre souris, vous pouvez aussi faire un zoom sur une section de la figure. Utilisez le double-clic pour sortir du zoom. J'ai utilisé pour ça la fonction `plot_ly` de la librairie `plotly`. Je vpous laisse découvrir...   
```{r, fig.cap="**Figure x.** Courbe ROC (interactive)", message=FALSE, warning=FALSE}
library(plotly)
x_axis <- list(title = "(1-spécificité)")
y_axis <- list(title = "Sensibilité")
plot_ly(
  x=round((1-roc_data$specificities), digits=2),
  y=round(roc_data$sensitivities, digits=2),
  type="scatter",
  mode="line"
) %>%
  layout(
    title="ROC",
    xaxis=x_axis,
    yaxis=y_axis
  )
```

À l'aide de l'objet ROC créé, vous pourrez produire différents graphiques par exemple des graphiques illustrant comment la sensibilité (et/ou la spécificité) varie en fonction du seuil choisi.

```{r, fig.cap="**Figure x.** Sensibilité et spécificité en fonction du seuil choisi.", message=FALSE, warning=FALSE}
library(plotly)
x_axis <- list(title = "Seuil de probabilité choisi")
y_axis <- list(title = "Précision")
plot_ly(
  x=round((1-roc_data$thresholds), digits=2),
  y=round(roc_data$sensitivities, digits=2),
  type="scatter",
  mode="line",
  name="Sensibilité"
) %>%
  add_trace(
    x=round((1-roc_data$thresholds), digits=2),
     y=round(roc_data$specificities, digits=2),
    name="Spécificité"
    )%>%
  
  layout(
    title="Précision du modèle",
    xaxis=x_axis,
    yaxis=y_axis
        )
```
