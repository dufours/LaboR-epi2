<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 6 Régression linéaire | Épidémiologie 2 - Labo informatique R (PTM-6675)</title>
  <meta name="description" content="Chapitre 10" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 6 Régression linéaire | Épidémiologie 2 - Labo informatique R (PTM-6675)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapitre 10" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 6 Régression linéaire | Épidémiologie 2 - Labo informatique R (PTM-6675)" />
  
  <meta name="twitter:description" content="Chapitre 10" />
  

<meta name="author" content="Simon Dufour (Professeur à la Faculté de Médecine vétérinaire de l’Université de Montréal)" />


<meta name="date" content="2023-01-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="r-markdown.html"/>
<link rel="next" href="régression-logistique.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Épidémiologie 2 - Labo informatique R (PTM-6675)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> À propos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#spécificités-de-r"><i class="fa fa-check"></i><b>1.1</b> Spécificités de R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html"><i class="fa fa-check"></i><b>2</b> Bonnes pratiques de gestion de projet</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#organiser-son-projet-de-recherche"><i class="fa fa-check"></i><b>2.1</b> Organiser son projet de recherche</a></li>
<li class="chapter" data-level="2.2" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#où-sauvegarder-son-projet"><i class="fa fa-check"></i><b>2.2</b> Où sauvegarder son projet</a></li>
<li class="chapter" data-level="2.3" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#où-sauvegarder-ses-données"><i class="fa fa-check"></i><b>2.3</b> Où sauvegarder ses données</a></li>
<li class="chapter" data-level="2.4" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#scripts-danalyse"><i class="fa fa-check"></i><b>2.4</b> Scripts d’analyse</a></li>
<li class="chapter" data-level="2.5" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#les-projets-r"><i class="fa fa-check"></i><b>2.5</b> Les projets R</a></li>
<li class="chapter" data-level="2.6" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#copies-de-sécurité"><i class="fa fa-check"></i><b>2.6</b> Copies de sécurité</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="obtention-des-données-pour-les-travaux-pratiques.html"><a href="obtention-des-données-pour-les-travaux-pratiques.html"><i class="fa fa-check"></i><b>3</b> Obtention des données pour les travaux pratiques</a></li>
<li class="chapter" data-level="4" data-path="aide-de-r.html"><a href="aide-de-r.html"><i class="fa fa-check"></i><b>4</b> Aide de R</a></li>
<li class="chapter" data-level="5" data-path="r-markdown.html"><a href="r-markdown.html"><i class="fa fa-check"></i><b>5</b> R Markdown</a></li>
<li class="chapter" data-level="6" data-path="régression-linéaire.html"><a href="régression-linéaire.html"><i class="fa fa-check"></i><b>6</b> Régression linéaire</a>
<ul>
<li class="chapter" data-level="6.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#généralités"><i class="fa fa-check"></i><b>6.1</b> Généralités</a></li>
<li class="chapter" data-level="6.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#ajouter-des-intervalles-de-confiance"><i class="fa fa-check"></i><b>6.2</b> Ajouter des intervalles de confiance</a></li>
<li class="chapter" data-level="6.3" data-path="régression-linéaire.html"><a href="régression-linéaire.html#test-de-f-pour-comparer-modèles-complet-vs.-réduit"><i class="fa fa-check"></i><b>6.3</b> Test de <em>F</em> pour comparer modèles complet <em>vs.</em> réduit</a></li>
<li class="chapter" data-level="6.4" data-path="régression-linéaire.html"><a href="régression-linéaire.html#transformer-une-variable"><i class="fa fa-check"></i><b>6.4</b> Transformer une variable</a></li>
<li class="chapter" data-level="6.5" data-path="régression-linéaire.html"><a href="régression-linéaire.html#choisir-la-valeur-de-référence-pour-une-variable-catégorique"><i class="fa fa-check"></i><b>6.5</b> Choisir la valeur de référence pour une variable catégorique</a></li>
<li class="chapter" data-level="6.6" data-path="régression-linéaire.html"><a href="régression-linéaire.html#comparer-les-niveaux-dun-prédicteur-catégorique-avec-2-catégories"><i class="fa fa-check"></i><b>6.6</b> Comparer les niveaux d’un prédicteur catégorique avec &gt;2 catégories</a></li>
<li class="chapter" data-level="6.7" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluer-une-interaction-entre-2-variables"><i class="fa fa-check"></i><b>6.7</b> Évaluer une interaction entre 2 variables</a></li>
<li class="chapter" data-level="6.8" data-path="régression-linéaire.html"><a href="régression-linéaire.html#tol-et-vif---évaluer-la-colinéarité"><i class="fa fa-check"></i><b>6.8</b> TOL et VIF - Évaluer la colinéarité</a></li>
<li class="chapter" data-level="6.9" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluation-du-modèle"><i class="fa fa-check"></i><b>6.9</b> Évaluation du modèle</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluer-la-linéarité-de-la-relation-à-laide-de-courbes-lissées-pour-prédicteur-quantitatif"><i class="fa fa-check"></i><b>6.9.1</b> Évaluer la linéarité de la relation à l’aide de courbes lissées (pour prédicteur quantitatif)</a></li>
<li class="chapter" data-level="6.9.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluer-la-linéarité-de-la-relation-à-laide-de-termes-polynomiaux-pour-prédicteur-quantitatif"><i class="fa fa-check"></i><b>6.9.2</b> Évaluer la linéarité de la relation à l’aide de termes polynomiaux (pour prédicteur quantitatif)</a></li>
<li class="chapter" data-level="6.9.3" data-path="régression-linéaire.html"><a href="régression-linéaire.html#méthodes-diagnostiques-pour-les-résiduels"><i class="fa fa-check"></i><b>6.9.3</b> Méthodes diagnostiques pour les résiduels</a></li>
<li class="chapter" data-level="6.9.4" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluation-des-observations-extrêmes-etou-influentes"><i class="fa fa-check"></i><b>6.9.4</b> Évaluation des observations extrêmes et/ou influentes</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="régression-linéaire.html"><a href="régression-linéaire.html#travaux-pratiques-1---régression-linéaire---base"><i class="fa fa-check"></i><b>6.10</b> Travaux pratiques 1 - Régression linéaire - Base</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#exercices"><i class="fa fa-check"></i><b>6.10.1</b> Exercices</a></li>
<li class="chapter" data-level="6.10.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#code-r-et-réponses"><i class="fa fa-check"></i><b>6.10.2</b> Code R et réponses</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="régression-linéaire.html"><a href="régression-linéaire.html#travaux-pratiques-2---régression-linéaire---évaluation-du-modèle"><i class="fa fa-check"></i><b>6.11</b> Travaux pratiques 2 - Régression linéaire - Évaluation du modèle</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#exercices-1"><i class="fa fa-check"></i><b>6.11.1</b> Exercices</a></li>
<li class="chapter" data-level="6.11.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#code-r-et-réponses-1"><i class="fa fa-check"></i><b>6.11.2</b> Code R et réponses</a></li>
</ul></li>
<li class="chapter" data-level="6.12" data-path="régression-linéaire.html"><a href="régression-linéaire.html#travaux-pratiques-3---régression-linéaire---construction-de-modèle"><i class="fa fa-check"></i><b>6.12</b> Travaux pratiques 3 - Régression linéaire - Construction de modèle</a>
<ul>
<li class="chapter" data-level="6.12.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#exercices-2"><i class="fa fa-check"></i><b>6.12.1</b> Exercices</a></li>
<li class="chapter" data-level="6.12.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#code-r-et-réponses-2"><i class="fa fa-check"></i><b>6.12.2</b> Code R et réponses</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="régression-logistique.html"><a href="régression-logistique.html"><i class="fa fa-check"></i><b>7</b> Régression logistique</a>
<ul>
<li class="chapter" data-level="7.1" data-path="régression-logistique.html"><a href="régression-logistique.html#généralités-1"><i class="fa fa-check"></i><b>7.1</b> Généralités</a></li>
<li class="chapter" data-level="7.2" data-path="régression-logistique.html"><a href="régression-logistique.html#effectuer-un-test-de-rapport-de-vraisemblance"><i class="fa fa-check"></i><b>7.2</b> Effectuer un test de rapport de vraisemblance</a></li>
<li class="chapter" data-level="7.3" data-path="régression-logistique.html"><a href="régression-logistique.html#ajouter-des-ic95"><i class="fa fa-check"></i><b>7.3</b> Ajouter des IC95</a></li>
<li class="chapter" data-level="7.4" data-path="régression-logistique.html"><a href="régression-logistique.html#choisir-valeur-de-référence-pour-les-variables-catégoriques"><i class="fa fa-check"></i><b>7.4</b> Choisir valeur de référence pour les variables catégoriques</a></li>
<li class="chapter" data-level="7.5" data-path="régression-logistique.html"><a href="régression-logistique.html#produire-des-tables-de-résultats"><i class="fa fa-check"></i><b>7.5</b> Produire des tables de résultats</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="régression-logistique.html"><a href="régression-logistique.html#présenter-les-rapports-de-cotes-plutôt-que-les-log-odds"><i class="fa fa-check"></i><b>7.5.1</b> Présenter les rapports de cotes plutôt que les log odds</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="régression-logistique.html"><a href="régression-logistique.html#spécifier-pour-quelle-augmentation-dun-prédicteur-continu-le-rapport-de-cotes-est-calculé"><i class="fa fa-check"></i><b>7.6</b> Spécifier pour quelle augmentation d’un prédicteur continu le rapport de cotes est calculé</a></li>
<li class="chapter" data-level="7.7" data-path="régression-logistique.html"><a href="régression-logistique.html#évaluer-une-interaction-entre-2-variables-1"><i class="fa fa-check"></i><b>7.7</b> Évaluer une interaction entre 2 variables</a></li>
<li class="chapter" data-level="7.8" data-path="régression-logistique.html"><a href="régression-logistique.html#comparer-rapports-de-cotes-pour-une-combinaison-spécifique-de-prédicteurs"><i class="fa fa-check"></i><b>7.8</b> Comparer rapports de cotes pour une combinaison spécifique de prédicteurs</a></li>
<li class="chapter" data-level="7.9" data-path="régression-logistique.html"><a href="régression-logistique.html#présenter-leffet-des-prédicteurs-sur-une-échelle-de-probabilité"><i class="fa fa-check"></i><b>7.9</b> Présenter l’effet des prédicteurs sur une échelle de probabilité</a></li>
<li class="chapter" data-level="7.10" data-path="régression-logistique.html"><a href="régression-logistique.html#linéarité-de-la-relation-pour-prédicteur-quantitatif"><i class="fa fa-check"></i><b>7.10</b> Linéarité de la relation (pour prédicteur quantitatif)</a></li>
<li class="chapter" data-level="7.11" data-path="régression-logistique.html"><a href="régression-logistique.html#test-de-fit-de-hosmer-lemeshow-et-de-pearson"><i class="fa fa-check"></i><b>7.11</b> Test de ‘fit’ de Hosmer-Lemeshow et de Pearson</a></li>
<li class="chapter" data-level="7.12" data-path="régression-logistique.html"><a href="régression-logistique.html#évaluation-des-profils-extrêmes-etou-influents"><i class="fa fa-check"></i><b>7.12</b> Évaluation des profils extrêmes et/ou influents</a></li>
<li class="chapter" data-level="7.13" data-path="régression-logistique.html"><a href="régression-logistique.html#sensibilité-spécificité-et-courbe-roc"><i class="fa fa-check"></i><b>7.13</b> Sensibilité, spécificité et courbe ROC</a></li>
<li class="chapter" data-level="7.14" data-path="régression-logistique.html"><a href="régression-logistique.html#travaux-pratiques-4---régression-logistique---base"><i class="fa fa-check"></i><b>7.14</b> Travaux pratiques 4 - Régression logistique - Base</a>
<ul>
<li class="chapter" data-level="7.14.1" data-path="régression-logistique.html"><a href="régression-logistique.html#exercices-3"><i class="fa fa-check"></i><b>7.14.1</b> Exercices</a></li>
<li class="chapter" data-level="7.14.2" data-path="régression-logistique.html"><a href="régression-logistique.html#code-r-et-réponses-3"><i class="fa fa-check"></i><b>7.14.2</b> Code R et réponses</a></li>
</ul></li>
<li class="chapter" data-level="7.15" data-path="régression-logistique.html"><a href="régression-logistique.html#travaux-pratiques-5---régression-logistique---évaluation-du-modèle"><i class="fa fa-check"></i><b>7.15</b> Travaux pratiques 5 - Régression logistique - Évaluation du modèle</a>
<ul>
<li class="chapter" data-level="7.15.1" data-path="régression-logistique.html"><a href="régression-logistique.html#exercices-4"><i class="fa fa-check"></i><b>7.15.1</b> Exercices</a></li>
<li class="chapter" data-level="7.15.2" data-path="régression-logistique.html"><a href="régression-logistique.html#code-r-et-réponses-4"><i class="fa fa-check"></i><b>7.15.2</b> Code R et réponses</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html"><i class="fa fa-check"></i><b>8</b> Régression pour données de compte et d’incidence</a>
<ul>
<li class="chapter" data-level="8.1" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#régression-de-poisson"><i class="fa fa-check"></i><b>8.1</b> Régression de Poisson</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#indiquer-un-offset-i.e.-un-dénominateur-par-exemple-un-nombre-danimal-temps-à-risque"><i class="fa fa-check"></i><b>8.1.1</b> Indiquer un “offset” (i.e., un dénominateur, par exemple un nombre d’animal-temps à risque)</a></li>
<li class="chapter" data-level="8.1.2" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#test-de-rapport-de-vraisemblance"><i class="fa fa-check"></i><b>8.1.2</b> Test de rapport de vraisemblance</a></li>
<li class="chapter" data-level="8.1.3" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#présenter-les-ratios-dincidence"><i class="fa fa-check"></i><b>8.1.3</b> Présenter les ratios d’incidence</a></li>
<li class="chapter" data-level="8.1.4" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#calculer-un-compte-prédit-dévènements"><i class="fa fa-check"></i><b>8.1.4</b> Calculer un compte prédit d’évènements</a></li>
<li class="chapter" data-level="8.1.5" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#comparer-les-niveaux-dun-prédicteur-catégorique-avec-2-catégories-1"><i class="fa fa-check"></i><b>8.1.5</b> Comparer les niveaux d’un prédicteur catégorique avec &gt; 2 catégories</a></li>
<li class="chapter" data-level="8.1.6" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#linéarité-de-la-relation-pour-prédicteur-continu"><i class="fa fa-check"></i><b>8.1.6</b> Linéarité de la relation (pour prédicteur continu)</a></li>
<li class="chapter" data-level="8.1.7" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#test-de-chi-carré-de-pearson"><i class="fa fa-check"></i><b>8.1.7</b> Test de chi-carré de Pearson</a></li>
<li class="chapter" data-level="8.1.8" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#profils-extrêmes-ou-influents"><i class="fa fa-check"></i><b>8.1.8</b> Profils extrêmes ou influents</a></li>
<li class="chapter" data-level="8.1.9" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#comparer-les-comptes-observés-et-prédits"><i class="fa fa-check"></i><b>8.1.9</b> Comparer les comptes observés et prédits</a></li>
<li class="chapter" data-level="8.1.10" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#erreurs-type-mises-à-léchelle-scaled-se"><i class="fa fa-check"></i><b>8.1.10</b> Erreurs-type mises à l’échelle (scaled SE)</a></li>
<li class="chapter" data-level="8.1.11" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#variance-robuste"><i class="fa fa-check"></i><b>8.1.11</b> Variance robuste</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#régression-binomiale-négative"><i class="fa fa-check"></i><b>8.2</b> Régression binomiale négative</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#comparer-les-modèles-poisson-et-binomial-négatif"><i class="fa fa-check"></i><b>8.2.1</b> Comparer les modèles Poisson et Binomial négatif</a></li>
<li class="chapter" data-level="8.2.2" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#évaluer-les-résiduels-dun-modèle-binomial-négatif"><i class="fa fa-check"></i><b>8.2.2</b> Évaluer les résiduels d’un modèle Binomial négatif</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#modèles-zéro-enflés"><i class="fa fa-check"></i><b>8.3</b> Modèles zéro-enflés</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#généralités-2"><i class="fa fa-check"></i><b>8.3.1</b> Généralités</a></li>
<li class="chapter" data-level="8.3.2" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#test-de-vuong-comparer-modèle-zéros-enflés-au-modèle-conventionnel"><i class="fa fa-check"></i><b>8.3.2</b> Test de Vuong – Comparer modèle zéros-enflés au modèle conventionnel</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#calcul-du-risque-relatif-à-laide-dune-régression-de-poisson"><i class="fa fa-check"></i><b>8.4</b> Calcul du risque relatif à l’aide d’une régression de Poisson</a></li>
<li class="chapter" data-level="8.5" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#travaux-pratiques-6---régression-de-poisson-et-binomiale-négative"><i class="fa fa-check"></i><b>8.5</b> Travaux pratiques 6 - Régression de Poisson et Binomiale négative</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#exercices-5"><i class="fa fa-check"></i><b>8.5.1</b> Exercices</a></li>
<li class="chapter" data-level="8.5.2" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#code-r-et-réponses-5"><i class="fa fa-check"></i><b>8.5.2</b> Code R et réponses</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#travaux-pratiques-7---modèles-modifiés-en-zéro-et-calcul-dun-risque-relatif"><i class="fa fa-check"></i><b>8.6</b> Travaux pratiques 7 - Modèles modifiés en zéro et calcul d’un risque relatif</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#exercices-6"><i class="fa fa-check"></i><b>8.6.1</b> Exercices</a></li>
<li class="chapter" data-level="8.6.2" data-path="régression-pour-données-de-compte-et-dincidence.html"><a href="régression-pour-données-de-compte-et-dincidence.html#code-r-et-réponses-6"><i class="fa fa-check"></i><b>8.6.2</b> Code R et réponses</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html"><i class="fa fa-check"></i><b>9</b> Analyses de survie</a>
<ul>
<li class="chapter" data-level="9.1" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#généralités-3"><i class="fa fa-check"></i><b>9.1</b> Généralités</a></li>
<li class="chapter" data-level="9.2" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#format-des-données-pour-une-analyse-de-survie"><i class="fa fa-check"></i><b>9.2</b> Format des données pour une analyse de survie</a></li>
<li class="chapter" data-level="9.3" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#analyses-non-paramétriques-kaplan-meier"><i class="fa fa-check"></i><b>9.3</b> Analyses non-paramétriques (Kaplan-Meier)</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#table-de-kaplan-meier-et-temps-médian-de-survie"><i class="fa fa-check"></i><b>9.3.1</b> Table de Kaplan-Meier et temps médian de survie</a></li>
<li class="chapter" data-level="9.3.2" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#courbe-de-survie-de-kaplan-meier"><i class="fa fa-check"></i><b>9.3.2</b> Courbe de survie de Kaplan-Meier</a></li>
<li class="chapter" data-level="9.3.3" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#estimer-la-probabilité-de-survie-pour-un-temps-donné"><i class="fa fa-check"></i><b>9.3.3</b> Estimer la probabilité de survie pour un temps donné</a></li>
<li class="chapter" data-level="9.3.4" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#comparaisons-entre-niveaux-dun-prédicteur-catégorique"><i class="fa fa-check"></i><b>9.3.4</b> Comparaisons entre niveaux d’un prédicteur catégorique</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#régression-de-cox-à-hasard-proportionnel"><i class="fa fa-check"></i><b>9.4</b> Régression de Cox à hasard proportionnel</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#analyses-stratifiées"><i class="fa fa-check"></i><b>9.4.1</b> Analyses stratifiées</a></li>
<li class="chapter" data-level="9.4.2" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#prédicteur-dont-la-valeur-change-dans-le-temps"><i class="fa fa-check"></i><b>9.4.2</b> Prédicteur dont la valeur change dans le temps</a></li>
<li class="chapter" data-level="9.4.3" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#prédicteur-dont-leffet-change-dans-le-temps"><i class="fa fa-check"></i><b>9.4.3</b> Prédicteur dont l’effet change dans le temps</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#évaluation-du-modèle-1"><i class="fa fa-check"></i><b>9.5</b> Évaluation du modèle</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#linéarité-de-la-relation-pour-les-prédicteurs-quantitatifs"><i class="fa fa-check"></i><b>9.5.1</b> Linéarité de la relation (pour les prédicteurs quantitatifs)</a></li>
<li class="chapter" data-level="9.5.2" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#valider-la-supposition-de-hasard-proportionnel"><i class="fa fa-check"></i><b>9.5.2</b> Valider la supposition de hasard proportionnel</a></li>
<li class="chapter" data-level="9.5.3" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#évaluer-impact-du-non-respect-de-la-supposition-de-censure-non-informative"><i class="fa fa-check"></i><b>9.5.3</b> Évaluer impact du non-respect de la supposition de censure non-informative</a></li>
<li class="chapter" data-level="9.5.4" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#observations-extrêmes"><i class="fa fa-check"></i><b>9.5.4</b> Observations extrêmes</a></li>
<li class="chapter" data-level="9.5.5" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#observations-influentes"><i class="fa fa-check"></i><b>9.5.5</b> Observations influentes</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#pour-aller-plus-loin"><i class="fa fa-check"></i><b>9.6</b> Pour aller plus loin</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#erreurs-types-robustes"><i class="fa fa-check"></i><b>9.6.1</b> Erreurs-types robustes</a></li>
<li class="chapter" data-level="9.6.2" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#régression-de-cox-à-fragilité-partagée"><i class="fa fa-check"></i><b>9.6.2</b> Régression de Cox à fragilité partagée</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#travaux-pratiques-8---analyses-de-survie-non-paramétriques"><i class="fa fa-check"></i><b>9.7</b> Travaux pratiques 8 - Analyses de survie non-paramétriques</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#exercices-7"><i class="fa fa-check"></i><b>9.7.1</b> Exercices</a></li>
<li class="chapter" data-level="9.7.2" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#code-r-et-réponses-7"><i class="fa fa-check"></i><b>9.7.2</b> Code R et réponses</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#travaux-pratiques-9---analyses-de-survie-semi-paramétriques"><i class="fa fa-check"></i><b>9.8</b> Travaux pratiques 9 - Analyses de survie semi-paramétriques</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#exercices-8"><i class="fa fa-check"></i><b>9.8.1</b> Exercices</a></li>
<li class="chapter" data-level="9.8.2" data-path="analyses-de-survie.html"><a href="analyses-de-survie.html#code-r-et-réponses-8"><i class="fa fa-check"></i><b>9.8.2</b> Code R et réponses</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html"><i class="fa fa-check"></i><b>10</b> Modèles mixtes pour données structurées</a>
<ul>
<li class="chapter" data-level="10.1" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#généralités-4"><i class="fa fa-check"></i><b>10.1</b> Généralités</a></li>
<li class="chapter" data-level="10.2" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#évaluer-la-structure-de-regroupement"><i class="fa fa-check"></i><b>10.2</b> Évaluer la structure de regroupement</a></li>
<li class="chapter" data-level="10.3" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#modèle-linéaire-mixte"><i class="fa fa-check"></i><b>10.3</b> Modèle linéaire mixte</a></li>
<li class="chapter" data-level="10.4" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#modèle-mixte-avec-un-seul-intercept-aléatoire"><i class="fa fa-check"></i><b>10.4</b> Modèle mixte avec un seul intercept aléatoire</a></li>
<li class="chapter" data-level="10.5" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#modèle-mixte-avec-plus-dun-intercept-aléatoire"><i class="fa fa-check"></i><b>10.5</b> Modèle mixte avec plus d’un intercept aléatoire</a></li>
<li class="chapter" data-level="10.6" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#partition-de-la-variance"><i class="fa fa-check"></i><b>10.6</b> Partition de la variance</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#coefficient-de-corrélation-intra-classe"><i class="fa fa-check"></i><b>10.6.1</b> Coefficient de corrélation intra-classe</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#effet-contextuel"><i class="fa fa-check"></i><b>10.7</b> Effet contextuel</a></li>
<li class="chapter" data-level="10.8" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#évaluation-du-modèle-2"><i class="fa fa-check"></i><b>10.8</b> Évaluation du modèle</a></li>
<li class="chapter" data-level="10.9" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#pentes-aléatoires"><i class="fa fa-check"></i><b>10.9</b> Pentes aléatoires</a></li>
<li class="chapter" data-level="10.10" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#travaux-pratiques-10---modèles-linéaires-mixtes"><i class="fa fa-check"></i><b>10.10</b> Travaux pratiques 10 - Modèles linéaires mixtes</a>
<ul>
<li class="chapter" data-level="10.10.1" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#exercices-9"><i class="fa fa-check"></i><b>10.10.1</b> Exercices</a></li>
<li class="chapter" data-level="10.10.2" data-path="modèles-mixtes-pour-données-structurées.html"><a href="modèles-mixtes-pour-données-structurées.html#code-r-et-réponses-9"><i class="fa fa-check"></i><b>10.10.2</b> Code R et réponses</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publié avec bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Épidémiologie 2 - Labo informatique R (PTM-6675)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="régression-linéaire" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapitre 6</span> Régression linéaire<a href="régression-linéaire.html#régression-linéaire" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="généralités" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Généralités<a href="régression-linéaire.html#généralités" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La fonction de base dans R pour la régression linéaire est la fonction <code>lm()</code>. Pour les exemples suivants, nous allons utiliser que les troupeaux du jeu de données Daisy2.xlsx avec h7=1.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="régression-linéaire.html#cb11-1" aria-hidden="true" tabindex="-1"></a>daisy2 <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;daisy2.csv&quot;</span>, </span>
<span id="cb11-2"><a href="régression-linéaire.html#cb11-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">header=</span><span class="cn">TRUE</span>, </span>
<span id="cb11-3"><a href="régression-linéaire.html#cb11-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">sep=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb11-4"><a href="régression-linéaire.html#cb11-4" aria-hidden="true" tabindex="-1"></a>daisy2_mod <span class="ot">&lt;-</span> <span class="fu">subset</span>(daisy2, </span>
<span id="cb11-5"><a href="régression-linéaire.html#cb11-5" aria-hidden="true" tabindex="-1"></a>                     h7<span class="sc">==</span><span class="dv">1</span>)</span></code></pre></div>
<p>Une régression linéaire dans sa plus simple expression pourrait être:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="régression-linéaire.html#cb12-1" aria-hidden="true" tabindex="-1"></a>modele <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb12-2"><a href="régression-linéaire.html#cb12-2" aria-hidden="true" tabindex="-1"></a>             milk120 <span class="sc">~</span> (parity<span class="sc">+</span>twin)</span>
<span id="cb12-3"><a href="régression-linéaire.html#cb12-3" aria-hidden="true" tabindex="-1"></a>             ) <span class="co">#Nous avons créé un nouvel objet qui s&#39;appelle modele et qui est une régression des variables parity et twin sur milk120</span></span>
<span id="cb12-4"><a href="régression-linéaire.html#cb12-4" aria-hidden="true" tabindex="-1"></a>modele <span class="co">#Nous demandons à voir l&#39;objet modele</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (parity + twin), data = daisy2_mod)
## 
## Coefficients:
## (Intercept)       parity         twin  
##      2734.9        172.5       -150.6</code></pre>
<p>Les résultats présentés sont simplement l’intercept et les coefficients de <em>parity</em> et de <em>twin</em>. Pour une vache avec <em>parity</em>=0 et <em>twin</em>=0 le modèle prédit 2734,9kg de lait en 120 jours. On ajoute 172,5kg pour chaque augmentation de 1 unité de <em>parity</em> et on enlève 150,6kg lorsque <em>twin</em> est présent. Si vous préférez:</p>
<p><span class="math display">\[ milk120 = 2734,9 + 172,5*parity - 150,6*twin \]</span></p>
<p>Pour avoir un peu plus d’informations sur ce modèle, vous pouvez demander:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="régression-linéaire.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele) <span class="co">#Nous demandons un résumé de l&#39;objet modele</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (parity + twin), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1969.69  -434.13    -7.12   422.23  2147.50 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2734.865     32.313   84.64   &lt;2e-16 ***
## parity       172.513      9.923   17.39   &lt;2e-16 ***
## twin        -150.557    101.741   -1.48    0.139    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 650.3 on 1765 degrees of freedom
##   (208 observations effacées parce que manquantes)
## Multiple R-squared:  0.1463, Adjusted R-squared:  0.1453 
## F-statistic: 151.2 on 2 and 1765 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Quelques infos sont alors présentées sur:<br />
- Les <strong>résiduels</strong> (par exemple, le min et le max).<br />
- Votre modèle, mais cette fois avec les <strong>erreurs-types</strong> de chacun des coefficients et les <strong>valeurs de</strong> <em>P</em> <strong>pour le test de</strong> <em>T</em> <strong>de chaque coefficient</strong>.<br />
- <strong>L’erreur-type des résiduels</strong> est également rapportée (650.3) de même que les <strong>degrés de liberté</strong> (1765) et le <strong>nombre d’observations manquantes</strong> (208).<br />
- Le <strong><span class="math inline">\(R^2\)</span></strong> (le coefficient de détermination) est présenté. Dans ce cas 14.63% de la variation de <em>milk120</em> est expliquée par le modèle.<br />
- La <strong>valeur de</strong> <em>F</em> (151.2) qui teste si tous les coefficients=0 est aussi rapportée, de même que ses degrés de libertés (2 et 1765) et la valeur de <em>P</em> associée (P&lt;0.01).</p>
<p>Vous pouvez demander à voir la <strong>table ANOVA</strong> à l’aide de la fonction <code>aov()</code>.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="régression-linéaire.html#cb16-1" aria-hidden="true" tabindex="-1"></a>aov<span class="ot">&lt;-</span><span class="fu">aov</span>(modele) <span class="co">#Nous créons un objet aov</span></span>
<span id="cb16-2"><a href="régression-linéaire.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(aov) <span class="co">#Nous demandons de résumer cet objet aov</span></span></code></pre></div>
<pre><code>##               Df    Sum Sq   Mean Sq F value Pr(&gt;F)    
## parity         1 126939726 126939726  300.21 &lt;2e-16 ***
## twin           1    925932    925932    2.19  0.139    
## Residuals   1765 746306281    422836                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 208 observations effacées parce que manquantes</code></pre>
<p>Finalement, notez que <em>parity</em> a été traitée comme une variable quantitative. <strong>Si vous désirez qu’elle soit traitée comme une variable catégorique</strong>, vous pourriez soit créer une nouvelle variable catégorique et l’utiliser dans le modèle.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="régression-linéaire.html#cb18-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_cat <span class="ot">&lt;-</span> <span class="fu">factor</span>(daisy2_mod<span class="sc">$</span>parity)</span></code></pre></div>
<p>Soit l’écrire directement dans le modèle.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="régression-linéaire.html#cb19-1" aria-hidden="true" tabindex="-1"></a>modele1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb19-2"><a href="régression-linéaire.html#cb19-2" aria-hidden="true" tabindex="-1"></a>              milk120 <span class="sc">~</span> (<span class="fu">factor</span>(parity)<span class="sc">+</span>twin)</span>
<span id="cb19-3"><a href="régression-linéaire.html#cb19-3" aria-hidden="true" tabindex="-1"></a>              ) <span class="co">#Factor() nous permet d&#39;indiquer qu&#39;une variable est catégorique</span></span>
<span id="cb19-4"><a href="régression-linéaire.html#cb19-4" aria-hidden="true" tabindex="-1"></a>modele1 </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (factor(parity) + twin), data = daisy2_mod)
## 
## Coefficients:
##     (Intercept)  factor(parity)2  factor(parity)3  factor(parity)4  
##          2630.9            719.3            798.9            836.2  
## factor(parity)5  factor(parity)6  factor(parity)7             twin  
##           818.8            937.6            793.9           -192.3</code></pre>
<p>Il y aura maintenant un coefficient pour chaque niveau de la variable <em>parity</em> sauf le niveau de référence (<em>parity</em>=1 a été choisi comme référence ici).</p>
</div>
<div id="ajouter-des-intervalles-de-confiance" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Ajouter des intervalles de confiance<a href="régression-linéaire.html#ajouter-des-intervalles-de-confiance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Des IC95% pour chacun des paramètres estimés seront obtenus comme suit à l’aide de la fonction <code>confint()</code>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="régression-linéaire.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(modele, </span>
<span id="cb21-2"><a href="régression-linéaire.html#cb21-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">level=</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 2671.4897 2798.2413
## parity       153.0500  191.9752
## twin        -350.1027   48.9892</code></pre>
</div>
<div id="test-de-f-pour-comparer-modèles-complet-vs.-réduit" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Test de <em>F</em> pour comparer modèles complet <em>vs.</em> réduit<a href="régression-linéaire.html#test-de-f-pour-comparer-modèles-complet-vs.-réduit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Tester si quelques coefficients spécifiques sont différents de zéro (i.e., comparer un modèle complet et un modèle réduit) est très simple dans <code>R</code>. Il faut d’abord faire rouler chaque modèle. Par exemple, dans le modèle suivant, pour tester les 4 problèmes de reproduction (<em>twin</em>, <em>dyst</em>, <em>rp</em> et <em>vag_disch</em>) ensemble, vous devrez exécuter les 2 modèles suivants</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="régression-linéaire.html#cb23-1" aria-hidden="true" tabindex="-1"></a>modele_complet <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb23-2"><a href="régression-linéaire.html#cb23-2" aria-hidden="true" tabindex="-1"></a>                     milk120 <span class="sc">~</span> (parity<span class="sc">+</span>twin<span class="sc">+</span>dyst<span class="sc">+</span>rp<span class="sc">+</span>vag_disch)</span>
<span id="cb23-3"><a href="régression-linéaire.html#cb23-3" aria-hidden="true" tabindex="-1"></a>                     )</span>
<span id="cb23-4"><a href="régression-linéaire.html#cb23-4" aria-hidden="true" tabindex="-1"></a>modele_reduit <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb23-5"><a href="régression-linéaire.html#cb23-5" aria-hidden="true" tabindex="-1"></a>                    milk120 <span class="sc">~</span> (parity)</span>
<span id="cb23-6"><a href="régression-linéaire.html#cb23-6" aria-hidden="true" tabindex="-1"></a>                    )</span></code></pre></div>
<p>Ensuite, on peut utiliser la fonction <code>anova()</code> pour comparer les modèles.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="régression-linéaire.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele_complet, modele_reduit)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: milk120 ~ (parity + twin + dyst + rp + vag_disch)
## Model 2: milk120 ~ (parity)
##   Res.Df       RSS Df Sum of Sq      F Pr(&gt;F)
## 1   1762 744046844                           
## 2   1766 747232213 -4  -3185369 1.8858 0.1103</code></pre>
<p>Dans ce cas, on obtient une valeur de <em>P</em> de 0.11. Donc, le modèle complet n’est pas meilleur ou, si vous préférez, les coefficients de <em>twin</em>, <em>dyst</em>, <em>rp</em> et <em>vag_disch</em> ne sont pas différents de zéro.</p>
</div>
<div id="transformer-une-variable" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Transformer une variable<a href="régression-linéaire.html#transformer-une-variable" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Pour transformer une variable <strong>(e.g. centrer, mettre à l’échelle, mettre au carré ou au cube)</strong>, vous pouvez simplement utiliser les notions de base pour créer une nouvelle variable dans votre jeu de données. Vous pourrez ensuite utiliser cette nouvelle variable dans votre modèle. Par exemple, le code suivant permet de créer 3 nouvelles variables.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="régression-linéaire.html#cb26-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>parity_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>parity<span class="dv">-1</span> </span>
<span id="cb26-2"><a href="régression-linéaire.html#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="régression-linéaire.html#cb26-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct_sc <span class="ot">&lt;-</span> (daisy2_mod<span class="sc">$</span>herd_size<span class="dv">-250</span>)<span class="sc">/</span><span class="dv">100</span></span>
<span id="cb26-4"><a href="régression-linéaire.html#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="régression-linéaire.html#cb26-5" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_sq <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>herd_size_ct_sc<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct_sc</span></code></pre></div>
<ul>
<li>Une variable parity centrée sur la valeur 1 (i.e., le 1 devient le zéro pour cette nouvelle variable);<br />
</li>
<li>Une nouvelle variable herd_size_ct_sc centrée sur 250 vaches et mise à l’échelle pour représenter une augmentation de 100 vaches;<br />
</li>
<li>Une nouvelle variable herd_size_sq qui est la variable herd_size centrée, mise à l’échelle et élevé au carré (i.e. un terme polynomial qui pourra être utilisé afin de vérifier la linéarité de la relation entre herd_size et votre variable dépendante).</li>
</ul>
</div>
<div id="choisir-la-valeur-de-référence-pour-une-variable-catégorique" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Choisir la valeur de référence pour une variable catégorique<a href="régression-linéaire.html#choisir-la-valeur-de-référence-pour-une-variable-catégorique" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Notez que pour les variables catégoriques, <code>R</code> décide (et pas toujours bien) de la valeur de référence. On peut tout de même forcer la valeur de référence qui nous intéresse. Dans le code suivant, j’ai indiqué en utilisant la fonction <code>relevel()</code> que, pour la variable <em>par_cat</em> créée précédemment, la valeur 2 sera la catégorie de référence. Lorsque j’utilise ensuite cette variable dans un modèle statistique, la valeur 2 est automatiquement utilisée comme référence.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="régression-linéaire.html#cb27-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod <span class="ot">&lt;-</span> <span class="fu">within</span>(daisy2_mod, </span>
<span id="cb27-2"><a href="régression-linéaire.html#cb27-2" aria-hidden="true" tabindex="-1"></a>                   par_cat <span class="ot">&lt;-</span> <span class="fu">relevel</span>(par_cat, <span class="at">ref=</span><span class="dv">2</span>)</span>
<span id="cb27-3"><a href="régression-linéaire.html#cb27-3" aria-hidden="true" tabindex="-1"></a>                   ) <span class="co">#Sélection de la valeur de référence par_cat=2</span></span>
<span id="cb27-4"><a href="régression-linéaire.html#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="régression-linéaire.html#cb27-5" aria-hidden="true" tabindex="-1"></a>modele2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb27-6"><a href="régression-linéaire.html#cb27-6" aria-hidden="true" tabindex="-1"></a>              milk120 <span class="sc">~</span> (par_cat<span class="sc">+</span>twin)</span>
<span id="cb27-7"><a href="régression-linéaire.html#cb27-7" aria-hidden="true" tabindex="-1"></a>              )</span>
<span id="cb27-8"><a href="régression-linéaire.html#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (par_cat + twin), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2240.03  -382.80     3.92   373.68  2180.58 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3350.23      30.80 108.777  &lt; 2e-16 ***
## par_cat1     -719.28      42.46 -16.938  &lt; 2e-16 ***
## par_cat3       79.60      44.96   1.771  0.07681 .  
## par_cat4      116.96      49.33   2.371  0.01785 *  
## par_cat5       99.49      51.56   1.930  0.05382 .  
## par_cat6      218.27      67.51   3.233  0.00125 ** 
## par_cat7       74.66     218.88   0.341  0.73308    
## twin         -192.25      96.06  -2.001  0.04550 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 612.9 on 1760 degrees of freedom
##   (208 observations effacées parce que manquantes)
## Multiple R-squared:  0.2436, Adjusted R-squared:  0.2406 
## F-statistic: 80.98 on 7 and 1760 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="comparer-les-niveaux-dun-prédicteur-catégorique-avec-2-catégories" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Comparer les niveaux d’un prédicteur catégorique avec &gt;2 catégories<a href="régression-linéaire.html#comparer-les-niveaux-dun-prédicteur-catégorique-avec-2-catégories" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Pour un prédicteur catégorique avec plus de 2 catégories, on voudra d’abord savoir si le prédicteur est significativement associé à la variable dépendante (i.e. test de <em>F</em>). Si c’est le cas, on voudra alors comparer les niveaux entre eux (i.e. tests de <em>T</em>). Deux problèmes se posent alors :<br />
1) Problème de comparaisons multiples; on voudra ajuster nos valeurs de <em>P</em> ou nos <em>IC 95%</em> en fonction du nombre de comparaisons effectuées.<br />
2) La table avec les coefficients de régression nous rapporte le test de <em>T</em> pour chaque coefficient, lorsque comparé au niveau de référence, mais pas entre eux.<br />
Par exemple, avec une variable parity_cat avec 3 catégories : 1=parité 1, 2=parité 2 et 3=parité ≥ 3, on aura</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="régression-linéaire.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous créons une variable parity catégorique:</span></span>
<span id="cb29-2"><a href="régression-linéaire.html#cb29-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_cat <span class="ot">&lt;-</span> <span class="fu">cut</span>(daisy2_mod<span class="sc">$</span>parity, </span>
<span id="cb29-3"><a href="régression-linéaire.html#cb29-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="cn">Inf</span>), </span>
<span id="cb29-4"><a href="régression-linéaire.html#cb29-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;First&quot;</span>, <span class="st">&quot;Second&quot;</span>, <span class="st">&quot;Third or more&quot;</span>)</span>
<span id="cb29-5"><a href="régression-linéaire.html#cb29-5" aria-hidden="true" tabindex="-1"></a>                          )</span>
<span id="cb29-6"><a href="régression-linéaire.html#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">#La régression</span></span>
<span id="cb29-7"><a href="régression-linéaire.html#cb29-7" aria-hidden="true" tabindex="-1"></a>modele <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb29-8"><a href="régression-linéaire.html#cb29-8" aria-hidden="true" tabindex="-1"></a>             milk120 <span class="sc">~</span> (par_cat)</span>
<span id="cb29-9"><a href="régression-linéaire.html#cb29-9" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb29-10"><a href="régression-linéaire.html#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (par_cat), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2234.73  -387.55     7.79   377.11  2176.01 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           2629.63      29.31   89.71   &lt;2e-16 ***
## par_catSecond          715.30      42.45   16.85   &lt;2e-16 ***
## par_catThird or more   824.66      35.54   23.20   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 613.5 on 1765 degrees of freedom
##   (208 observations effacées parce que manquantes)
## Multiple R-squared:  0.2402, Adjusted R-squared:  0.2393 
## F-statistic: 278.9 on 2 and 1765 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Dans les résultats, les tests de <em>T</em> nous indiquent que <em>Second</em> est différent de <em>First</em> (la catégorie de référence) et que <em>Third or more</em> est différent de <em>First</em>. Mais on ne peut comparer <em>Second</em> avec <em>Third or more</em> et ces valeurs de <em>T</em> ne sont pas ajustées pour les comparaisons multiples. La fonction <code>emmeans()</code> du package <code>emmeans</code> permettra de générer les informations nécessaires pour faire les contrastes. La fonction <code>pairs()</code> calculera ces contrastes. Par défaut la méthode d’ajustement <em>a posteriori</em> pour comparaison multiple de Tukey-Kramer est utilisée.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="régression-linéaire.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb31-2"><a href="régression-linéaire.html#cb31-2" aria-hidden="true" tabindex="-1"></a>contrast <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(modele, <span class="st">&quot;par_cat&quot;</span>) <span class="co">#Ici nous avons créé un objet nommé contrast qui contient les éléments dont nous aurons besoin pour comparer les catégories de par_cat</span></span>
<span id="cb31-3"><a href="régression-linéaire.html#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(contrast) <span class="co">#Nous demandons ensuite les estimés des différentes catégories. </span></span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df t.ratio p.value
##  First - Second             -715 42.5 1765 -16.848  &lt;.0001
##  First - Third or more      -825 35.5 1765 -23.200  &lt;.0001
##  Second - Third or more     -109 36.7 1765  -2.979  0.0082
## 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>Nous voyons maintenant toutes les comparaisons possibles. Par exemple les vaches de 2ième lactation produisaient 109kg de lait de moins que les 3ième lactation. Et les valeurs de <em>P</em> présentées sont ajustées <em>a posteriori</em> pour les comparaisons multiples.Notez que vous pourriez aussi simplement faire un ajustement <em>a priori</em> (e.g. Bonferroni). Vous n’aurez pas alors à modifier le calcul des valeurs de <em>P</em> ou de vos <em>IC 95%</em>, mais simplement votre seuil <em>α</em>.</p>
<p>Si vous désirez plutôt l’estimé (i.e., le least square means) pour chaque catégorie et son intervalle de confiance, vous pouvez alors simplement utiliser la fonction <code>confint()</code> sur votre contraste:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="régression-linéaire.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">pairs</span>(contrast))</span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df lower.CL upper.CL
##  First - Second             -715 42.5 1765     -815   -615.7
##  First - Third or more      -825 35.5 1765     -908   -741.3
##  Second - Third or more     -109 36.7 1765     -195    -23.3
## 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>On verra alors les différences de production moyenne par catégorie et leurs <em>IC 95</em>. Par exemple, les vaches de 1ère lactation produisaient en moyenne 715kg de moins que les 2ième (<em>IC 95</em>: 616, 815). Ces <em>IC 95</em> sont également ajustés pour les comparaisons multiples.</p>
</div>
<div id="évaluer-une-interaction-entre-2-variables" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> Évaluer une interaction entre 2 variables<a href="régression-linéaire.html#évaluer-une-interaction-entre-2-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>L’interaction entre 2 variables peut être modélisée de manière très simple, vous n’avez qu’à indiquer dans votre modèle l’interaction entre les variables (<em>parity</em> x <em>dyst</em>). La fonction <code>lm()</code> se chargera alors d’inclure tous les termes nécessaires (i.e., <em>dyst</em> + <em>parity</em> + <em>dyst</em> x <em>parity</em>).</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="régression-linéaire.html#cb35-1" aria-hidden="true" tabindex="-1"></a>modele <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb35-2"><a href="régression-linéaire.html#cb35-2" aria-hidden="true" tabindex="-1"></a>             milk120 <span class="sc">~</span> (parity<span class="sc">*</span>dyst)) <span class="co">#parity*dyst demandera d&#39;inclure dans le modèle: dyst + parity + dyst*parity</span></span>
<span id="cb35-3"><a href="régression-linéaire.html#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (parity * dyst), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1970.32  -437.44   -17.17   422.63  2149.86 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2741.50      33.93  80.805   &lt;2e-16 ***
## parity        169.51      10.27  16.506   &lt;2e-16 ***
## dyst          -89.58     115.00  -0.779    0.436    
## parity:dyst    30.42      44.90   0.678    0.498    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 650.7 on 1764 degrees of freedom
##   (208 observations effacées parce que manquantes)
## Multiple R-squared:  0.1455, Adjusted R-squared:  0.1441 
## F-statistic: 100.1 on 3 and 1764 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="régression-linéaire.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: milk120
##               Df    Sum Sq   Mean Sq  F value Pr(&gt;F)    
## parity         1 126939726 126939726 299.7720 &lt;2e-16 ***
## dyst           1     64457     64457   0.1522 0.6965    
## parity:dyst    1    194401    194401   0.4591 0.4981    
## Residuals   1764 746973355    423454                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Ici, on voit les valeurs estimées du coefficient de chacun des paramètres du modèle et le test de <em>F</em> pour l’interaction (<em>P</em>=0.498).</p>
<p>C’est également possible de demander à voir un graphique illustrant cette interaction (ce sera parfois plus facile à interpréter). Le package <code>sjPlot</code> permet de générer toutes sortes de graphiques à partir de modèles estimés à l’aide des fonctions <code>lm</code>, <code>glm</code>, <code>lme</code>, <code>lmerMod</code>, etc. La fonction <code>plot_model</code> permet de générer une figure, j’indique le nom du modèle (dans ce cas, je l’avais simplement nommé <em>modele</em>) et le type de figure demandée. Ici je demande une figure <code>int</code> illustrant les effets des termes d’intéractions. La fonction <code>plot_model</code> cherchera les termes d’interaction dans le modèle et fera une figure à l’aide de ceux-ci. La variable apparaissant en premier dans le modèle sera utilisée pour l’axe des x. Pour plus de détails voir <a href="https://cran.r-project.org/web/packages/sjPlot/vignettes/plot_interactions.html">Plotting interaction effects of regression models</a>.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="régression-linéaire.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb39-2"><a href="régression-linéaire.html#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(modele, <span class="at">type=</span><span class="st">&quot;int&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-28"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-28-1.png" alt="Effet de parité et dystocie sur la production laitière entre 0 et 120 jours en lait." width="672" />
<p class="caption">
Figure 6.1: Effet de parité et dystocie sur la production laitière entre 0 et 120 jours en lait.
</p>
</div>
<p>Notez que, si un de vos termes d’interaction est catégorique avec &gt; 2 catégories et que vous avez utilisé la fonction <code>factor()</code> qui vous aura permis de bien identifier que cette variable est catégorique, les variables indicatrices seront alors créées automatiquement pour vous (ce qui sera très utile lorsque vous aurez des interactions avec des prédicteurs catégoriques avec &gt; 2 catégories).</p>
</div>
<div id="tol-et-vif---évaluer-la-colinéarité" class="section level2 hasAnchor" number="6.8">
<h2><span class="header-section-number">6.8</span> TOL et VIF - Évaluer la colinéarité<a href="régression-linéaire.html#tol-et-vif---évaluer-la-colinéarité" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Afin de détecter les problèmes de colinéarité, on peut demander le calcul du « variance inflation factor » (VIF) à l’aide du package <code>car</code> et de la fonction <code>vif()</code>. La tolérance sera simplement (1/VIF). Un VIF &gt; 10 (ou tolérance &lt; 0.10) indiquera un problème sévère de colinéarité.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="régression-linéaire.html#cb40-1" aria-hidden="true" tabindex="-1"></a>modele1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb40-2"><a href="régression-linéaire.html#cb40-2" aria-hidden="true" tabindex="-1"></a>            milk120 <span class="sc">~</span> (dyst <span class="sc">+</span> parity)</span>
<span id="cb40-3"><a href="régression-linéaire.html#cb40-3" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb40-4"><a href="régression-linéaire.html#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb40-5"><a href="régression-linéaire.html#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(modele1)</span></code></pre></div>
<pre><code>##     dyst   parity 
## 1.017337 1.017337</code></pre>
<p>On a donc un VIF de 1.02 (ou une tolérance de 0.98).</p>
</div>
<div id="évaluation-du-modèle" class="section level2 hasAnchor" number="6.9">
<h2><span class="header-section-number">6.9</span> Évaluation du modèle<a href="régression-linéaire.html#évaluation-du-modèle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>L’évaluation du modèle est basée sur différentes procédures diagnostiques. L’évaluation de graphiques constitue une part importante de ce travail.</p>
<div id="évaluer-la-linéarité-de-la-relation-à-laide-de-courbes-lissées-pour-prédicteur-quantitatif" class="section level3 hasAnchor" number="6.9.1">
<h3><span class="header-section-number">6.9.1</span> Évaluer la linéarité de la relation à l’aide de courbes lissées (pour prédicteur quantitatif)<a href="régression-linéaire.html#évaluer-la-linéarité-de-la-relation-à-laide-de-courbes-lissées-pour-prédicteur-quantitatif" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La linéarité de la relation est une supposition importante du modèle. Pour les prédicteurs quantitatifs, vous devrez toujours vérifier si cette supposition est bien respectée. Vous pouvez le faire à l’aide du modèle polynomial (en ajoutant le <span class="math inline">\(prédicteur^2\)</span> ou le <span class="math inline">\(prédicteur^2\)</span> et le <span class="math inline">\(prédicteur^3\)</span> dans votre modèle; voir prochaine section). Si les coefficients de ces termes sont significativement différents de zéro (i.e. P &lt; 0.05), ont concluera que la relation est une courbe, ou une courbe avec un ou plusieurs points d’inflexion, respectivement.</p>
<p>Mais une représentation graphique de la relation facilite toujours la compréhension. Les courbes lissées (e.g. loess, kernel) permettent de bien visualiser cette relation. Le package <code>ggplot2</code> et les fonctions <code>ggplot()</code>, <code>geom_point()</code> et <code>geom_smooth()</code> vous permettent de réaliser ce genre de graphique. Le code suivant permet de visualiser la relation entre 2 variables continues (<code>wpc</code> et <code>milk120</code>). En jouant avec l’argument <code>span</code> vous pouvez changer le lissage de la courbe. Une petite valeur produira une courbe qui sautille beaucoup, une plus grande valeur produira une courbe plus lisse.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="régression-linéaire.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb42-2"><a href="régression-linéaire.html#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, <span class="fu">aes</span>(wpc, milk120)) <span class="sc">+</span> <span class="co">#Ici nous avons simplement indiqué le jeu de données, puis les variables d&#39;intérêt</span></span>
<span id="cb42-3"><a href="régression-linéaire.html#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  <span class="co">#Nous demandons d&#39;ajouter le nuage de points (un &#39;scatterplot&#39;)</span></span>
<span id="cb42-4"><a href="régression-linéaire.html#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="dv">2</span>)<span class="sc">+</span> <span class="co">#Nous demandons d&#39;ajouter la courbe lissée de type loess. L&#39;argument span nous permet d&#39;ajuster le lissage </span></span>
<span id="cb42-5"><a href="régression-linéaire.html#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="co">#C&#39;est joli un fond blanc pour les figures (un thème noir et blanc: theme_bw()). C&#39;est futile, mais bon...</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-30"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-30-1.png" alt="Relation entre le nombre de jours jusqu’à la saillie fécondante (wpc) et la production de lait en 120j (milk120) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.2: Relation entre le nombre de jours jusqu’à la saillie fécondante (wpc) et la production de lait en 120j (milk120) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p>Ici, la relation entre <em>wpc</em> et <em>milk120</em> semble être une droite.</p>
</div>
<div id="évaluer-la-linéarité-de-la-relation-à-laide-de-termes-polynomiaux-pour-prédicteur-quantitatif" class="section level3 hasAnchor" number="6.9.2">
<h3><span class="header-section-number">6.9.2</span> Évaluer la linéarité de la relation à l’aide de termes polynomiaux (pour prédicteur quantitatif)<a href="régression-linéaire.html#évaluer-la-linéarité-de-la-relation-à-laide-de-termes-polynomiaux-pour-prédicteur-quantitatif" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Une autre manière d’évaluer la linéarité de la relation entre un prédicteur quantitatif et votre variable dépendante est de vérifier si des termes polynomiaux sont significatifs lorsque ajoutés au modèle. Par exemple, le modèle suivant suppose que la relation entre <em>wpc</em> et <em>milk120</em> est une droite.</p>
<p><span class="math display">\[ milk120 = β_0 + β_1*wpc \]</span></p>
<p>En ajoutant une variable <span class="math inline">\(wpc^2\)</span> au carré à ce modèle, nous permettons maintenant une relation curvilinéaire.</p>
<p><span class="math display">\[ milk120 = β_0 + β_1*wpc + β_2*wpc^2\]</span></p>
<p>Nous pourrions maintenant vérifier si le coefficient du terme <span class="math inline">\(wpc^2\)</span> dans ce dernier modèle est statistiquement significatif. Si ce n’est pas le cas, nous avons alors confirmation que la relation est une droite. Si ce coefficient est statistiquement significatif, nous devons alors conclure à une relation curvilinéaire. Ce serait alors sage de vérifier s’il s’agit d’une simple courbe, ou plutôt d’une courbe avec un ou plusieurs points d’inflexion. Cela peut être fait en ajoutant un terme au cube, comme suit.</p>
<p><span class="math display">\[ milk120 = β_0 + β_*wpc + β_2*wpc^2 + β_3*wpc^3\]</span></p>
<p>Cette fois, nous évaluerons si le coefficent du terme <span class="math inline">\(wpc^3\)</span> est statistiquement significatif. Si ce n’est pas le cas, nous avons alors confirmation que la relation est une simple courbe. Si ce coefficient est statistiquement significatif, nous devons alors conclure à une relation curvilinéaire avec un ou plusieurs points d’inflexion.</p>
<p>Dans <code>R</code>, deux options s’offrent à nous afin de vérifier ces modèles avec des termes polynomiaux. Nous pouvonc évidemment créer manuellement ces nouvelles variables au carré et au cube et les inclure dans le modèle. Cependant, la fonction <code>poly()</code> permet de créer automatiquement ces variables.</p>
<p>Par exemple, en créant manuellement les variables:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="régression-linéaire.html#cb43-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>wpc_sq <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>wpc<span class="sc">*</span>daisy2_mod<span class="sc">$</span>wpc</span>
<span id="cb43-2"><a href="régression-linéaire.html#cb43-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>wpc_cu <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>wpc<span class="sc">*</span>daisy2_mod<span class="sc">$</span>wpc<span class="sc">*</span>daisy2_mod<span class="sc">$</span>wpc</span>
<span id="cb43-3"><a href="régression-linéaire.html#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="régression-linéaire.html#cb43-4" aria-hidden="true" tabindex="-1"></a>modele<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb43-5"><a href="régression-linéaire.html#cb43-5" aria-hidden="true" tabindex="-1"></a>            milk120 <span class="sc">~</span> (wpc <span class="sc">+</span> wpc_sq))</span>
<span id="cb43-6"><a href="régression-linéaire.html#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="régression-linéaire.html#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (wpc + wpc_sq), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2103.49  -480.94     5.16   467.80  2439.52 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.282e+03  4.606e+01  71.266   &lt;2e-16 ***
## wpc         -1.568e+00  1.114e+00  -1.408    0.159    
## wpc_sq       5.518e-03  5.094e-03   1.083    0.279    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 698 on 1533 degrees of freedom
##   (440 observations effacées parce que manquantes)
## Multiple R-squared:  0.001738,   Adjusted R-squared:  0.0004358 
## F-statistic: 1.335 on 2 and 1533 DF,  p-value: 0.2636</code></pre>
<p>Dans ce cas, nous voyons que le terme au carré n’est pas statistiquement significatif (P=0.279). Nous pourrions donc conclure que la relation entre <em>wpc</em> et <em>milk120</em> est une droite. Dans ce cas, c’est alors inutile de vérifier le modèle avec termes au carré et au cube.</p>
<p>Nous pourrions obtenir les mêmes résultats avec la fonction <code>poly()</code>:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="régression-linéaire.html#cb45-1" aria-hidden="true" tabindex="-1"></a>modele<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb45-2"><a href="régression-linéaire.html#cb45-2" aria-hidden="true" tabindex="-1"></a>            milk120 <span class="sc">~</span> (<span class="fu">poly</span>(wpc, </span>
<span id="cb45-3"><a href="régression-linéaire.html#cb45-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">degree=</span><span class="dv">2</span>,  <span class="co">#degree=2 demande le terme principal + celui au carré. Avec degree=3, nous aurions alors les 3 termes</span></span>
<span id="cb45-4"><a href="régression-linéaire.html#cb45-4" aria-hidden="true" tabindex="-1"></a>                            <span class="at">raw=</span><span class="cn">TRUE</span>)))</span>
<span id="cb45-5"><a href="régression-linéaire.html#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="régression-linéaire.html#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (poly(wpc, degree = 2, raw = TRUE)), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2103.49  -480.94     5.16   467.80  2439.52 
## 
## Coefficients:
##                                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                         3.282e+03  4.606e+01  71.266   &lt;2e-16 ***
## poly(wpc, degree = 2, raw = TRUE)1 -1.568e+00  1.114e+00  -1.408    0.159    
## poly(wpc, degree = 2, raw = TRUE)2  5.518e-03  5.094e-03   1.083    0.279    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 698 on 1533 degrees of freedom
##   (440 observations effacées parce que manquantes)
## Multiple R-squared:  0.001738,   Adjusted R-squared:  0.0004358 
## F-statistic: 1.335 on 2 and 1533 DF,  p-value: 0.2636</code></pre>
</div>
<div id="méthodes-diagnostiques-pour-les-résiduels" class="section level3 hasAnchor" number="6.9.3">
<h3><span class="header-section-number">6.9.3</span> Méthodes diagnostiques pour les résiduels<a href="régression-linéaire.html#méthodes-diagnostiques-pour-les-résiduels" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La fonction <code>plot()</code> demande les principaux graphiques qui serviront à évaluer l’adéquation du modèle (i.e. l’homoscédasticité et la normalité des résiduels).<br />
Les plus intéressants sont probablement :<br />
• Le graphique des Résiduels x valeurs prédites (Residual vs Fitted). Ce graphique vous permettra de visualiser si la variance est homogène en fonction des valeurs prédites. On désire une « bande » horizontale égale (semble assez problématique pour cet exemple; la bande va en augmentant)<br />
• Le graphique des quantiles x résiduels (Normal Q-Q) permet d’évaluer la normalité des résiduels. On désire que les points forment une ligne de 45º qui se superpose à la ligne pointillée dans la figure (encore assez problématique dans cet exemple)</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="régression-linéaire.html#cb47-1" aria-hidden="true" tabindex="-1"></a>modele2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb47-2"><a href="régression-linéaire.html#cb47-2" aria-hidden="true" tabindex="-1"></a>              wpc <span class="sc">~</span> (dyst <span class="sc">+</span> parity <span class="sc">+</span> herd_size <span class="sc">+</span> twin)</span>
<span id="cb47-3"><a href="régression-linéaire.html#cb47-3" aria-hidden="true" tabindex="-1"></a>              )</span>
<span id="cb47-4"><a href="régression-linéaire.html#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele2, <span class="dv">1</span>) <span class="co">#Nous demandons la première figure du &#39;pannel plot&#39; de diagnostique (c&#39;est la figure Residual vs Fitted)</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-33"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-33-1.png" alt="Graphique des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.3: Graphique des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="régression-linéaire.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele2, <span class="dv">2</span>) <span class="co">#Nous demandons la 2ième figure du &#39;pannel plot&#39; de diagnostique (c&#39;est la figure Normal Q-Q)</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-34"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-34-1.png" alt="Graphique Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.4: Graphique Q-Q des résiduels.
</p>
</div>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="régression-linéaire.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Alternativement, nous pourrions ne pas spécifier les figures qui nous intéressent et simplement tout demander ainsi:</span></span>
<span id="cb49-2"><a href="régression-linéaire.html#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(modele2)</span></span>
<span id="cb49-3"><a href="régression-linéaire.html#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Vous aurez alors toute la série (n=4) de graphiques</span></span></code></pre></div>
</div>
<div id="évaluation-des-observations-extrêmes-etou-influentes" class="section level3 hasAnchor" number="6.9.4">
<h3><span class="header-section-number">6.9.4</span> Évaluation des observations extrêmes et/ou influentes<a href="régression-linéaire.html#évaluation-des-observations-extrêmes-etou-influentes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Certaines observations peuvent être très différentes des autres et avoir un effet important sur les résultats
de la régression. Cette observation peut être une observation extrême (outlier), c’est-à-dire une observation avec une combinaison inhabituelle de valeurs pour la variable dépendante et les variables indépendantes. Ce peut être une observation avec une valeur extrême pour un prédicteur, que l’on appelle variable à effet levier (leverage). Enfin ce peut être une observation qui, si elle est soustraite à l’analyse, change substantiellement les estimés des coefficients (influence).</p>
<p>Dans <code>R</code>, vous pouvez facilement ajouter dans votre base de données les valeurs prédites par le modèle, les résiduels, les distances de Cook, les leviers, etc avec la fonction <code>augment()</code> du package <code>broom</code>. Vous pourrez ensuite trier cette table pour identifier, par exemple, les observations avec les résiduels, les leviers ou les distances de Cook les plus extrêmes et essayer de comprendre si ces observations ont quelque chose en commun.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="régression-linéaire.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb50-2"><a href="régression-linéaire.html#cb50-2" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(modele2) <span class="co">#Nous avons créé une nouvelle table dans laquelle les résiduels, distance de cook, etc se trouvent maintenant</span></span>
<span id="cb50-3"><a href="régression-linéaire.html#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diag)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 12
##   .rown…¹   wpc  dyst parity herd_…²  twin .fitted .resid    .hat .sigma .cooksd
##   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;  &lt;int&gt;   &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 3          67     0      5     294     0    78.0  -11.0 0.00239   50.4 2.30e-5
## 2 4           9     0      5     294     0    78.0  -69.0 0.00239   50.4 9.01e-4
## 3 5          61     0      5     294     0    78.0  -17.0 0.00239   50.4 5.48e-5
## 4 8         117     0      5     294     0    78.0   39.0 0.00239   50.4 2.87e-4
## 5 9          36     0      6     294     0    79.2  -43.2 0.00397   50.4 5.88e-4
## 6 11         19     0      5     294     0    78.0  -59.0 0.00239   50.4 6.59e-4
## # … with 1 more variable: .std.resid &lt;dbl&gt;, and abbreviated variable names
## #   ¹​.rownames, ²​herd_size</code></pre>
<p>Les nouvelles variables correspondent à:<br />
- Valeur prédite (<em>.fitted</em>)<br />
- Résiduel (<em>.resid</em>)<br />
- Levier (<em>.hat</em>)<br />
- Distance de Cook (<em>.cooksd</em>)<br />
- Résiduel standardisé (<em>.std.resid</em>)</p>
<p>À l’aide de la fonction <code>ggplot</code> vous pourrez alors produire les graphiques qui vous intéressent. Par exemple :</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="régression-linéaire.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diag, </span>
<span id="cb52-2"><a href="régression-linéaire.html#cb52-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x=</span>wpc, </span>
<span id="cb52-3"><a href="régression-linéaire.html#cb52-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">y=</span>.std.resid, </span>
<span id="cb52-4"><a href="régression-linéaire.html#cb52-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">colour=</span>.std.resid)</span>
<span id="cb52-5"><a href="régression-linéaire.html#cb52-5" aria-hidden="true" tabindex="-1"></a>       ) <span class="sc">+</span> <span class="co">#Nous indiquons les variables d&#39;intérêt. Nous nous sommes permis une petite fantaisie ici, nous modifions la couleur des points en fonction de la valeur du résiduel standardisé</span></span>
<span id="cb52-6"><a href="régression-linéaire.html#cb52-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="co">#Nous demandons un graphique nuage de points</span></span>
<span id="cb52-7"><a href="régression-linéaire.html#cb52-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="dv">3</span>)) <span class="sc">+</span> <span class="co">#Une autre fantaisie, ajoutons des barres horizontales qui permettent de marquer les valeurs -3 et +3 (pour identifier les résiduels &#39;extrêmes&#39;)</span></span>
<span id="cb52-8"><a href="régression-linéaire.html#cb52-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="sc">-</span><span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb52-9"><a href="régression-linéaire.html#cb52-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="co">#Le fameux fond blanc!</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-36"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-36-1.png" alt="Graphique des résiduels de Student par jours jusqu’à la saillie fécondante (wpc)." width="672" />
<p class="caption">
Figure 6.5: Graphique des résiduels de Student par jours jusqu’à la saillie fécondante (wpc).
</p>
</div>
<p>Dans ce cas, on voit que seulement les vaches avec un WPC long (&gt; 250j) ont des résiduels larges (i.e. &gt; 3.0 ou &lt; -3.0). Le modèle semble donc avoir de la difficulté à bien prédire ces observations.</p>
</div>
</div>
<div id="travaux-pratiques-1---régression-linéaire---base" class="section level2 hasAnchor" number="6.10">
<h2><span class="header-section-number">6.10</span> Travaux pratiques 1 - Régression linéaire - Base<a href="régression-linéaire.html#travaux-pratiques-1---régression-linéaire---base" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercices" class="section level3 hasAnchor" number="6.10.1">
<h3><span class="header-section-number">6.10.1</span> Exercices<a href="régression-linéaire.html#exercices" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour ce TP utilisez le fichier DAISY2 (voir description VER p.809).</p>
<p><strong>Ne sélectionnez que les 7 troupeaux avec h7=1. </strong></p>
<p><strong>1)</strong> Considérons le <strong>nombre de jours jusqu’à la saillie fécondante (WPC) comme variable dépendante</strong> et vérifions comment différents prédicteurs permettent de prédire cet intervalle.</p>
<p><strong>a.</strong> Représentez graphiquement l’association entre milk120 et WPC. Pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<p><strong>b.</strong> Faites varier le lissage (e.g. 0.1 ou 1) et décrivez comment la courbe lissée change en fonction de ce lissage.</p>
<p><strong>c.</strong> Maintenant, représentez graphiquement la relation entre parity et wpc. Dans ce cas, pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<p><strong>d.</strong> À partir du diagramme de dispersion, il est raisonnable de penser que l’intervalle WPC change linéairement avec parity. Cette relation linéaire peut être exprimée par le modèle <span class="math inline">\(WPC= β_0 + β_1*parity\)</span>. À l’aide d’un modèle de régression linéaire, estimez les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span>. Écrivez l’équation de régression sous la forme donnée ci-dessus, avec ces estimés dans l’équation. Comment interprétez-vous ces estimés ?</p>
<p><strong>e.</strong> Un test de <em>F</em> vous est rapporté pour le modèle de même qu’un test de <em>T</em> pour le coefficient de régression de parity (i.e. <span class="math inline">\(β_1\)</span>). Quelles sont les hypothèses nulles pour chacun de ces tests? Dans ce cas, ces 2 tests sont-ils réellement différents?</p>
<p><strong>f.</strong> Quel serait l’IC95% pour le coefficient de régression de parity?</p>
<p><strong>g.</strong> Existe-t-il une relation linéaire statistiquement significative entre ces 2 variables?</p>
<p><strong>h.</strong> Le nombre de jours jusqu’à la saillie fécondante (WPC) pour une vache de parité zéro n’a, bien sûr, pas de sens biologique. Pour repositionner ce paramètre à la parité minimale observée (i.e. parity=1), on peut remplacer la parité par une nouvelle variable (parity_ct) centrée sur parity=1. Créez cette nouvelle variable et, à l’aide d’un modèle de régression linéaire, estimez les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span> et interprétez les coefficients de régression comme à la question 1.d.</p>
<p><strong>2)</strong> À la question 1.a, nous avons vu que la relation entre milk120 et WPC ne semble pas être linéaire. Nous pourrions donc créer des termes polynomiaux afin de modéliser correctement cette association.</p>
<p><strong>a.</strong> Créez une nouvelle variable milk120_ct centrée sur la production moyenne. Puis créez 1 terme polynomial milk120_ct_sq (i.e. milk120 au carré). Vérifiez si l’ajout d’une courbe (i.e. le terme au carré) ajoute significativement au modèle.</p>
<p><strong>b.</strong> Selon votre analyse graphique réalisée à la question 1.a, pensez-vous que vous auriez besoin d’ajouter d’autres points d’inflexion pour bien représenter cette association? Vérifiez votre réponse en ajoutant un terme au cube pour milk120 en plus du terme au carré.</p>
<p><strong>c.</strong> Dans ce dernier modèle, vérifiez qu’il n’y a pas de problème sévère de colinéarité.</p>
<p><strong>3)</strong> Dans le modèle suivant <span class="math inline">\(wpc = β_0 +β_1*parityct + β_2*twin + β_3*dyst\)</span> vous vous demandez si les problèmes de vêlage (i.e. twin et dyst ensemble) apportent significativement au modèle. Quel test pourriez-vous réaliser afin de répondre à cette question? Quel est le résultat de ce test et votre interprétation de ce résultat?</p>
<p><strong>4)</strong> Recodez maintenant parity afin d’avoir une nouvelle variable catégorique (parity_cat) à 3 niveaux (parity 1, parity 2 et parity ≥3). Vérifiez la relation entre parity_cat et WPC en vous assurant d’avoir parity 1 comme valeur de référence.</p>
<p><strong>a.</strong> Est-ce que parity_cat (comme variable) est significativement associée à WPC?</p>
<p><strong>b.</strong> De combien WPC change pour une vache de 2ième parité comparativement à une vache de 1ère parité?</p>
<p><strong>c.</strong> Quel est le WPC pour une vache de 1ère parité?</p>
<p><strong>d.</strong> Quelle est la différence de WPC entre une vache de 2ième et une de 3ième parité et quel est l’IC 95% ajusté pour comparaisons multiples pour cette différence? Cette différence est-elle statistiquement significative?</p>
<p><strong>5)</strong> Vous supposez que l’effet d’une dystocie (dyst) sur WPC varie en fonction de la parité (catégorique 1ère, 2ième, ou ≥3ième). Par exemple, une vache plus vieille ayant une dystocie aura possiblement un délai plus long jusqu’à la saille fécondante comparativement à une vache plus jeune.</p>
<p><strong>a.</strong> Que devrez-vous tester pour vérifier cette hypothèse?</p>
<p><strong>b.</strong> Effectuez ce test. Est-ce que l’effet de dystocie varie de manière statistiquement significative en fonction de la parité?</p>
<p><strong>c.</strong> Quel est le nombre de jours moyen jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie (i.e. remplir le tableau suivant)? Pour quel niveau de parité les différences semblent les plus importantes?</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-156">Table 6.1: </span>Nombre moyen de jours jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie
</caption>
<thead>
<tr>
<th style="text-align:left;">
Parite
</th>
<th style="text-align:left;">
Dystocie_0
</th>
<th style="text-align:left;">
Dystocie_1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1ère lactation
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
2ième lactation
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
3ième ou plus
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
</div>
<div id="code-r-et-réponses" class="section level3 hasAnchor" number="6.10.2">
<h3><span class="header-section-number">6.10.2</span> Code R et réponses<a href="régression-linéaire.html#code-r-et-réponses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour ce TP utilisez le fichier DAISY2 (voir description VER p.809).<br />
<strong>Ne sélectionnez que les 7 troupeaux avec h7=1. </strong></p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="régression-linéaire.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Ouvrir le jeu de données</span></span>
<span id="cb53-2"><a href="régression-linéaire.html#cb53-2" aria-hidden="true" tabindex="-1"></a>daisy2 <span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;daisy2.csv&quot;</span>, </span>
<span id="cb53-3"><a href="régression-linéaire.html#cb53-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">header=</span><span class="cn">TRUE</span>, </span>
<span id="cb53-4"><a href="régression-linéaire.html#cb53-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">sep=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb53-5"><a href="régression-linéaire.html#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Sélectionner les 7 troupeaux</span></span>
<span id="cb53-6"><a href="régression-linéaire.html#cb53-6" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">subset</span>(daisy2, </span>
<span id="cb53-7"><a href="régression-linéaire.html#cb53-7" aria-hidden="true" tabindex="-1"></a>                   h7<span class="sc">==</span><span class="dv">1</span>)</span></code></pre></div>
<p><strong>1)</strong> Considérons le <strong>nombre de jours jusqu’à la saillie fécondante (WPC) comme variable dépendante</strong> et vérifions comment différents prédicteurs permettent de prédire cet intervalle.</p>
<p><strong>a.</strong> Représentez graphiquement l’association entre milk120 et WPC. Pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="régression-linéaire.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb54-2"><a href="régression-linéaire.html#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, </span>
<span id="cb54-3"><a href="régression-linéaire.html#cb54-3" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(milk120, wpc)</span>
<span id="cb54-4"><a href="régression-linéaire.html#cb54-4" aria-hidden="true" tabindex="-1"></a>       ) <span class="sc">+</span> </span>
<span id="cb54-5"><a href="régression-linéaire.html#cb54-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb54-6"><a href="régression-linéaire.html#cb54-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, </span>
<span id="cb54-7"><a href="régression-linéaire.html#cb54-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">span=</span><span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb54-8"><a href="régression-linéaire.html#cb54-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-158"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-158-1.png" alt="Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.6: Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Non, relation semble légèrement curvilinéaire</p>
<p><strong>b.</strong> Faites varier le lissage (e.g. 0.1 ou 1) et décrivez comment la courbe lissée change en fonction de ce lissage.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="régression-linéaire.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, </span>
<span id="cb55-2"><a href="régression-linéaire.html#cb55-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(milk120, wpc)</span>
<span id="cb55-3"><a href="régression-linéaire.html#cb55-3" aria-hidden="true" tabindex="-1"></a>       ) <span class="sc">+</span> </span>
<span id="cb55-4"><a href="régression-linéaire.html#cb55-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb55-5"><a href="régression-linéaire.html#cb55-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, </span>
<span id="cb55-6"><a href="régression-linéaire.html#cb55-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">span=</span><span class="fl">0.2</span>) <span class="sc">+</span> </span>
<span id="cb55-7"><a href="régression-linéaire.html#cb55-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-159"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-159-1.png" alt="Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 0.2." width="672" />
<p class="caption">
Figure 6.7: Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 0.2.
</p>
</div>
<p><strong>Réponse:</strong> Lorsqu’on réduit le <code>span</code>, la courbe permet de visualiser toutes les petites variations. Elle devient plus droite (i.e. moins sensible aux variations locales) lorsque le <code>span</code> augmente.</p>
<p><strong>c.</strong> Maintenant, représentez graphiquement la relation entre parity et wpc. Dans ce cas, pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="régression-linéaire.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, </span>
<span id="cb56-2"><a href="régression-linéaire.html#cb56-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(parity, wpc)</span>
<span id="cb56-3"><a href="régression-linéaire.html#cb56-3" aria-hidden="true" tabindex="-1"></a>       ) <span class="sc">+</span> </span>
<span id="cb56-4"><a href="régression-linéaire.html#cb56-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb56-5"><a href="régression-linéaire.html#cb56-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, </span>
<span id="cb56-6"><a href="régression-linéaire.html#cb56-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">span=</span><span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb56-7"><a href="régression-linéaire.html#cb56-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-160"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-160-1.png" alt="Relation entre parité (parity) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.8: Relation entre parité (parity) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Oui, semble mieux</p>
<p><strong>d.</strong> À partir du diagramme de dispersion, il est raisonnable de penser que l’intervalle WPC change linéairement avec parity. Cette relation linéaire peut être exprimée par le modèle <span class="math inline">\(WPC= β_0 + β_1*parity\)</span>. À l’aide d’un modèle de régression linéaire, estimez les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span>. Écrivez l’équation de régression sous la forme donnée ci-dessus, avec ces estimés dans l’équation. Comment interprétez-vous ces estimés ?</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="régression-linéaire.html#cb57-1" aria-hidden="true" tabindex="-1"></a>modele1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb57-2"><a href="régression-linéaire.html#cb57-2" aria-hidden="true" tabindex="-1"></a>            wpc <span class="sc">~</span> (parity)</span>
<span id="cb57-3"><a href="régression-linéaire.html#cb57-3" aria-hidden="true" tabindex="-1"></a>            ) </span>
<span id="cb57-4"><a href="régression-linéaire.html#cb57-4" aria-hidden="true" tabindex="-1"></a>modele1 </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (parity), data = daisy2_mod)
## 
## Coefficients:
## (Intercept)       parity  
##      65.218        1.312</code></pre>
<p><strong>Réponse:</strong> <span class="math inline">\(WPC= 65.2 + 1.3*parity\)</span><br />
Intervalle WPC moyen quand parité=0 est de 65.2j. On ajoute ensuite 1.3 jours à chaque fois qu’on ajoute une parité.</p>
<p><strong>e.</strong> Un test de <em>F</em> vous est rapporté pour le modèle de même qu’un test de <em>T</em> pour le coefficient de régression de parity (i.e. <span class="math inline">\(β_1\)</span>). Quelles sont les hypothèses nulles pour chacun de ces tests? Dans ce cas, ces 2 tests sont-ils réellement différents?</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="régression-linéaire.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (parity), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -67.47 -38.47 -15.15  24.16 227.53 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  65.2181     2.7090  24.075   &lt;2e-16 ***
## parity        1.3118     0.8706   1.507    0.132    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.58 on 1572 degrees of freedom
##   (402 observations effacées parce que manquantes)
## Multiple R-squared:  0.001442,   Adjusted R-squared:  0.000807 
## F-statistic: 2.271 on 1 and 1572 DF,  p-value: 0.1321</code></pre>
<p><strong>Réponse:</strong> Test de <em>F</em> (<em>P</em>=0.132): tous les coefficients (outre <span class="math inline">\(β_0\)</span>, l’intercept) = 0<br />
Test de <em>T</em> (aussi <em>P</em>=0.132): le coefficient de parity (<span class="math inline">\(β_1\)</span>) = 0<br />
Non, puisqu’il y a un seul coefficient de régression dans l’équation les 2 tests sont équivalents.</p>
<p><strong>f.</strong> Quel serait l’IC95% pour le coefficient de régression de parity?</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="régression-linéaire.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(modele1)</span></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) 59.9045164 70.531662
## parity      -0.3958026  3.019367</code></pre>
<p><strong>Réponse:</strong> -0.4 à 3.0 jours</p>
<p><strong>g.</strong> Existe-t-il une relation linéaire statistiquement significative entre ces 2 variables?<br />
<strong>Réponse:</strong> Non (<em>P</em>=0.13 et l’<em>IC95%</em> inclus la valeur 0)</p>
<p><strong>h.</strong> Le nombre de jours jusqu’à la saillie fécondante (WPC) pour une vache de parité zéro n’a, bien sûr, pas de sens biologique. Pour repositionner ce paramètre à la parité minimale observée (i.e. parity=1), on peut remplacer la parité par une nouvelle variable (parity_ct) centrée sur parity=1. Créez cette nouvelle variable et, à l’aide d’un modèle de régression linéaire, estimez les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span> et interprétez les coefficients de régression comme à la question 1.d.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="régression-linéaire.html#cb63-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>parity<span class="dv">-1</span></span>
<span id="cb63-2"><a href="régression-linéaire.html#cb63-2" aria-hidden="true" tabindex="-1"></a>modele2<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb63-3"><a href="régression-linéaire.html#cb63-3" aria-hidden="true" tabindex="-1"></a>            wpc <span class="sc">~</span> (par_ct)</span>
<span id="cb63-4"><a href="régression-linéaire.html#cb63-4" aria-hidden="true" tabindex="-1"></a>            ) </span>
<span id="cb63-5"><a href="régression-linéaire.html#cb63-5" aria-hidden="true" tabindex="-1"></a>modele2</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (par_ct), data = daisy2_mod)
## 
## Coefficients:
## (Intercept)       par_ct  
##      66.530        1.312</code></pre>
<p><strong>Réponse:</strong> Intervalle <em>wpc</em> moyen quand parité=1 est de 66.5j. On ajoute ensuite 1.3 jours à chaque fois qu’on ajoute une parité.</p>
<p><strong>2)</strong> À la question 1.a, nous avons vu que la relation entre milk120 et WPC ne semble pas être linéaire. Nous pourrions donc créer des termes polynomiaux afin de modéliser correctement cette association.</p>
<p><strong>a.</strong> Créez une nouvelle variable milk120_ct centrée sur la production moyenne. Puis créez 1 terme polynomial milk120_ct_sq (i.e. milk120 au carré). Vérifiez si l’ajout d’une courbe (i.e. le terme au carré) ajoute significativement au modèle.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="régression-linéaire.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions d&#39;abord quelle est la moyenne de milk120</span></span>
<span id="cb65-2"><a href="régression-linéaire.html#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(daisy2_mod<span class="sc">$</span>milk120, </span>
<span id="cb65-3"><a href="régression-linéaire.html#cb65-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 3225.311</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="régression-linéaire.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous créons ensuite la variable centrée sur 3225 et celle au carré</span></span>
<span id="cb67-2"><a href="régression-linéaire.html#cb67-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>milk120_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>milk120<span class="dv">-3225</span></span>
<span id="cb67-3"><a href="régression-linéaire.html#cb67-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>milk120_ct_sq <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>milk120_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>milk120_ct</span>
<span id="cb67-4"><a href="régression-linéaire.html#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions que ça a bien fonctionné</span></span>
<span id="cb67-5"><a href="régression-linéaire.html#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(daisy2_mod)</span></code></pre></div>
<pre><code>##   region herd cow study_lact herd_size mwp parity milk120    calv_dt cf fs cc
## 1      1    1   1          1       294  26      5  3505.8 1996-11-11 80 NA NA
## 2      1    1   2          1       294  26      5  3691.3 1997-01-12 64 NA NA
## 3      1    1   3          1       294  26      5  4173.0 1997-01-17 71  0 93
## 4      1    1   4          1       294  26      5  3727.3 1997-02-11 35  1 35
## 5      1    1   5          1       294  26      5  3090.8 1997-06-26 47  0 87
## 6      1    1   6          1       294  26      4  5041.2 1996-10-16 NA NA NA
##   wpc spc twin dyst rp vag_disch h7 par_ct milk120_ct milk120_ct_sq
## 1  NA   6    0    0  0         0  1      4      280.8      78848.67
## 2  NA   3    0    0  0         0  1      4      466.3     217435.74
## 3  67   2    0    0  0         0  1      4      948.0     898704.00
## 4   9   1    0    0  0         0  1      4      502.3     252305.34
## 5  61   2    0    0  0         0  1      4     -134.2      18009.63
## 6  NA  NA    0    0  1         0  1      3     1816.2    3298583.15</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="régression-linéaire.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions le modèle avec les termes polynomiaux</span></span>
<span id="cb69-2"><a href="régression-linéaire.html#cb69-2" aria-hidden="true" tabindex="-1"></a>modele3<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb69-3"><a href="régression-linéaire.html#cb69-3" aria-hidden="true" tabindex="-1"></a>            wpc <span class="sc">~</span> (milk120_ct<span class="sc">+</span>milk120_ct_sq)</span>
<span id="cb69-4"><a href="régression-linéaire.html#cb69-4" aria-hidden="true" tabindex="-1"></a>            ) </span>
<span id="cb69-5"><a href="régression-linéaire.html#cb69-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (milk120_ct + milk120_ct_sq), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -66.34 -38.70 -15.26  25.28 222.44 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    6.697e+01  1.639e+00  40.856   &lt;2e-16 ***
## milk120_ct    -2.545e-03  1.892e-03  -1.345   0.1787    
## milk120_ct_sq  4.089e-06  1.998e-06   2.046   0.0409 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.65 on 1533 degrees of freedom
##   (440 observations effacées parce que manquantes)
## Multiple R-squared:  0.003696,   Adjusted R-squared:  0.002396 
## F-statistic: 2.843 on 2 and 1533 DF,  p-value: 0.05854</code></pre>
<p><strong>Réponse:</strong> Oui, le terme au carré est significativement associé (i.e. <em>P</em> = 0.04) à wpc. Donc le terme représentant la courbe à un coefficient différent de 0.</p>
<p><strong>b.</strong> Selon votre analyse graphique réalisée à la question 1.a, pensez-vous que vous auriez besoin d’ajouter d’autres points d’inflexion pour bien représenter cette association? Vérifiez votre réponse en ajoutant un terme au cube pour milk120 en plus du terme au carré.</p>
<p><strong>Réponse:</strong> <em>a priori</em>, ça semblait être une simple courbe.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="régression-linéaire.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous créons une variable milk120 à la puissance 3</span></span>
<span id="cb71-2"><a href="régression-linéaire.html#cb71-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>milk120_ct_cu <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>milk120_ct_sq<span class="sc">*</span>daisy2_mod<span class="sc">$</span>milk120_ct</span>
<span id="cb71-3"><a href="régression-linéaire.html#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous l&#39;ajoutons au modèle</span></span>
<span id="cb71-4"><a href="régression-linéaire.html#cb71-4" aria-hidden="true" tabindex="-1"></a>modele4<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb71-5"><a href="régression-linéaire.html#cb71-5" aria-hidden="true" tabindex="-1"></a>            wpc <span class="sc">~</span> (milk120_ct<span class="sc">+</span>milk120_ct_sq<span class="sc">+</span>milk120_ct_cu)</span>
<span id="cb71-6"><a href="régression-linéaire.html#cb71-6" aria-hidden="true" tabindex="-1"></a>            ) </span>
<span id="cb71-7"><a href="régression-linéaire.html#cb71-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (milk120_ct + milk120_ct_sq + milk120_ct_cu), 
##     data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -68.71 -38.40 -15.64  25.59 223.22 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    6.724e+01  1.650e+00  40.761   &lt;2e-16 ***
## milk120_ct    -6.171e-03  3.163e-03  -1.951   0.0513 .  
## milk120_ct_sq  3.330e-06  2.067e-06   1.611   0.1073    
## milk120_ct_cu  2.651e-09  1.854e-09   1.430   0.1530    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.63 on 1532 degrees of freedom
##   (440 observations effacées parce que manquantes)
## Multiple R-squared:  0.005023,   Adjusted R-squared:  0.003075 
## F-statistic: 2.578 on 3 and 1532 DF,  p-value: 0.05222</code></pre>
<p>Effectivement, on obtient <em>P</em>=0.15 pour le terme au cube (i.e. n’ajoute rien au modèle).</p>
<p><strong>c.</strong> Dans ce dernier modèle, vérifiez qu’il n’y a pas de problème sévère de colinéarité.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="régression-linéaire.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb73-2"><a href="régression-linéaire.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(modele4)</span></code></pre></div>
<pre><code>##    milk120_ct milk120_ct_sq milk120_ct_cu 
##      2.808468      1.074436      2.918711</code></pre>
<p><strong>Réponse:</strong> Les VIF sont tous &lt; 10, donc pas de problème.</p>
<p><strong>3)</strong> Dans le modèle suivant <span class="math inline">\(wpc = β_0 +β_1*parityct + β_2*twin + β_3*dyst\)</span> vous vous demandez si les problèmes de vêlage (i.e. twin et dyst ensemble) apportent significativement au modèle. Quel test pourriez-vous réaliser afin de répondre à cette question? Quel est le résultat de ce test et votre interprétation de ce résultat?</p>
<p><strong>Réponse:</strong> Test de <em>F</em> pour comparer modèle complet (i.e. parity_ct, twin et dyst) vs. modèle réduit (i.e. parity_ct).</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="régression-linéaire.html#cb75-1" aria-hidden="true" tabindex="-1"></a>modele_complet <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod,</span>
<span id="cb75-2"><a href="régression-linéaire.html#cb75-2" aria-hidden="true" tabindex="-1"></a>                     wpc <span class="sc">~</span> (par_ct<span class="sc">+</span>twin<span class="sc">+</span>dyst)</span>
<span id="cb75-3"><a href="régression-linéaire.html#cb75-3" aria-hidden="true" tabindex="-1"></a>                     )</span>
<span id="cb75-4"><a href="régression-linéaire.html#cb75-4" aria-hidden="true" tabindex="-1"></a>modele_reduit <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb75-5"><a href="régression-linéaire.html#cb75-5" aria-hidden="true" tabindex="-1"></a>                    wpc <span class="sc">~</span> (par_ct)</span>
<span id="cb75-6"><a href="régression-linéaire.html#cb75-6" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb75-7"><a href="régression-linéaire.html#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele_complet, </span>
<span id="cb75-8"><a href="régression-linéaire.html#cb75-8" aria-hidden="true" tabindex="-1"></a>      modele_reduit)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wpc ~ (par_ct + twin + dyst)
## Model 2: wpc ~ (par_ct)
##   Res.Df     RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1   1570 4167004                              
## 2   1572 4182050 -2    -15046 2.8345 0.05905 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><em>P</em> =0.06, donc ces variables, ensemble, n’apportent pas au modèle (i.e. les coefficients de régression ne sont pas différents de 0).</p>
<p><strong>4)</strong> Recodez maintenant parity afin d’avoir une nouvelle variable catégorique (parity_cat) à 3 niveaux (parity 1, parity 2 et parity ≥3). Vérifiez la relation entre parity_cat et WPC en vous assurant d’avoir parity 1 comme valeur de référence.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="régression-linéaire.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous créons une variable parity catégorique:</span></span>
<span id="cb77-2"><a href="régression-linéaire.html#cb77-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_cat <span class="ot">&lt;-</span> <span class="fu">cut</span>(daisy2_mod<span class="sc">$</span>parity, </span>
<span id="cb77-3"><a href="régression-linéaire.html#cb77-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="cn">Inf</span>), </span>
<span id="cb77-4"><a href="régression-linéaire.html#cb77-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;First&quot;</span>, <span class="st">&quot;Second&quot;</span>, <span class="st">&quot;Third or more&quot;</span>)</span>
<span id="cb77-5"><a href="régression-linéaire.html#cb77-5" aria-hidden="true" tabindex="-1"></a>                          )</span>
<span id="cb77-6"><a href="régression-linéaire.html#cb77-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous fixons le niveau de référence et l&#39;ajoutons au modèle</span></span>
<span id="cb77-7"><a href="régression-linéaire.html#cb77-7" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">within</span>(daisy2_mod, </span>
<span id="cb77-8"><a href="régression-linéaire.html#cb77-8" aria-hidden="true" tabindex="-1"></a>                   par_cat <span class="ot">&lt;-</span> <span class="fu">relevel</span>(par_cat, </span>
<span id="cb77-9"><a href="régression-linéaire.html#cb77-9" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">ref=</span><span class="st">&quot;First&quot;</span>)) <span class="co">#Sélection de la valeur de référence par_cat=1</span></span>
<span id="cb77-10"><a href="régression-linéaire.html#cb77-10" aria-hidden="true" tabindex="-1"></a>modele5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb77-11"><a href="régression-linéaire.html#cb77-11" aria-hidden="true" tabindex="-1"></a>              wpc <span class="sc">~</span> (par_cat)</span>
<span id="cb77-12"><a href="régression-linéaire.html#cb77-12" aria-hidden="true" tabindex="-1"></a>              )</span>
<span id="cb77-13"><a href="régression-linéaire.html#cb77-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (par_cat), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -67.54 -38.21 -15.54  24.46 227.46 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           66.9520     2.5270  26.495   &lt;2e-16 ***
## par_catSecond          0.2592     3.6750   0.071    0.944    
## par_catThird or more   3.5895     3.1284   1.147    0.251    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.6 on 1571 degrees of freedom
##   (402 observations effacées parce que manquantes)
## Multiple R-squared:  0.001132,   Adjusted R-squared:  -0.0001392 
## F-statistic: 0.8905 on 2 and 1571 DF,  p-value: 0.4106</code></pre>
<p><strong>a.</strong> Est-ce que parity_cat (comme variable) est significativement associée à WPC?<br />
<strong>Réponse:</strong> Non, le test de <em>F</em> qui teste tous les coefficients ensemble donne <em>P</em>=0.41</p>
<p><strong>b.</strong> De combien WPC change pour une vache de 2ième parité comparativement à une vache de 1ère parité?<br />
<strong>Réponse:</strong> +0.3 jours</p>
<p><strong>c.</strong> Quel est le WPC pour une vache de 1ère parité?<br />
<strong>Réponse:</strong> 67.0 jours</p>
<p><strong>d.</strong> Quelle est la différence de WPC entre une 2ième et une 3ième parité et quel est l’IC 95% ajusté pour comparaisons multiples pour cette différence? Cette différence est-elle statistiquement significative?</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="régression-linéaire.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb79-2"><a href="régression-linéaire.html#cb79-2" aria-hidden="true" tabindex="-1"></a>contrast <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(modele5, </span>
<span id="cb79-3"><a href="régression-linéaire.html#cb79-3" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;par_cat&quot;</span>) <span class="co">#Ici nous créons un objet nommé contrast qui contient les éléments dont nous aurons besoin pour comparer les catégories de par_cat</span></span>
<span id="cb79-4"><a href="régression-linéaire.html#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(contrast) <span class="co">#Nous demandons ensuite de comparer les différentes catégories. </span></span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df t.ratio p.value
##  First - Second           -0.259 3.68 1571  -0.071  0.9973
##  First - Third or more    -3.589 3.13 1571  -1.147  0.4850
##  Second - Third or more   -3.330 3.24 1571  -1.027  0.5601
## 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="régression-linéaire.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Pour voir les intervalles de confiance, nous pourrons demander un confint() sur cette fonction pairs()</span></span>
<span id="cb81-2"><a href="régression-linéaire.html#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">pairs</span>(contrast))</span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df lower.CL upper.CL
##  First - Second           -0.259 3.68 1571    -8.88     8.36
##  First - Third or more    -3.589 3.13 1571   -10.93     3.75
##  Second - Third or more   -3.330 3.24 1571   -10.94     4.28
## 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p><strong>Réponse:</strong> 3.3 jours de plus pour une 3ième parité (<em>vs</em>. 2ième). <em>IC95</em>: -4.3 à 10.9 jours de plus. Ce n’est pas une différence statistiquement significative (la valeur zéro est incluse dans l’<em>IC95</em>).</p>
<p><strong>5)</strong> Vous supposez que l’effet d’une dystocie (dyst) sur WPC varie en fonction de la parité (catégorique 1ère, 2ième, ou ≥3ième). Par exemple, une vache plus vieille ayant une dystocie aura possiblement un délai plus long jusqu’à la saille fécondante comparativement à une vache plus jeune.</p>
<p><strong>a.</strong> Que devrez-vous tester pour vérifier cette hypothèse?<br />
<strong>Réponse:</strong> L’interaction entre <em>dyst</em> et <em>par_cat</em>.</p>
<p><strong>b.</strong> Effectuez ce test. Est-ce que l’effet de dystocie varie de manière statistiquement significative en fonction de la parité?</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="régression-linéaire.html#cb83-1" aria-hidden="true" tabindex="-1"></a>modele6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb83-2"><a href="régression-linéaire.html#cb83-2" aria-hidden="true" tabindex="-1"></a>              wpc <span class="sc">~</span> (par_cat<span class="sc">*</span>dyst)</span>
<span id="cb83-3"><a href="régression-linéaire.html#cb83-3" aria-hidden="true" tabindex="-1"></a>              )</span>
<span id="cb83-4"><a href="régression-linéaire.html#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele6)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (par_cat * dyst), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -84.00 -37.65 -15.47  24.53 228.35 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                67.0249     2.7110  24.724   &lt;2e-16 ***
## par_catSecond               0.4429     3.8446   0.115   0.9083    
## par_catThird or more        2.6221     3.2911   0.797   0.4257    
## dyst                       -0.5428     7.3977  -0.073   0.9415    
## par_catSecond:dyst         -5.1015    14.7724  -0.345   0.7299    
## par_catThird or more:dyst  33.8958    13.5848   2.495   0.0127 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.51 on 1568 degrees of freedom
##   (402 observations effacées parce que manquantes)
## Multiple R-squared:  0.006688,   Adjusted R-squared:  0.00352 
## F-statistic: 2.111 on 5 and 1568 DF,  p-value: 0.0615</code></pre>
<p><strong>Réponse:</strong> Notez que nous avons maintenant 2 coefficients (<em>par_catSecond:dyst</em> et <em>par_catThird or more:dyst</em>) qui, ensemble, représentent l’interaction entre <em>par_cat</em> et <em>dyst</em>. Nous devons donc faire un test de <em>F</em> sur ces 2 coefficients à la fois.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="régression-linéaire.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle réduit sans les deux coefficients:</span></span>
<span id="cb85-2"><a href="régression-linéaire.html#cb85-2" aria-hidden="true" tabindex="-1"></a>modele_red <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb85-3"><a href="régression-linéaire.html#cb85-3" aria-hidden="true" tabindex="-1"></a>                 wpc <span class="sc">~</span> (par_cat<span class="sc">+</span>dyst)</span>
<span id="cb85-4"><a href="régression-linéaire.html#cb85-4" aria-hidden="true" tabindex="-1"></a>                 )</span>
<span id="cb85-5"><a href="régression-linéaire.html#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="co">#La fonction anova() pour comparer les modèles:</span></span>
<span id="cb85-6"><a href="régression-linéaire.html#cb85-6" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele6, </span>
<span id="cb85-7"><a href="régression-linéaire.html#cb85-7" aria-hidden="true" tabindex="-1"></a>      modele_red)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wpc ~ (par_cat * dyst)
## Model 2: wpc ~ (par_cat + dyst)
##   Res.Df     RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1   1568 4160082                              
## 2   1570 4179615 -2    -19533 3.6812 0.02541 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Oui l’interaction est significative, nous obtenons une valeur de <em>P</em>=0.03 pour le test de <em>F</em>.</p>
<p><strong>c.</strong> Quel est le nombre de jours moyen jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie (i.e. remplir le tableau suivant)? Pour quel niveau de parité les différences semblent les plus importantes?</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-176">Table 6.2: </span>Nombre moyen de jours jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie
</caption>
<thead>
<tr>
<th style="text-align:left;">
Parite
</th>
<th style="text-align:left;">
Dystocie_0
</th>
<th style="text-align:left;">
Dystocie_1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1ère lactation
</td>
<td style="text-align:left;">
67.0 jours
</td>
<td style="text-align:left;">
67.0-0.5=66.5 jours
</td>
</tr>
<tr>
<td style="text-align:left;">
2ième lactation
</td>
<td style="text-align:left;">
67.0+0.4=67.4 jours
</td>
<td style="text-align:left;">
67.0+0.4-0.5-5.1=61.8 jours
</td>
</tr>
<tr>
<td style="text-align:left;">
3ième ou plus
</td>
<td style="text-align:left;">
67.0+2.6=69.6 jours
</td>
<td style="text-align:left;">
67.0+2.6-0.5+33.9=103.0 jours
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="travaux-pratiques-2---régression-linéaire---évaluation-du-modèle" class="section level2 hasAnchor" number="6.11">
<h2><span class="header-section-number">6.11</span> Travaux pratiques 2 - Régression linéaire - Évaluation du modèle<a href="régression-linéaire.html#travaux-pratiques-2---régression-linéaire---évaluation-du-modèle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercices-1" class="section level3 hasAnchor" number="6.11.1">
<h3><span class="header-section-number">6.11.1</span> Exercices<a href="régression-linéaire.html#exercices-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour ce TP utilisez le fichier DAISY2 (voir description VER p.809).</p>
<p><strong>Ne sélectionnez que les 7 troupeaux avec h7=1. </strong></p>
<p>Nous nous intéresserons d’abord au modèle suivant qui permet d’évaluer l’effet de dystocie (<em>dyst</em>) sur le nombre de jours jusqu’à la saillie fécondante (<em>WPC</em>). Cette association est ajustée pour 3 facteurs confondants (<em>parity</em>, <em>herd_size</em> et <em>twin</em>). Un des confondants (<em>herd_size</em>) n’a pas une relation linéaire avec WPC. Cette relation a donc dû être modélisée avec l’ajout d’un terme quadratique. Finalement, l’interaction entre dystocie et parité est également d’intérêt.</p>
<p><span class="math inline">\(wpc = β_0 +β_1*dyst + β_2*parity + β_3*dyst*parity + β_4*herdsize + β_5*herdsize^2 + β_6*twin\)</span></p>
<p><strong>1)</strong> D’abord vous pourriez créer les nouvelles variables centrées et quadratiques qui seront utilisées dans ce modèle.</p>
<p><span class="math inline">\(Parity\)</span> pourrait être centrée sur une première lactation.<br />
<span class="math inline">\(Herdsize\)</span> pourrait être centré sur 250 vaches.<br />
<span class="math inline">\(Herdsize^2\)</span> sera, en fait, votre variable <em>herd_size</em> centrée et mise au carré.</p>
<p>Maintenant, estimez ce modèle à l’aide de la fonction <code>lm</code> et évaluez d’abord graphiquement les suppositions de normalité des résiduels (i.e. l’histogramme des résiduels et le Q-Q plot) et d’homoscédasticité de la variance (i.e. les résiduels x valeurs prédites). Quelles sont vos conclusions ? Notez qu’un simple histogramme de <em>WPC</em> vous aurait possiblement aussi indiqué les problèmes potentiels avec la variable <em>WPC</em>.</p>
<p><strong>2)</strong> Afin d’améliorer les suppositions du modèle (i.e. normalité des résiduels et homoscédasticité), vous pourriez tenter de transformer <em>WPC</em>. Essayez les transformations suivantes et utilisez les comme variables dépendantes dans votre modèle à la place de <em>WPC</em>. Dans quels cas les suppositions de normalité et d’homoscédasticité sont améliorées et quelle transformation préféreriez-vous utiliser?</p>
<ol style="list-style-type: lower-alpha">
<li>Le log naturel de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<ol start="2" style="list-style-type: lower-alpha">
<li>L’inverse de <em>WPC</em> (1/<em>WPC</em>)<br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<ol start="3" style="list-style-type: lower-alpha">
<li>La racine carrée de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<p><strong>3)</strong> Outre l’amélioration des suppositions du modèle, est-ce que la transformation par le logarithme naturel pourrait vous offrir d’autres avantages comparativement, par exemple, à la transformation par la racine carrée?</p>
<p><strong>4)</strong> Vous décidez donc de continuer à travailler avec le logarithme naturel de <em>WPC</em>. Rappelez-vous que lorsque vous aviez évalué la relation entre <em>herd_size</em> et <em>WPC</em>, cette relation semblait curvilinéaire. Est-ce que cela implique que la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em> est également curvilinéaire ?</p>
<p><strong>5)</strong> Évaluez graphiquement et à l’aide de termes quadratique et cubique la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em>. Avez-vous besoin d’inclure un terme au carré ? Un terme au cube ?</p>
<p><strong>6)</strong> Dans votre modèle avec le logarithme naturel de <em>WPC</em>, et <em>herd_size</em> modélisé avec les termes polynomiaux appropriés, est-ce que l’interaction entre <em>dyst</em> et <em>parity</em> est toujours statistiquement significative ?</p>
<p><strong>7)</strong> Si l’interaction n’est plus statistiquement significative cela signifie que:</p>
<ol style="list-style-type: lower-alpha">
<li>L’effet de dystocie ne varie pas en fonction de la parité<br />
</li>
<li>Le terme d’interaction n’est pas nécessaire dans le modèle<br />
</li>
<li>Le coefficient de régression pour le terme d’interaction n’est pas différent de zéro<br />
</li>
<li>Toutes ces réponses</li>
</ol>
<p><strong>8)</strong> Comme vous avez pu le noter, transformer la variable dépendante vous oblige à revoir pratiquement tout votre modèle de A à Z. Mais bon, votre modèle final pourrait donc être :</p>
<p><span class="math inline">\(log(wpc) = β_0 +β_1*dyst + β_2*parity_c + β_3*herdsize _c + β_4*herdsize_c^2 + β_5*twin\)</span></p>
<p>Évaluez une dernière fois les suppositions de normalité des résiduels et d’homoscédasticité (puisque vous ne l’avez pas encore fait pour ce modèle sans l’interaction <span class="math inline">\(dyst*parity\)</span>) et calculez dans une nouvelle table les valeurs prédites, les résiduels de Student, les leviers et les distances de Cook.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Combien d’observations ont des résiduels larges (résiduels de Student &gt; 3.0 ou &lt; -3.0)? Ont-elles quelque chose en commun en ce qui a trait à leurs valeurs de <em>WPC</em>, <em>dyst</em>, <em>parity</em>, <em>herd_size</em> ou <em>twin</em>?</p></li>
<li><p>Vous pourriez représenter graphiquement les résiduels de Student en fonction de <em>WPC</em> pour mieux visualiser où se situent ses résiduels larges. Quel genre d’observations (en termes de <em>WPC</em>) le modèle semble avoir de la difficulté à prédire?</p></li>
<li><p>Évaluez maintenant les 5 ou 10 observations avec les leviers les plus élevés. Encore une fois, ont-elles quelque chose en commun?</p></li>
<li><p>Les observations avec des résiduels ou des leviers larges (ou les deux) sont des observations qui peuvent potentiellement influencer le modèle de régression. Les distances de Cook nous permettront d’identifier quelles observations avaient effectivement une influence sur le modèle. Évaluez donc maintenant les 5 ou 10 observations avec les distances de Cook les plus élevées. Ont-elles quelque chose en commun ?</p></li>
<li><p>Vérifiez maintenant jusqu’à quel point ces observations influencent vos résultats en calculant de nouveau votre modèle mais sans les observations avec les distance de Cook les plus élevées (e.g. les 7 observations avec les distances de Cook &gt; 0.010). Est-ce que les conclusions des tests de <em>F</em> ou de <em>T</em> changent comparativement au modèle calculé au début de la question 8? Est-ce que les estimés obtenus changent beaucoup ? Pour quel paramètre l’estimé semble être le plus affecté ? Est-ce en accord avec votre réponse à la question 8.d. ?</p></li>
</ol>
</div>
<div id="code-r-et-réponses-1" class="section level3 hasAnchor" number="6.11.2">
<h3><span class="header-section-number">6.11.2</span> Code R et réponses<a href="régression-linéaire.html#code-r-et-réponses-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>1)</strong> D’abord vous pourriez créer les nouvelles variables centrées et quadratiques qui seront utilisées dans ce modèle. Maintenant, estimez ce modèle à l’aide de la fonction <code>lm</code> et évaluez d’abord graphiquement les suppositions de normalité des résiduels (i.e. l’histogramme des résiduels et le Q-Q plot) et d’homoscédasticité de la variance (i.e. les résiduels x valeurs prédites). Quelles sont vos conclusions? Notez qu’un simple histogramme de <em>WPC</em> vous aurait possiblement aussi indiqué les problèmes potentiels avec la variable <em>WPC</em>.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="régression-linéaire.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Ouvrir le jeu de données</span></span>
<span id="cb87-2"><a href="régression-linéaire.html#cb87-2" aria-hidden="true" tabindex="-1"></a>daisy2 <span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;daisy2.csv&quot;</span>, </span>
<span id="cb87-3"><a href="régression-linéaire.html#cb87-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">header=</span><span class="cn">TRUE</span>, </span>
<span id="cb87-4"><a href="régression-linéaire.html#cb87-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">sep=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb87-5"><a href="régression-linéaire.html#cb87-5" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">subset</span>(daisy2, </span>
<span id="cb87-6"><a href="régression-linéaire.html#cb87-6" aria-hidden="true" tabindex="-1"></a>                   h7<span class="sc">==</span><span class="dv">1</span>)</span>
<span id="cb87-7"><a href="régression-linéaire.html#cb87-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-8"><a href="régression-linéaire.html#cb87-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous génèrons les nouvelles variables</span></span>
<span id="cb87-9"><a href="régression-linéaire.html#cb87-9" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>parity<span class="dv">-1</span></span>
<span id="cb87-10"><a href="régression-linéaire.html#cb87-10" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>herd_size<span class="dv">-250</span></span>
<span id="cb87-11"><a href="régression-linéaire.html#cb87-11" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct_sq <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>herd_size_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct</span>
<span id="cb87-12"><a href="régression-linéaire.html#cb87-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-13"><a href="régression-linéaire.html#cb87-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle</span></span>
<span id="cb87-14"><a href="régression-linéaire.html#cb87-14" aria-hidden="true" tabindex="-1"></a>modele1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb87-15"><a href="régression-linéaire.html#cb87-15" aria-hidden="true" tabindex="-1"></a>            wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin)</span>
<span id="cb87-16"><a href="régression-linéaire.html#cb87-16" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb87-17"><a href="régression-linéaire.html#cb87-17" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele1, <span class="dv">2</span>) <span class="co">#Nous demandons la 2e figure Normal Q-Q</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-178"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-178-1.png" alt="Graphique Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.9: Graphique Q-Q des résiduels.
</p>
</div>
<p><strong>Réponse:</strong> La normalité des résiduels est problématique</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="régression-linéaire.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele1, <span class="dv">1</span>) <span class="co">#Nous demandons la figure Residual vs Fitted</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-179"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-179-1.png" alt="Graphique des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.10: Graphique des résiduels x valeurs prédites.
</p>
</div>
<p><strong>Réponse:</strong> Il semble aussi y avoir un problème d’hétéroscédascticité (<em>i.e.</em> la variance augmente avec l’augmentation des valeurs prédites).</p>
<p><strong>2)</strong> Afin d’améliorer les suppositions du modèle (i.e. normalité des résiduels et homoscédasticité), vous pourriez tenter de transformer <em>WPC</em>. Essayez les transformations suivantes et utilisez les comme variables dépendantes dans votre modèle à la place de <em>WPC</em>. Dans quels cas les suppositions de normalité et d’homoscédasticité sont améliorées et quelle transformation préféreriez-vous utiliser?</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="régression-linéaire.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous créons les nouvelles variables en bloc:</span></span>
<span id="cb89-2"><a href="régression-linéaire.html#cb89-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>ln_wpc <span class="ot">&lt;-</span> <span class="fu">log</span>(daisy2_mod<span class="sc">$</span>wpc)</span>
<span id="cb89-3"><a href="régression-linéaire.html#cb89-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>inv_wpc <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>daisy2_mod<span class="sc">$</span>wpc</span>
<span id="cb89-4"><a href="régression-linéaire.html#cb89-4" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>sqr_wpc <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(daisy2_mod<span class="sc">$</span>wpc)</span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Le log naturel de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="régression-linéaire.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle pour log_wpc</span></span>
<span id="cb90-2"><a href="régression-linéaire.html#cb90-2" aria-hidden="true" tabindex="-1"></a>modele_log<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb90-3"><a href="régression-linéaire.html#cb90-3" aria-hidden="true" tabindex="-1"></a>               ln_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin)</span>
<span id="cb90-4"><a href="régression-linéaire.html#cb90-4" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb90-5"><a href="régression-linéaire.html#cb90-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-6"><a href="régression-linéaire.html#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_log, <span class="dv">1</span>) <span class="co">#La figure Residual vs Fitted</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-181"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-181-1.png" alt="Graphique des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.11: Graphique des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="régression-linéaire.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_log, <span class="dv">2</span>) <span class="co">#La figure Normal Q-Q</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-182"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-182-1.png" alt="Graphique Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.12: Graphique Q-Q des résiduels.
</p>
</div>
<p><strong>Réponse:</strong> Normalité est très améliorée; homoscédasticité est beaucoup mieux. Peut-être une légère diminution de la variance avec augmentation des valeurs prédites.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>L’inverse de <em>WPC</em> (1/<em>WPC</em>)<br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="régression-linéaire.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle pour inv_wpc</span></span>
<span id="cb92-2"><a href="régression-linéaire.html#cb92-2" aria-hidden="true" tabindex="-1"></a>modele_inv<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb92-3"><a href="régression-linéaire.html#cb92-3" aria-hidden="true" tabindex="-1"></a>               inv_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin)</span>
<span id="cb92-4"><a href="régression-linéaire.html#cb92-4" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb92-5"><a href="régression-linéaire.html#cb92-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-6"><a href="régression-linéaire.html#cb92-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_inv, <span class="dv">1</span>) <span class="co">#La figure Residual vs Fitted</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-183"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-183-1.png" alt="Graphique des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.13: Graphique des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="régression-linéaire.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_inv, <span class="dv">2</span>) <span class="co">#La 2 figure Normal Q-Q</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-184"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-184-1.png" alt="Graphique Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.14: Graphique Q-Q des résiduels.
</p>
</div>
<p><strong>Réponse:</strong> Normalité est pire; homoscédasticité est pire aussi, variance augmente clairement avec augmentation des valeurs prédites.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>La racine carrée de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="régression-linéaire.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle pour sqr_wpc</span></span>
<span id="cb94-2"><a href="régression-linéaire.html#cb94-2" aria-hidden="true" tabindex="-1"></a>modele_sqr<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb94-3"><a href="régression-linéaire.html#cb94-3" aria-hidden="true" tabindex="-1"></a>               sqr_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin)</span>
<span id="cb94-4"><a href="régression-linéaire.html#cb94-4" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb94-5"><a href="régression-linéaire.html#cb94-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-6"><a href="régression-linéaire.html#cb94-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_sqr, <span class="dv">1</span>) <span class="co">#La figure Residual vs Fitted</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-185"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-185-1.png" alt="Graphique des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.15: Graphique des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="régression-linéaire.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_sqr, <span class="dv">2</span>) <span class="co">#La figure Normal Q-Q</span></span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-186"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-186-1.png" alt="Graphique Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.16: Graphique Q-Q des résiduels.
</p>
</div>
<p><strong>Réponse:</strong> Normalité des résiduels est un peu mieux que <em>WPC</em>, mais encore problématique (<em>ln_wpc</em> était meilleur de ce côté). L’homoscédasticité est beaucoup mieux. Peut-être même un peu mieux que <em>ln_wpc</em> sur cet aspect.</p>
<p><strong>3)</strong> Outre l’amélioration des suppositions du modèle, est-ce que la transformation par le logarithme naturel pourrait vous offrir d’autres avantages comparativement, par exemple, à la transformation par la racine carrée?</p>
<p><strong>Réponse:</strong> Oui, côté interprétation ce sera plus facile parce que nous pourrons directement retransformer et plus facilement interpréter l’estimé (i.e. l’exposant de <span class="math inline">\(β_1\)</span>) et son IC 95%. Par exemple, avec le <span class="math inline">\(β\)</span> de dyst (et IC 95%) de 0.027 (-0.163, 0.218) nous obtiendrons des valeurs retransformées de 1.03 (0.85, 1.24). Nous pourrons interpréter ces valeurs comme suit : <em>WPC</em> est multiplié par un facteur de 1.03 lorsque dystocie est présente, et nous avons 95% de certitude que la vraie valeur se situe entre une multiplication par 0.85 (i.e. une diminution du nombre de jours) et une multiplication par 1.24.</p>
<p><strong>4)</strong> Vous décidez donc de continuer à travailler avec le logarithme naturel de <em>WPC</em>. Rappelez-vous que lorsque vous aviez évalué la relation entre <em>herd_size</em> et <em>WPC</em>, cette relation semblait curvilinéaire. Est-ce que cela implique que la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em> est également curvilinéaire ?</p>
<p><strong>Réponse:</strong> Pas nécessairement, <em>ln_wpc</em> est une variable différente.</p>
<p><strong>5)</strong> Évaluez graphiquement et à l’aide de termes quadratique et cubique la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em>. Avez-vous besoin d’inclure un terme au carré ? Un terme au cube ?</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="régression-linéaire.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb96-2"><a href="régression-linéaire.html#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, </span>
<span id="cb96-3"><a href="régression-linéaire.html#cb96-3" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(herd_size, ln_wpc)</span>
<span id="cb96-4"><a href="régression-linéaire.html#cb96-4" aria-hidden="true" tabindex="-1"></a>       ) <span class="sc">+</span> </span>
<span id="cb96-5"><a href="régression-linéaire.html#cb96-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb96-6"><a href="régression-linéaire.html#cb96-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, </span>
<span id="cb96-7"><a href="régression-linéaire.html#cb96-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">span=</span><span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb96-8"><a href="régression-linéaire.html#cb96-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-187"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-187-1.png" alt="Relation entre la taille du troupeau (herd_size) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.17: Relation entre la taille du troupeau (herd_size) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Graphiquement, la relation avec <em>ln_wpc</em> semble aussi curvilinéaire.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="régression-linéaire.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle avec le terme au carré</span></span>
<span id="cb97-2"><a href="régression-linéaire.html#cb97-2" aria-hidden="true" tabindex="-1"></a>modele_log2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb97-3"><a href="régression-linéaire.html#cb97-3" aria-hidden="true" tabindex="-1"></a>                  ln_wpc <span class="sc">~</span> (herd_size_ct <span class="sc">+</span> herd_size_ct_sq)</span>
<span id="cb97-4"><a href="régression-linéaire.html#cb97-4" aria-hidden="true" tabindex="-1"></a>                  )</span>
<span id="cb97-5"><a href="régression-linéaire.html#cb97-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_log2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (herd_size_ct + herd_size_ct_sq), data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9279 -0.5420 -0.0283  0.5442  1.7717 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.881e+00  2.568e-02 151.147  &lt; 2e-16 ***
## herd_size_ct    3.357e-03  3.145e-04  10.676  &lt; 2e-16 ***
## herd_size_ct_sq 1.922e-05  4.564e-06   4.212 2.68e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7402 on 1571 degrees of freedom
##   (402 observations effacées parce que manquantes)
## Multiple R-squared:  0.06839,    Adjusted R-squared:  0.06721 
## F-statistic: 57.67 on 2 and 1571 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Le terme au carré est significatif (<em>P</em> &lt; 0.001), cela confirme la relation curvilinéaire.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="régression-linéaire.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co">#La variable au cube</span></span>
<span id="cb99-2"><a href="régression-linéaire.html#cb99-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct_cu <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>herd_size_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct</span>
<span id="cb99-3"><a href="régression-linéaire.html#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle avec le terme au cube</span></span>
<span id="cb99-4"><a href="régression-linéaire.html#cb99-4" aria-hidden="true" tabindex="-1"></a>modele_log3<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb99-5"><a href="régression-linéaire.html#cb99-5" aria-hidden="true" tabindex="-1"></a>                ln_wpc <span class="sc">~</span> (herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> herd_size_ct_cu)</span>
<span id="cb99-6"><a href="régression-linéaire.html#cb99-6" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb99-7"><a href="régression-linéaire.html#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_log3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (herd_size_ct + herd_size_ct_sq + herd_size_ct_cu), 
##     data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9243 -0.5377 -0.0293  0.5416  1.7768 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.879e+00  2.754e-02 140.868  &lt; 2e-16 ***
## herd_size_ct    3.230e-03  6.862e-04   4.707 2.73e-06 ***
## herd_size_ct_sq 2.012e-05  6.254e-06   3.217  0.00132 ** 
## herd_size_ct_cu 1.687e-08  8.074e-08   0.209  0.83452    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7404 on 1570 degrees of freedom
##   (402 observations effacées parce que manquantes)
## Multiple R-squared:  0.06842,    Adjusted R-squared:  0.06664 
## F-statistic: 38.44 on 3 and 1570 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Par contre le terme au cube n’est pas nécessaire (<em>P</em>=0.83) je pourrais l’enlever du modèle.</p>
<p><strong>6)</strong> Dans votre modèle avec le logarithme naturel de <em>WPC</em>, et <em>herd_size</em> modélisé avec les termes polynomiaux appropriés, est-ce que l’interaction entre <em>dyst</em> et <em>parity</em> est toujours statistiquement significative ?</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="régression-linéaire.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle pour log_wpc</span></span>
<span id="cb101-2"><a href="régression-linéaire.html#cb101-2" aria-hidden="true" tabindex="-1"></a>modele_log<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb101-3"><a href="régression-linéaire.html#cb101-3" aria-hidden="true" tabindex="-1"></a>               ln_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin)</span>
<span id="cb101-4"><a href="régression-linéaire.html#cb101-4" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb101-5"><a href="régression-linéaire.html#cb101-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_log)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (dyst * par_ct + herd_size_ct + herd_size_ct_sq + 
##     twin), data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9054 -0.5348 -0.0242  0.5413  1.7691 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.851e+00  3.446e-02 111.734  &lt; 2e-16 ***
## dyst            2.747e-02  9.715e-02   0.283  0.77735    
## par_ct          6.599e-03  1.292e-02   0.511  0.60960    
## herd_size_ct    3.438e-03  3.163e-04  10.872  &lt; 2e-16 ***
## herd_size_ct_sq 2.029e-05  4.580e-06   4.430 1.01e-05 ***
## twin            4.577e-01  1.438e-01   3.184  0.00148 ** 
## dyst:par_ct     1.031e-01  6.160e-02   1.673  0.09449 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7373 on 1567 degrees of freedom
##   (402 observations effacées parce que manquantes)
## Multiple R-squared:  0.07782,    Adjusted R-squared:  0.07429 
## F-statistic: 22.04 on 6 and 1567 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Non, <em>P</em> =0.0945</p>
<p><strong>7)</strong> Si l’interaction n’est plus statistiquement significative cela signifie que:</p>
<ol style="list-style-type: lower-alpha">
<li>L’effet de dystocie ne varie pas en fonction de la parité<br />
</li>
<li>Le terme d’interaction n’est pas nécessaire dans le modèle<br />
</li>
<li>Le coefficient de régression pour le terme d’interaction n’est pas différent de zéro<br />
</li>
<li>Toutes ces réponses</li>
</ol>
<p><strong>Réponse:</strong> d. Toutes ces réponses.</p>
<p><strong>8)</strong> Comme vous avez pu le noter, transformer la variable dépendante vous oblige à revoir pratiquement tout votre modèle de A à Z. Mais bon, votre modèle final pourrait donc être :</p>
<p><span class="math inline">\(log(wpc) = β_0 +β_1*dyst + β_2*parity_c + β_3*herdsize _c + β_4*herdsize_c^2 + β_5*twin\)</span></p>
<p>Évaluez une dernière fois les suppositions de normalité des résiduels et d’homoscédasticité (puisque vous ne l’avez pas encore fait pour ce modèle sans l’interaction <span class="math inline">\(dyst*parity\)</span>) et calculez dans une nouvelle table les valeurs prédites, les résiduels de Student, les leviers et les distances de Cook.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="régression-linéaire.html#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Générons le modèle sans l&#39;interaction</span></span>
<span id="cb103-2"><a href="régression-linéaire.html#cb103-2" aria-hidden="true" tabindex="-1"></a>modele_final<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, </span>
<span id="cb103-3"><a href="régression-linéaire.html#cb103-3" aria-hidden="true" tabindex="-1"></a>                 ln_wpc <span class="sc">~</span> (dyst <span class="sc">+</span> par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin)</span>
<span id="cb103-4"><a href="régression-linéaire.html#cb103-4" aria-hidden="true" tabindex="-1"></a>                 )</span>
<span id="cb103-5"><a href="régression-linéaire.html#cb103-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_final)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (dyst + par_ct + herd_size_ct + herd_size_ct_sq + 
##     twin), data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9017 -0.5355 -0.0242  0.5342  1.7585 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.842e+00  3.413e-02 112.583  &lt; 2e-16 ***
## dyst            1.196e-01  8.008e-02   1.494  0.13548    
## par_ct          1.112e-02  1.264e-02   0.880  0.37911    
## herd_size_ct    3.440e-03  3.164e-04  10.870  &lt; 2e-16 ***
## herd_size_ct_sq 2.035e-05  4.582e-06   4.441 9.58e-06 ***
## twin            4.523e-01  1.438e-01   3.145  0.00169 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7378 on 1568 degrees of freedom
##   (402 observations effacées parce que manquantes)
## Multiple R-squared:  0.07617,    Adjusted R-squared:  0.07323 
## F-statistic: 25.86 on 5 and 1568 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="régression-linéaire.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions d&#39;abord les suppositions:</span></span>
<span id="cb105-2"><a href="régression-linéaire.html#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_final, <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-191"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-191-1.png" alt="Graphique des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.18: Graphique des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="régression-linéaire.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_final, <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-192"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-192-1.png" alt="Graphique Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.19: Graphique Q-Q des résiduels.
</p>
</div>
<p><strong>Réponses:</strong> OK, les suppositions semblent respectées.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="régression-linéaire.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Enregistrons les valeurs prédites, les résiduels de Student, les leviers et les distance de Cook</span></span>
<span id="cb107-2"><a href="régression-linéaire.html#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb107-3"><a href="régression-linéaire.html#cb107-3" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(modele_final) <span class="co">#Nous venons de créer un nouveau jeu de données dans lequel les résiduels, les distances de cook, etc se trouvent maintenant</span></span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Combien d’observations ont des résiduels larges (résiduels de Student &gt; 3.0 ou &lt; -3.0)? Ont-elles quelque chose en commun en ce qui a trait à leurs valeurs de <em>WPC</em>, <em>dyst</em>, <em>parity</em>, <em>herd_size</em> ou <em>twin</em>?</li>
</ol>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="régression-linéaire.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous pouvons filtrer cette table pour ne conserver que les résiduels standardisés larges</span></span>
<span id="cb108-2"><a href="régression-linéaire.html#cb108-2" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, (.std.resid <span class="sc">&gt;=</span><span class="fl">3.0</span> <span class="sc">|</span> .std.resid<span class="sc">&lt;=-</span><span class="fl">3.0</span>))</span>
<span id="cb108-3"><a href="régression-linéaire.html#cb108-3" aria-hidden="true" tabindex="-1"></a>diag_res</span></code></pre></div>
<pre><code>## # A tibble: 5 × 13
##   .rownames ln_wpc  dyst par_ct herd_size…¹ herd_…²  twin .fitted .resid    .hat
##   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 445         1.10     0      3         -15     225     0    3.83  -2.73 0.00189
## 2 1091        1.39     0      3         -49    2401     0    3.76  -2.37 0.00190
## 3 1144        0        0      1         -49    2401     0    3.73  -3.73 0.00153
## 4 1177        1.39     0      0         -49    2401     0    3.72  -2.34 0.00223
## 5 2500        0        0      1          13     169     0    3.90  -3.90 0.00134
## # … with 3 more variables: .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;, and
## #   abbreviated variable names ¹​herd_size_ct, ²​herd_size_ct_sq</code></pre>
<p><strong>Réponse:</strong> 5 observations ont des résiduels larges. Elles ont toutes des WPC très courts (<em>i.e.</em> des <em>log_wpc</em> près de 0 ou 1), pas de jumeaux (<em>twin</em>=0) et pas de dystocie (<em>dyst</em>=0).</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Vous pourriez représenter graphiquement les résiduels de Student en fonction de <em>WPC</em> pour mieux visualiser où se situent ses résiduels larges. Quel genre d’observations (en termes de <em>WPC</em>) le modèle semble avoir de la difficulté à prédire?</li>
</ol>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="régression-linéaire.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb110-2"><a href="régression-linéaire.html#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>diag, <span class="fu">aes</span>(ln_wpc, .std.resid, <span class="at">colour=</span>.std.resid)) <span class="sc">+</span> </span>
<span id="cb110-3"><a href="régression-linéaire.html#cb110-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb110-4"><a href="régression-linéaire.html#cb110-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb110-5"><a href="régression-linéaire.html#cb110-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="dv">3</span>)) <span class="sc">+</span> </span>
<span id="cb110-6"><a href="régression-linéaire.html#cb110-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="sc">-</span><span class="dv">3</span>))</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-195"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-195-1.png" alt="Relation entre résiduels standardisés et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.20: Relation entre résiduels standardisés et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Le modèle semble avoir de la difficulté à prédire les vaches avec <em>log_WPC</em> très court.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Évaluez maintenant les 5 ou 10 observations avec les leviers les plus élevés. Encore une fois, ont-elles quelque chose en commun?</li>
</ol>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="régression-linéaire.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous pouvons ordonner cette table pour voir les 10 observations avec les leviers les plus larges</span></span>
<span id="cb111-2"><a href="régression-linéaire.html#cb111-2" aria-hidden="true" tabindex="-1"></a>diag_hat <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.hat),]</span>
<span id="cb111-3"><a href="régression-linéaire.html#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diag_hat, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 13
##    .rownames ln_wpc  dyst par_ct herd_siz…¹ herd_…²  twin .fitted  .resid   .hat
##    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
##  1 48          4.60     1      1         44    1936     1    4.62 -0.0211 0.0473
##  2 5628        3.14     1      0        -65    4225     1    4.28 -1.14   0.0470
##  3 1148        3.47     1      1        -49    2401     1    4.31 -0.840  0.0461
##  4 1363        4.36     0      2       -125   15625     1    4.20  0.152  0.0439
##  5 791         3.64     0      4         83    6889     1    4.76 -1.13   0.0405
##  6 313         4.79     0      0         44    1936     1    4.49  0.302  0.0395
##  7 377         5.15     0      5        -15     225     1    4.30  0.844  0.0393
##  8 2627        3.97     0      5         13     169     1    4.40 -0.428  0.0393
##  9 2628        4.66     0      5         13     169     1    4.40  0.265  0.0393
## 10 2513        4.70     0      0         13     169     1    4.34  0.358  0.0392
## # … with 3 more variables: .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;, and
## #   abbreviated variable names ¹​herd_size_ct, ²​herd_size_ct_sq</code></pre>
<p><strong>Réponse:</strong> Ces vaches ont toutes eu des jumeaux.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Les observations avec des résiduels ou des leviers larges (ou les deux) sont des observations qui peuvent potentiellement influencer le modèle de régression. Les distances de Cook nous permettront d’identifier quelles observations avaient effectivement une influence sur le modèle. Évaluez donc maintenant les 5 ou 10 observations avec les distances de Cook les plus élevées. Ont-elles quelque chose en commun ?</li>
</ol>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="régression-linéaire.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous pouvons ordonner cette table pour voir les 10 observations avec les distances de Cook les plus larges</span></span>
<span id="cb113-2"><a href="régression-linéaire.html#cb113-2" aria-hidden="true" tabindex="-1"></a>diag_cook <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.cooksd),]</span>
<span id="cb113-3"><a href="régression-linéaire.html#cb113-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diag_cook, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 13
##    .rownames ln_wpc  dyst par_ct herd_size…¹ herd_…²  twin .fitted .resid   .hat
##    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1 491         2.64     0      2         -15     225     1    4.27 -1.63  0.0375
##  2 5628        3.14     1      0         -65    4225     1    4.28 -1.14  0.0470
##  3 791         3.64     0      4          83    6889     1    4.76 -1.13  0.0405
##  4 1148        3.47     1      1         -49    2401     1    4.31 -0.840 0.0461
##  5 1239        5.45     1      4         -49    2401     0    3.89  1.56  0.0138
##  6 1230        5.53     1      3         -49    2401     0    3.88  1.66  0.0122
##  7 5527        5.48     1      3         -65    4225     0    3.86  1.62  0.0124
##  8 377         5.15     0      5         -15     225     1    4.30  0.844 0.0393
##  9 2543        2.40     1      0          13     169     0    4.01 -1.61  0.0112
## 10 2753        2.40     1      1          13     169     0    4.02 -1.62  0.0111
## # … with 3 more variables: .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;, and
## #   abbreviated variable names ¹​herd_size_ct, ²​herd_size_ct_sq</code></pre>
<p><strong>Réponse:</strong> Les vaches qui ont eu des jumeaux sont les pires. Les <em>log_WPC</em> courts (i.e. résiduels larges) ne semblent pas influencer beaucoup le modèle.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Vérifiez maintenant jusqu’à quel point ces observations influencent vos résultats en calculant de nouveau votre modèle mais sans les observations avec les distance de Cook les plus élevées (e.g. les 7 observations avec les distances de Cook &gt; 0.010).</li>
</ol>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="régression-linéaire.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous générons un jeu de données sans les 7 observations avec les distances de Cook les plus grandes</span></span>
<span id="cb115-2"><a href="régression-linéaire.html#cb115-2" aria-hidden="true" tabindex="-1"></a>outlier <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, .cooksd<span class="sc">&lt;</span><span class="fl">0.01</span>)</span>
<span id="cb115-3"><a href="régression-linéaire.html#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle sur ce jeu de données réduit</span></span>
<span id="cb115-4"><a href="régression-linéaire.html#cb115-4" aria-hidden="true" tabindex="-1"></a>modele_outlier<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>outlier, </span>
<span id="cb115-5"><a href="régression-linéaire.html#cb115-5" aria-hidden="true" tabindex="-1"></a>                   ln_wpc <span class="sc">~</span> (dyst <span class="sc">+</span> par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin)</span>
<span id="cb115-6"><a href="régression-linéaire.html#cb115-6" aria-hidden="true" tabindex="-1"></a>                   )</span>
<span id="cb115-7"><a href="régression-linéaire.html#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_outlier)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (dyst + par_ct + herd_size_ct + herd_size_ct_sq + 
##     twin), data = outlier)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9025 -0.5359 -0.0304  0.5329  1.7697 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.847e+00  3.397e-02 113.257  &lt; 2e-16 ***
## dyst            8.378e-02  8.160e-02   1.027    0.305    
## par_ct          6.913e-03  1.260e-02   0.548    0.583    
## herd_size_ct    3.485e-03  3.148e-04  11.070  &lt; 2e-16 ***
## herd_size_ct_sq 2.079e-05  4.557e-06   4.562 5.46e-06 ***
## twin            6.656e-01  1.546e-01   4.306 1.77e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7329 on 1561 degrees of freedom
## Multiple R-squared:  0.0826, Adjusted R-squared:  0.07966 
## F-statistic: 28.11 on 5 and 1561 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Est-ce que les conclusions des tests de <em>F</em> ou de <em>T</em> changent comparativement au modèle calculé au début de la question 8?</p>
<p><strong>Réponse:</strong> Les valeurs de <em>P</em> changent un peu mais aucune des conclusions n’est modifiée.</p>
<p>Est-ce que les estimés obtenus changent beaucoup ? Pour quel paramètre l’estimé semble être le plus affecté ? Est-ce en accord avec votre réponse à la question 8.d. ?</p>
<p><strong>Réponse:</strong> Les estimés ne changent pas beaucoup. Le paramètre qui semble être le plus affecté est <em>twin</em>. Ce dernier passe de +0.45 <em>log_wpc</em> à +0.66 <em>log_wpc</em> lorsque les observations influentes sont retirées. C’est bien certainement en accord avec le fait que les observations les plus influentes sont des observations où <em>twin</em>=1.</p>
</div>
</div>
<div id="travaux-pratiques-3---régression-linéaire---construction-de-modèle" class="section level2 hasAnchor" number="6.12">
<h2><span class="header-section-number">6.12</span> Travaux pratiques 3 - Régression linéaire - Construction de modèle<a href="régression-linéaire.html#travaux-pratiques-3---régression-linéaire---construction-de-modèle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercices-2" class="section level3 hasAnchor" number="6.12.1">
<h3><span class="header-section-number">6.12.1</span> Exercices<a href="régression-linéaire.html#exercices-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Les données utilisées pour ce TP sont obtenues à partir de la page du cours sur Studium. La base de données <em>milk2</em> est disponible en format ASCII délimité (.csv).</p>
<p>Le jeu de données <em>milk2</em> comprend 5 variables et 1140 observations:</p>
<p><strong>breed</strong> race de la vache (1 = Ayrshire, 2 = Holstein, 3 = Jersey, 8 =mixed)<br />
<strong>parity</strong> numéro de lactation<br />
<strong>kgmilk</strong> production journalière de lait en kg<br />
<strong>cellcount</strong> comptage en cellules somatiques x 10^3 cell./ml de lait<br />
<strong>cowid</strong> identification de la vache</p>
<p>Vous souhaitez savoir quel est l’effet de la production laitière sur le comptage des cellules somatiques. Votre diagramme causal est le suivant:</p>
<div class="figure">
<img src="Figures/Diag%20causal%20tp3.png" alt="" />
<p class="caption"><strong>Figure 6.21.</strong> Diagramme causal de la relation entre production laitière et comptage des cellules somatiques.</p>
</div>
<p>À partir du jeu de données fourni (<em>milk2</em>), répondre aux questions suivantes :</p>
<ol style="list-style-type: decimal">
<li><p>Quelles sont les variables confondantes que vous devrez possiblement contrôler pour répondre à votre question de recherche?</p></li>
<li><p>Quel serait votre modèle maximum?</p></li>
<li><p>Quelles sont les étapes que vous aurez à réaliser afin de développer et évaluer ce modèle statistique?</p></li>
</ol>
<p>Évidemment, ce serait difficile de tout faire cela dans un TP de 3hrs. Dans les questions suivantes, vous n’aurez qu’à évaluer certains aspects de ce travail.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Que pensez-vous de la variable <em>cellcount</em> (données manquantes, distribution)? Pensez-vous que cette variable causera des problèmes plus tard? Si oui, que pourriez-vous faire?</p></li>
<li><p>Évaluez la variable parity. Peu de vaches ont eu 5, 6, 7 ou 8 lactations. Pensez-vous qu’il serait préférable de catégoriser cette variable (e.g. 1ère vs. 2ième vs. 3ième vs. 4ième vs. &gt; 4ième)?</p></li>
<li><p>À propos de la relation entre <em>kgmilk</em> et <em>cellcount</em> :</p>
<p>6.1. Comment se comportent les résiduels (normalité et homoscédasticité) dans un modèle simple:<br />
<span class="math inline">\(cellcount=β_0 + β_1*kgmilk\)</span> ?<br />
Et avec <span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk\)</span>?</p>
<p>Comme noté à la question 4, il semble qu’il serait mieux de travailler avec le logarithme naturel de <em>cellcount</em> qu’avec la variable originale. Continuez donc avec le log(<em>cellcount</em>) pour les analyses suivantes.</p>
<p>6.2. Comment est-ce que le log(<em>cellcount</em>) varie en fonction de kgmilk? Est-ce que cette relation est linéaire? Comment allez-vous modéliser cette relation dans vos analyses subséquentes?</p></li>
<li><p>Associations conditionnelles.</p>
<p>7.1. La relation entre <em>parity</em> et <em>cellcount</em> également n’était pas linéaire et vous devrez donc modéliser cette relation à l’aide de 2 termes : <span class="math inline">\(parity centrée\)</span> et <span class="math inline">\(parity centrée^2\)</span>. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour le facteur confondant parité ?<br />
i.e. le modèle:<br />
<span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk + β_2*kgmilk^2 + β_3*kgmilk^3 + β_4*parity + β_5*parity^2\)</span></p>
<p>7.2. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour <em>race</em>?</p></li>
<li><p>Afin de réduire votre modèle maximum, vous décidez de retirer du modèle les facteurs confondants hypothétiques qui causaient une modification relative &lt; 10% de la mesure d’effet de <em>kgmilk</em>. Quel(s) facteur(s) confondant(s) gardez-vous? Y-a-t-il d’autres variables que vous désirez maintenant retirer du modèle? Quel serait votre modèle final?</p></li>
<li><p>Évaluez si les suppositions de votre modèle final sont respectées.</p></li>
<li><p>Évaluez les observations extrêmes, les leviers et les observations influentes (nombre, profil commun).<br />
10.1. Quelle est la valeur de <em>cellcount</em> pour les observations avec les résiduels négatifs les plus larges?<br />
10.2. Une valeur de 1,000 cell./ml est assez inusitée pour un comptage des cellules somatiques. En fait la limite analytique du Fossomatic cell counter est généralement de 10,000 cell./ml. Vous appelez donc le laboratoire pour en savoir plus sur ces résultats. On vous dit qu’on donne la valeur « 1 » aux échantillons qui ne peuvent être analysés (échappés, mal conservés, etc). Il s’agit donc d’observations manquantes! Vous pouvez donc ré-évaluer le modèle en excluant ces observations (et en priant pour que les résultats changent peu).<br />
Notez comment votre Q-Q plot et l’histogramme des résiduels sont encore mieux sans ces observations. Combien d’observations avec un résiduel large (&gt;3 ou &lt;-3) avez-vous? Ces observations ont-elles quelque chose en commun?<br />
10.3. Vérifiez maintenant les 10 observations avec les leviers les plus grands. Ont-elles quelque chose en commun?<br />
10.4. Vérifiez maintenant les 10 observations les plus influentes. Ont-elles quelque chose en commun?</p></li>
<li><p>Présentation des résultats.<br />
11.1. Présentez les résultats de votre modèle dans une table que vous pourriez soumettre dans une publication scientifique.<br />
L’effet de la production laitière n’est plus sur l’échelle originale. En plus, la relation entre production et CCS n’est pas linéaire. Tout ça rend votre modèle difficile à interpréter et il faudrait possiblement trouver une manière de rendre l’information plus digestible pour vos lecteurs.<br />
11.2. Vous pourriez présenter comment le CCS varie en fonction de la production laitière pour différents scénarios. Vous pourriez, par exemple, compléter la table suivante, en calculant la valeur prédite pour chaque scénario à l’aide de votre modèle, puis en retransformant ces valeurs sur l’échelle originale:</p></li>
</ol>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-201">Table 6.3: </span>Valeurs prédites de comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) d’une vache Ayrshire pour différentes combinaisons de production et parité.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Production
</th>
<th style="text-align:center;">
1ère lactation
</th>
<th style="text-align:center;">
2ième lactation
</th>
<th style="text-align:center;">
3ième et plus
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
10kg/jour
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
20kg/jour
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
30kg/jour
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>11.3. Encore mieux : à partir d’une table <code>R</code> contenant les valeurs prédites, retransformez la valeur prédite sur l’échelle originale en créant une nouvelle variable <span class="math inline">\(CCS=exp(valeur prédite)\)</span>. Ensuite, vous pourrez utiliser le package <code>ggplot2</code> pour représenter dans un graphique de nuage de points la relation entre la production laitière (en x) et la valeur prédite de CCS (en y).<br />
C’est plus simple à comprendre ainsi n’est-ce pas?</p>
</div>
<div id="code-r-et-réponses-2" class="section level3 hasAnchor" number="6.12.2">
<h3><span class="header-section-number">6.12.2</span> Code R et réponses<a href="régression-linéaire.html#code-r-et-réponses-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Les données utilisées pour ce TP sont obtenues à partir de la page du cours sur Studium. La base de données <em>milk2</em> est disponible en format ASCII délimité (.csv).</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="régression-linéaire.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Ouvrir le jeu de données</span></span>
<span id="cb117-2"><a href="régression-linéaire.html#cb117-2" aria-hidden="true" tabindex="-1"></a>milk2 <span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;milk2.csv&quot;</span>, </span>
<span id="cb117-3"><a href="régression-linéaire.html#cb117-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">header=</span><span class="cn">TRUE</span>, </span>
<span id="cb117-4"><a href="régression-linéaire.html#cb117-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Quelles sont les variables confondantes que vous devrez possiblement contrôler pour répondre à votre question de recherche?<br />
<strong>Réponse:</strong> Parité et Race</p></li>
<li><p>Quel serait votre modèle maximum?<br />
<strong>Réponse:</strong> <span class="math inline">\(cellcount = β_0 + β_1*kgmilk + β_2*breed + β_3*parity\)</span></p></li>
<li><p>Quelles sont les étapes que vous aurez à réaliser afin de développer et évaluer ce modèle statistique?<br />
<strong>Réponse:</strong></p>
<ol style="list-style-type: decimal">
<li>Évaluer <em>cellcount</em> seul (données manquantes, distribution, transformation…)<br />
</li>
<li>Évaluer individuellement <em>kgmilk</em>, <em>breed</em> et <em>parity</em> (données manquantes, distributions, table de fréquence, transformations pour centrer ou mettre à l’échelle, décider des catégories de référence…)<br />
</li>
<li>Évaluer association inconditionnelle entre chaque prédicteur et <em>cellcount</em> (graphiques et modèles, linéarité de la relation pour les variables continues):<br />
Pour <em>Kgmilk</em>:<br />
</li>
</ol>
<ul>
<li>Nuage de points <em>kgmilk</em> x <em>cellcount</em> avec courbe loess pour linéarité<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*kgmilk\)</span><br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*kgmilk + β_2*kgmilk^2\)</span> (pour évaluer la forme de la relation)<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*kgmilk + β_2*kgmilk^2 + kgmilk^3\)</span> (pour évaluer la forme de la relation)<br />
Pour <em>Breed</em>:<br />
</li>
<li>Box-plot <em>cellcount</em> x <em>breed</em><br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*breed\)</span><br />
Pour <em>Parity</em>:<br />
</li>
<li>Nuage de points avec loess ou box-plot <em>cellcount</em> x <em>parity</em> pour linéarité<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*parity\)</span><br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*parity + β_2*parity^2\)</span> (pour évaluer la forme de la relation)<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*parity + β_2*parity^2 + parity^3\)</span> (pour évaluer la forme de la relation)<br />
</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Évaluer les associations inconditionnelles entre prédicteurs<br />
Pour <em>Kgmilk</em> et <em>breed</em>:<br />
</li>
</ol>
<ul>
<li>Boxplot <em>kgmilk</em> x <em>breed</em><br />
</li>
<li>Modèle <span class="math inline">\(kgmilk=β_0 + β_1*breed\)</span><br />
Pour <em>Parity</em> et <em>breed</em>:<br />
</li>
<li>Boxplot <em>parity</em> x <em>breed</em><br />
</li>
<li>Modèle <span class="math inline">\(parity=β_0 + β_1*breed\)</span><br />
Pour <em>Kgmilk</em> et <em>parity</em>:</li>
<li>Nuage de points <em>kgmilk</em> x <em>parity</em> avec courbe loess<br />
</li>
<li>Modèle <span class="math inline">\(kgmilk=β_0 + β_1*parity\)</span><br />
</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Évaluer les associations conditionnelles (i.e. après avoir ajouté un confondant):<br />
<em>Breed</em> (confondant)<br />
</li>
</ol>
<ul>
<li>Modèle <span class="math inline">\(cellcount=β_0 + β_1*kgmilk + β_2*breed\)</span><br />
<em>Parity</em> (confondant)<br />
</li>
<li>Modèle <span class="math inline">\(cellcount=β_0 + β_1*kgmilk + β_2*Parity\)</span><br />
Notez : s’il y avait eu une interaction à investiguer, c’est à ce stade-ci que vous auriez pu évaluer le modèle avec juste l’interaction. Par exemple: <span class="math inline">\(cellcount= β_0 + β_1*kgmilk + β_2*parity + β_3*kgmilk*parity\)</span></li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>S’il y a lieu, éÉtablir une stratégie de sélection des covariables qui permettra de réduire le modèle maximum<br />
Confondants : par exemple on peut choisir de réduire le nombre de facteurs confondants en vérifiant si les associations conditionnelle et inconditionnelle diffèrent par plus de 10%<br />
Notez : s’il y avait eu une interaction à investiguer, c’est à ce stade-ci que vous auriez pu spécifier quels critères seront utilisés pour décider des interactions à retenir. Par exemple : si le(s) terme(s) d’interaction à une valeur de P &lt; 0.05, alors garder l’interaction et les termes principaux.<br />
</li>
<li>Évaluer le modèle<br />
Suppositions (homoscédasticité et normalité)<br />
Observations:<br />
</li>
</ol>
<ul>
<li>Extrêmes (résiduels)<br />
</li>
<li>Combinaisons de prédicteurs (leviers)<br />
</li>
<li>Influentes (Cook’s distance)</li>
</ul></li>
</ol>
<p>Évidemment, ce serait difficile de tout faire cela dans un TP de 3hrs. Dans les questions suivantes, vous n’aurez qu’à évaluer certains aspects de ce travail.</p>
<ol start="4" style="list-style-type: decimal">
<li>Que pensez-vous de la variable <em>cellcount</em> (données manquantes, distribution)? Pensez-vous que cette variable causera des problèmes plus tard? Si oui, que pourriez-vous faire ?</li>
</ol>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="régression-linéaire.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le package summarytools est utile pour les analyses descriptives. Ici nous demandons les stats descriptives pour toute les variables de milk2.</span></span>
<span id="cb118-2"><a href="régression-linéaire.html#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Nous aurions aussi pu spécifier milk2$cellcount pour ne voir que cellcount.</span></span>
<span id="cb118-3"><a href="régression-linéaire.html#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Dans un script RMarkdown, ont doit aussi spécifier method=&#39;render&#39;. Cet argument n&#39;est pas nécessaire sinon.</span></span>
<span id="cb118-4"><a href="régression-linéaire.html#cb118-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(summarytools)</span>
<span id="cb118-5"><a href="régression-linéaire.html#cb118-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dfSummary</span>(milk2), </span>
<span id="cb118-6"><a href="régression-linéaire.html#cb118-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">method=</span><span class="st">&#39;render&#39;</span>)</span></code></pre></div>
<div class="container st-container">
<h3>Data Frame Summary</h3>
<h4></h4>
<strong>Dimensions</strong>: 1140 x 5
  <br/><strong>Duplicates</strong>: 54
<br/>
<table class="table table-striped table-bordered st-table st-table-striped st-table-bordered st-multiline ">
  <thead>
    <tr>
      <th align="center" class="st-protect-top-border"><strong>No</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Variable</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Stats / Values</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Freqs (% of Valid)</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Graph</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Valid</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Missing</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="center">1</td>
      <td align="left">breed
[integer]</td>
      <td align="left" style="padding:8;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">Mean (sd) : 3.4 (2.6)</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">min &le; med &le; max:</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">1 &le; 2 &le; 8</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">IQR (CV) : 1 (0.8)</td></tr></table></td>
      <td align="left" style="padding:0;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">1</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">161</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">14.1%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">2</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">518</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">45.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">3</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">196</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">17.2%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">8</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">265</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">23.2%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr></table></td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent;"><img style="border:none;background-color:transparent;padding:0;max-width:max-content;" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAFEAAABmBAMAAABB3mAQAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5wETFgAB1/W/DwAAAGlJREFUWMPt1EEKgCAQRmGP0Nwg7AZ2/7u5KUqcnEGoEN9bfwsVfkMYp3glessht/0sIZHIQvp3JGZvymi2Vnd/ComcVfp39O/eO3+Gpry/UkIikdKzIzH7bO/qYbW76w+ARM4q/TsaoQx1OaBjvjFCTwAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0wMS0xOVQyMjowMDowMSswMDowMJ+e9CUAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMDEtMTlUMjI6MDA6MDErMDA6MDDuw0yZAAAAAElFTkSuQmCC"></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
    <tr>
      <td align="center">2</td>
      <td align="left">parity
[integer]</td>
      <td align="left" style="padding:8;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">Mean (sd) : 2.3 (1.4)</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">min &le; med &le; max:</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">1 &le; 2 &le; 8</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">IQR (CV) : 2 (0.6)</td></tr></table></td>
      <td align="left" style="padding:0;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">1</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">421</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">37.0%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">2</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">311</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">27.3%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">3</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">200</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">17.6%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">4</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">125</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">11.0%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">5</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">45</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">4.0%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">6</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">27</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">2.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">7</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">5</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">0.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">8</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">5</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">0.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr></table></td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent;"><img style="border:none;background-color:transparent;padding:0;max-width:max-content;" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAEQAAADEBAMAAADUjZpZAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5wETFgAB1/W/DwAAAItJREFUWMPt07ENwCAMRNGs4BEIG5D9d0uTBskYF2Cj6F/9Cp90vq6zchv5SH2GaRBIGnFsV4wsJeoRPdEaNQgkmzi2m/NHRSVdIwgkhDiGKUay/qiMSdX7QiAbiWOYYiThj8qEVL0vBLKROIYpRuL/aEpqg0CiiWOYIkGkQCD/JRJFTioNgSwmp+QFVhggu7WwNhMAAAAldEVYdGRhdGU6Y3JlYXRlADIwMjMtMDEtMTlUMjI6MDA6MDErMDA6MDCfnvQlAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIzLTAxLTE5VDIyOjAwOjAxKzAwOjAw7sNMmQAAAABJRU5ErkJggg=="></td>
      <td align="center">1139
(99.9%)</td>
      <td align="center">1
(0.1%)</td>
    </tr>
    <tr>
      <td align="center">3</td>
      <td align="left">kgmilk
[numeric]</td>
      <td align="left" style="padding:8;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">Mean (sd) : 19.9 (6.5)</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">min &le; med &le; max:</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">3.2 &le; 19.6 &le; 43.1</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">IQR (CV) : 8.3 (0.3)</td></tr></table></td>
      <td align="left" style="vertical-align:middle">269 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent;"><img style="border:none;background-color:transparent;padding:0;max-width:max-content;" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5wETFgAB1/W/DwAAAJRJREFUaN7t2c0NgCAMhmFWwA3EDWT/3Uy0PdDIj9iTvt+lCQlPyoXQEAKZSbxPkqxxKG1sy1fAwMB+gOnt4YJJ3cHAwMDAwMDAvo0t8oTywUoEDAzsxDqTyjMstzsEAwMDAwMDA2tj+jLpYJV/GoOZXTVMKhgYmBtmZwzBUjnhD2K6bLDKrkFMW3HBdNkc810CmckBq/EjtWaIAf0AAAAldEVYdGRhdGU6Y3JlYXRlADIwMjMtMDEtMTlUMjI6MDA6MDErMDA6MDCfnvQlAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIzLTAxLTE5VDIyOjAwOjAxKzAwOjAw7sNMmQAAAABJRU5ErkJggg=="></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
    <tr>
      <td align="center">4</td>
      <td align="left">cellcount
[integer]</td>
      <td align="left" style="padding:8;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">Mean (sd) : 369.9 (739.8)</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">min &le; med &le; max:</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">1 &le; 138 &le; 8100</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">IQR (CV) : 305 (2)</td></tr></table></td>
      <td align="left" style="vertical-align:middle">422 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent;"><img style="border:none;background-color:transparent;padding:0;max-width:max-content;" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5wETFgAB1/W/DwAAAGhJREFUaN7t2bENgDAMAMGswAiEDfD+u0Ek0qBQ4KS8l9yeXLhzKcpU7/Zttgc7IgIGg8FgMBgMBoPBYDAYDAaDwWAwGAwGW4G1R1ZdhbU5YbAPbOrW3tjUdiMsvd0I62DvL1aXVJTpAofjHfXbt3AuAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIzLTAxLTE5VDIyOjAwOjAxKzAwOjAwn570JQAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMy0wMS0xOVQyMjowMDowMSswMDowMO7DTJkAAAAASUVORK5CYII="></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
    <tr>
      <td align="center">5</td>
      <td align="left">cowid
[integer]</td>
      <td align="left" style="padding:8;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">Mean (sd) : 227807355 (155552851)</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">min &le; med &le; max:</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">25930370 &le; 117880788 &le; 455261650</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">IQR (CV) : 271260050 (0.7)</td></tr></table></td>
      <td align="left" style="vertical-align:middle">1086 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent;"><img style="border:none;background-color:transparent;padding:0;max-width:max-content;" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5wETFgAB1/W/DwAAAH5JREFUaN7t2MEJgDAMQNGsUDcwbqD77yaYXFJCkZCL8v8ll/JaeilUhCoNS6191IrYcT2BgYGBgYGBgYGBgYGBgYGBlbHNfyt6MFtxgoGBgYF9EJtehBRbfHFPWDxnii0OmGO+ew/m43+Y31IPlg4wMDAwsBqmoReYtiRU6QbCPrxcn2TkwAAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0wMS0xOVQyMjowMDowMSswMDowMJ+e9CUAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMDEtMTlUMjI6MDA6MDErMDA6MDDuw0yZAAAAAElFTkSuQmCC"></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
  </tbody>
</table>
<p>Generated by <a href='https://github.com/dcomtois/summarytools'>summarytools</a> 1.0.1 (<a href='https://www.r-project.org/'>R</a> version 4.2.0)<br/>2023-01-19</p>
</div>
<p><strong>Réponse:</strong> Pour <code>cellcount</code>, il n’y a pas de données manquantes, la distribution est skewed à droite. Oui, les résiduels seront probablement skewed aussi. Nous pourrions déjà vérifier si une transformation (par exemple un log naturel) améliorerait sa distribution :</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="régression-linéaire.html#cb119-1" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>log_cell <span class="ot">&lt;-</span> <span class="fu">log</span>(milk2<span class="sc">$</span>cellcount)</span>
<span id="cb119-2"><a href="régression-linéaire.html#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dfSummary</span>(milk2<span class="sc">$</span>log_cell), </span>
<span id="cb119-3"><a href="régression-linéaire.html#cb119-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">method=</span><span class="st">&#39;render&#39;</span>)</span></code></pre></div>
<pre><code>## milk2$log_cell was converted to a data frame</code></pre>
<div class="container st-container">
<h3>Data Frame Summary</h3>
<h4>milk2</h4>
<strong>Dimensions</strong>: 1140 x 1
  <br/><strong>Duplicates</strong>: 718
<br/>
<table class="table table-striped table-bordered st-table st-table-striped st-table-bordered st-multiline ">
  <thead>
    <tr>
      <th align="center" class="st-protect-top-border"><strong>No</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Variable</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Stats / Values</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Freqs (% of Valid)</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Graph</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Valid</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Missing</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="center">1</td>
      <td align="left">milk2
[numeric]</td>
      <td align="left" style="padding:8;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">Mean (sd) : 5 (1.4)</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">min &le; med &le; max:</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">0 &le; 4.9 &le; 9</td></tr><tr style="background-color:transparent"><td style="padding:0;margin:0;border:0" align="left">IQR (CV) : 1.9 (0.3)</td></tr></table></td>
      <td align="left" style="vertical-align:middle">422 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent;"><img style="border:none;background-color:transparent;padding:0;max-width:max-content;" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5wETFgAB1/W/DwAAAIxJREFUaN7t2MEJwCAMheGs0G5Qu0Gz/26Fkhz0oNUIpe3/LkLQDy+BEBEykqWeZGlcu4fteuUAA3sd1uiEPkzrPwQDAwMDAwMD68J8UCkxK29dmCFaYnaCgYGBgYGBgYH9Hlvz8TOI5QgY2JNYuQMOYV4GAwObhnmPTsG8bFjKdygxzF99HEtTImQkJyiqUC9GnpymAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIzLTAxLTE5VDIyOjAwOjAxKzAwOjAwn570JQAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMy0wMS0xOVQyMjowMDowMSswMDowMO7DTJkAAAAASUVORK5CYII="></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
  </tbody>
</table>
<p>Generated by <a href='https://github.com/dcomtois/summarytools'>summarytools</a> 1.0.1 (<a href='https://www.r-project.org/'>R</a> version 4.2.0)<br/>2023-01-19</p>
</div>
<ol start="5" style="list-style-type: decimal">
<li>Évaluez la variable parity. Peu de vaches ont eu 5, 6, 7 ou 8 lactations. Pensez-vous qu’il serait préférable de catégoriser cette variable (e.g. 1ère vs. 2ième vs. 3ième vs. 4ième vs. &gt; 4ième)?</li>
</ol>
<p><strong>Réponse:</strong> Voir les résultats descriptifs précédents. Non, parce qu’elle est utilisée comme facteur confondant. Nous préférons donc conserver la mesure la plus précise possible afin d’avoir le meilleur contrôle possible. S’il s’agissait d’une exposition, nous pourrions effectivement considérer cette catégorisation.</p>
<ol start="6" style="list-style-type: decimal">
<li><p>À propos de la relation entre <em>kgmilk</em> et <em>cellcount</em> :</p>
<p>6.1. Comment se comportent les résiduels (normalité et homoscédasticité) dans un modèle simple:<br />
<span class="math inline">\(cellcount=β_0 + β_1*kgmilk\)</span> ?<br />
Et avec <span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk\)</span>?</p></li>
</ol>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="régression-linéaire.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle avec cellcount et les figures de Dx des résiduels</span></span>
<span id="cb121-2"><a href="régression-linéaire.html#cb121-2" aria-hidden="true" tabindex="-1"></a>model_cellcount <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb121-3"><a href="régression-linéaire.html#cb121-3" aria-hidden="true" tabindex="-1"></a>                      cellcount <span class="sc">~</span> kgmilk)</span>
<span id="cb121-4"><a href="régression-linéaire.html#cb121-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_cellcount, <span class="dv">1</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-205"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-205-1.png" alt="Graphiques des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.21: Graphiques des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="régression-linéaire.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_cellcount, <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-206"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-206-1.png" alt="Graphiques Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.22: Graphiques Q-Q des résiduels.
</p>
</div>
<p><strong>Réponse:</strong> Problème de normalité et possiblement homoscédasticité!</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="régression-linéaire.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle avec le logarithme de cellcount et les figures de Dx des résiduels</span></span>
<span id="cb123-2"><a href="régression-linéaire.html#cb123-2" aria-hidden="true" tabindex="-1"></a>model_log_cell <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb123-3"><a href="régression-linéaire.html#cb123-3" aria-hidden="true" tabindex="-1"></a>                     log_cell <span class="sc">~</span> kgmilk)</span>
<span id="cb123-4"><a href="régression-linéaire.html#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_log_cell, <span class="dv">1</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-207"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-207-1.png" alt="Graphiques des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.23: Graphiques des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="régression-linéaire.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_log_cell, <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-208"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-208-1.png" alt="Graphiques Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.24: Graphiques Q-Q des résiduels.
</p>
</div>
<p><strong>Réponse:</strong> Dans le modèle avec le logarithme naturel de <em>cellcount</em> c’est beaucoup mieux.</p>
<p>Comme noté à la question 4, il semble qu’il serait mieux de travailler avec le logarithme naturel de <em>cellcount</em> qu’avec la variable originale. Continuez donc avec le log(<em>cellcount</em>) pour les analyses suivantes.</p>
<p>6.2. Comment est-ce que log(<em>cellcount</em>) varie en fonction de kgmilk? Est-ce que cette relation est linéaire? Comment allez-vous modéliser cette relation dans vos analyses subséquentes?</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="régression-linéaire.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb125-2"><a href="régression-linéaire.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(milk2, </span>
<span id="cb125-3"><a href="régression-linéaire.html#cb125-3" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(kgmilk, log_cell)</span>
<span id="cb125-4"><a href="régression-linéaire.html#cb125-4" aria-hidden="true" tabindex="-1"></a>       ) <span class="sc">+</span> </span>
<span id="cb125-5"><a href="régression-linéaire.html#cb125-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb125-6"><a href="régression-linéaire.html#cb125-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, </span>
<span id="cb125-7"><a href="régression-linéaire.html#cb125-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">span=</span><span class="dv">2</span>) <span class="sc">+</span>  </span>
<span id="cb125-8"><a href="régression-linéaire.html#cb125-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-209"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-209-1.png" alt="Relation entre la production laitière (en kg/j) et le logarithme naturel de cellcount avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.25: Relation entre la production laitière (en kg/j) et le logarithme naturel de cellcount avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Le logarithme de <em>cellcount</em> diminue avec la production puis augmente (i.e. une courbe). La relation n’est pas linéaire. Vérifions avec les termes polynomiaux…</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="régression-linéaire.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="co">#D&#39;abord, centrons kgmilk sur une valeur près de la moyenne (pour éviter la colinéarité)</span></span>
<span id="cb126-2"><a href="régression-linéaire.html#cb126-2" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>kgmilk_ct <span class="ot">&lt;-</span> milk2<span class="sc">$</span>kgmilk<span class="dv">-20</span></span>
<span id="cb126-3"><a href="régression-linéaire.html#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Puis créons des termes au carré et au cube</span></span>
<span id="cb126-4"><a href="régression-linéaire.html#cb126-4" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>kgmilk_ct_sq <span class="ot">&lt;-</span> milk2<span class="sc">$</span>kgmilk_ct<span class="sc">*</span>milk2<span class="sc">$</span>kgmilk_ct </span>
<span id="cb126-5"><a href="régression-linéaire.html#cb126-5" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>kgmilk_ct_cu <span class="ot">&lt;-</span> milk2<span class="sc">$</span>kgmilk_ct<span class="sc">*</span>milk2<span class="sc">$</span>kgmilk_ct<span class="sc">*</span>milk2<span class="sc">$</span>kgmilk_ct</span>
<span id="cb126-6"><a href="régression-linéaire.html#cb126-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions le modèle avec le terme au carré</span></span>
<span id="cb126-7"><a href="régression-linéaire.html#cb126-7" aria-hidden="true" tabindex="-1"></a>model_sq <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb126-8"><a href="régression-linéaire.html#cb126-8" aria-hidden="true" tabindex="-1"></a>               log_cell <span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq)</span>
<span id="cb126-9"><a href="régression-linéaire.html#cb126-9" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb126-10"><a href="régression-linéaire.html#cb126-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_sq)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9196 -0.9167 -0.0497  0.8787  4.2372 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.8028594  0.0491544  97.710  &lt; 2e-16 ***
## kgmilk_ct    -0.0281185  0.0064195  -4.380 1.30e-05 ***
## kgmilk_ct_sq  0.0035949  0.0006477   5.551 3.54e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.376 on 1137 degrees of freedom
## Multiple R-squared:  0.03517,    Adjusted R-squared:  0.03347 
## F-statistic: 20.72 on 2 and 1137 DF,  p-value: 1.448e-09</code></pre>
<p><strong>Réponse:</strong> Le terme au carré est significatif (<em>P</em> &lt; 0.05)</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="régression-linéaire.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions le modèle avec le terme au carré et le terme au cube</span></span>
<span id="cb128-2"><a href="régression-linéaire.html#cb128-2" aria-hidden="true" tabindex="-1"></a>model_cu <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb128-3"><a href="régression-linéaire.html#cb128-3" aria-hidden="true" tabindex="-1"></a>               log_cell <span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu)</span>
<span id="cb128-4"><a href="régression-linéaire.html#cb128-4" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb128-5"><a href="régression-linéaire.html#cb128-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_cu)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu), 
##     data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.8668 -0.9016 -0.0672  0.8875  4.2224 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.787e+00  4.974e-02  96.235  &lt; 2e-16 ***
## kgmilk_ct    -1.282e-02  1.007e-02  -1.273   0.2031    
## kgmilk_ct_sq  4.236e-03  7.241e-04   5.850 6.41e-09 ***
## kgmilk_ct_cu -1.185e-04  6.014e-05  -1.970   0.0491 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.375 on 1136 degrees of freedom
## Multiple R-squared:  0.03845,    Adjusted R-squared:  0.03591 
## F-statistic: 15.14 on 3 and 1136 DF,  p-value: 1.145e-09</code></pre>
<p><strong>Réponse:</strong> Le terme au cube est aussi significatif (<em>P</em> &lt; 0.05). Cette relation devrait donc être modélisée en utilisant <span class="math inline">\(kgmilk + kgmilk^2 + kgmilk^3\)</span></p>
<ol start="7" style="list-style-type: decimal">
<li><p>Associations conditionnelles.</p>
<p>7.1. La relation entre <em>parity</em> et <em>cellcount</em> également n’était pas linéaire et vous devrez donc modéliser cette relation à l’aide de 2 termes : <span class="math inline">\(parity\)</span> et <span class="math inline">\(parity^2\)</span>. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour le facteur confondant parité ?<br />
i.e. le modèle:<br />
<span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk + β_2*kgmilk^2 + β_3*kgmilk^3 + β_4*parity + β_5*parity^2\)</span></p></li>
</ol>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="régression-linéaire.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Générons ces nouvelles variables parité centrée sur parité 1</span></span>
<span id="cb130-2"><a href="régression-linéaire.html#cb130-2" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>parity_ct <span class="ot">&lt;-</span> milk2<span class="sc">$</span>parity<span class="dv">-1</span></span>
<span id="cb130-3"><a href="régression-linéaire.html#cb130-3" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>parity_ct_sq <span class="ot">&lt;-</span> milk2<span class="sc">$</span>parity_ct<span class="sc">*</span>milk2<span class="sc">$</span>parity_ct</span>
<span id="cb130-4"><a href="régression-linéaire.html#cb130-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions les modèles avec et sans ajustement pour parity (nous avons déjà fait rouler celui sans parity à la question 6.2)</span></span>
<span id="cb130-5"><a href="régression-linéaire.html#cb130-5" aria-hidden="true" tabindex="-1"></a>model_parity <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb130-6"><a href="régression-linéaire.html#cb130-6" aria-hidden="true" tabindex="-1"></a>                   log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq)</span>
<span id="cb130-7"><a href="régression-linéaire.html#cb130-7" aria-hidden="true" tabindex="-1"></a>                   )</span>
<span id="cb130-8"><a href="régression-linéaire.html#cb130-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_parity)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu + 
##     parity_ct + parity_ct_sq), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.2194 -0.8303 -0.0055  0.8096  4.1204 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.383e+00  6.476e-02  67.679  &lt; 2e-16 ***
## kgmilk_ct    -3.452e-02  9.947e-03  -3.471 0.000539 ***
## kgmilk_ct_sq  2.985e-03  7.087e-04   4.212 2.73e-05 ***
## kgmilk_ct_cu -6.589e-05  5.816e-05  -1.133 0.257514    
## parity_ct     5.102e-01  7.125e-02   7.161 1.44e-12 ***
## parity_ct_sq -5.742e-02  1.514e-02  -3.794 0.000156 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.323 on 1133 degrees of freedom
##   (1 observation effacée parce que manquante)
## Multiple R-squared:  0.1114, Adjusted R-squared:  0.1075 
## F-statistic: 28.41 on 5 and 1133 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Oui voir table suivante (notez que j’ai arrondi les estimés avant de faire les calculs). Notez aussi, le <span class="math inline">\(kgmilk^3\)</span> n’est plus significatif (<em>P</em> = 0.26) après avoir ajusté pour parité (i.e. <span class="math inline">\(kgmilk^3\)</span> ne serait plus nécessaire après ajustement pour parité).</p>
<table>
<caption>
<span id="tab:unnamed-chunk-214">Table 6.4: </span>Estimés de l’effet de la production laitière sans (inconditionnelle) et avec (conditionnelle) ajustement pour parity.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Inconditionnelle
</th>
<th style="text-align:right;">
Conditionelle
</th>
<th style="text-align:right;">
Diff_relative_parity
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
kgmilk_ct
</td>
<td style="text-align:right;">
-0.0128
</td>
<td style="text-align:right;">
-0.0345
</td>
<td style="text-align:right;">
-170
</td>
</tr>
<tr>
<td style="text-align:left;">
kgmilk_ct_sq
</td>
<td style="text-align:right;">
0.0042
</td>
<td style="text-align:right;">
0.0030
</td>
<td style="text-align:right;">
29
</td>
</tr>
<tr>
<td style="text-align:left;">
kgmilk_ct_cu
</td>
<td style="text-align:right;">
-0.0001
</td>
<td style="text-align:right;">
-0.0001
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p>7.2. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour <em>race</em>?</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="régression-linéaire.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions les modèles avec ajustement pour race</span></span>
<span id="cb132-2"><a href="régression-linéaire.html#cb132-2" aria-hidden="true" tabindex="-1"></a>model_breed <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb132-3"><a href="régression-linéaire.html#cb132-3" aria-hidden="true" tabindex="-1"></a>                  log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu <span class="sc">+</span> <span class="fu">factor</span>(breed))</span>
<span id="cb132-4"><a href="régression-linéaire.html#cb132-4" aria-hidden="true" tabindex="-1"></a>                  )</span>
<span id="cb132-5"><a href="régression-linéaire.html#cb132-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_breed)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu + 
##     factor(breed)), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9882 -0.8871 -0.0977  0.8370  4.0193 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     4.853e+00  1.117e-01  43.433  &lt; 2e-16 ***
## kgmilk_ct      -2.860e-02  1.026e-02  -2.787  0.00541 ** 
## kgmilk_ct_sq    3.754e-03  7.168e-04   5.237 1.94e-07 ***
## kgmilk_ct_cu   -7.864e-05  5.960e-05  -1.320  0.18726    
## factor(breed)2  1.880e-01  1.233e-01   1.524  0.12775    
## factor(breed)3 -5.860e-01  1.454e-01  -4.029 5.98e-05 ***
## factor(breed)8 -1.474e-01  1.361e-01  -1.083  0.27923    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.35 on 1133 degrees of freedom
## Multiple R-squared:  0.0749, Adjusted R-squared:   0.07 
## F-statistic: 15.29 on 6 and 1133 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Notez que j’ai du indiquer que <em>breed</em> est une variable catégorique (parce que, dans la base de données, les catégories de races sont indiquées par des chiffres, ce qui peut laisser croire à <code>R</code> qu’il s’agit d’une variable quantitative). Voir la table suivante où je présente les estimés ajustés ou non pour <em>breed</em>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-217">Table 6.5: </span>Estimés de l’effet de la production laitière sans (inconditionelle) et avec (conditionelle) ajustement pour breed.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Inconditionnelle
</th>
<th style="text-align:right;">
Conditionelle
</th>
<th style="text-align:right;">
Diff_relative_breed
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
kgmilk_ct
</td>
<td style="text-align:right;">
-0.0128
</td>
<td style="text-align:right;">
-0.0286
</td>
<td style="text-align:right;">
-123
</td>
</tr>
<tr>
<td style="text-align:left;">
kgmilk_ct_sq
</td>
<td style="text-align:right;">
0.0042
</td>
<td style="text-align:right;">
0.0038
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
kgmilk_ct_cu
</td>
<td style="text-align:right;">
-0.0001
</td>
<td style="text-align:right;">
-0.0001
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<ol start="8" style="list-style-type: decimal">
<li>Afin de réduire votre modèle maximum, vous décidez de retirer du modèle les facteurs confondants hypothétiques qui causaient une modification relative &lt; 10% de la mesure d’effet de <em>kgmilk</em>. Quel(s) facteur(s) confondant(s) gardez-vous? Y-a-t-il d’autres variables que vous désirez maintenant retirer du modèle? Quel serait votre modèle final?</li>
</ol>
<p><strong>Réponse:</strong> Parité et race seront inclus comme facteur confondant (i.e. <span class="math inline">\(parity + parity^2 + breed\)</span>). Ces deux variables créaient des changements importants (123 à 170% de différence relative) pour au moins un des termes <em>kgmilk</em>. Notez que l’ajout de point d’inflexion (i.e. <span class="math inline">\(kgmilk^3\)</span>) n’est plus nécessaire maintenant (voir résultats plus bas). Ce terme pourrait être retiré.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="régression-linéaire.html#cb134-1" aria-hidden="true" tabindex="-1"></a>model_max <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb134-2"><a href="régression-linéaire.html#cb134-2" aria-hidden="true" tabindex="-1"></a>                log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq <span class="sc">+</span> <span class="fu">factor</span>(breed))</span>
<span id="cb134-3"><a href="régression-linéaire.html#cb134-3" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb134-4"><a href="régression-linéaire.html#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_max)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu + 
##     parity_ct + parity_ct_sq + factor(breed)), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3616 -0.8233 -0.0648  0.8125  4.1456 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     4.406e+00  1.146e-01  38.463  &lt; 2e-16 ***
## kgmilk_ct      -5.924e-02  1.011e-02  -5.857 6.18e-09 ***
## kgmilk_ct_sq    2.260e-03  6.934e-04   3.259  0.00115 ** 
## kgmilk_ct_cu   -2.915e-06  5.701e-05  -0.051  0.95923    
## parity_ct       5.745e-01  6.950e-02   8.265 3.88e-16 ***
## parity_ct_sq   -6.241e-02  1.468e-02  -4.252 2.29e-05 ***
## factor(breed)2  2.043e-01  1.174e-01   1.741  0.08201 .  
## factor(breed)3 -7.932e-01  1.395e-01  -5.685 1.66e-08 ***
## factor(breed)8 -9.039e-02  1.296e-01  -0.697  0.48573    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.282 on 1130 degrees of freedom
##   (1 observation effacée parce que manquante)
## Multiple R-squared:  0.1679, Adjusted R-squared:  0.162 
## F-statistic:  28.5 on 8 and 1130 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Le modèle final serait: <span class="math inline">\(Log(cellcount) = β_0 + β_1*kgmilk + β_2*kgmilk^2 + β_3*parity + β_4*parity^2 + β_5*breed\)</span> et voici les résultats de ce modèle:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="régression-linéaire.html#cb136-1" aria-hidden="true" tabindex="-1"></a>model_final <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, </span>
<span id="cb136-2"><a href="régression-linéaire.html#cb136-2" aria-hidden="true" tabindex="-1"></a>                  log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq <span class="sc">+</span> <span class="fu">factor</span>(breed))</span>
<span id="cb136-3"><a href="régression-linéaire.html#cb136-3" aria-hidden="true" tabindex="-1"></a>                  )</span>
<span id="cb136-4"><a href="régression-linéaire.html#cb136-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_final)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + parity_ct + 
##     parity_ct_sq + factor(breed)), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3612 -0.8246 -0.0672  0.8113  4.1447 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     4.406646   0.114237  38.574  &lt; 2e-16 ***
## kgmilk_ct      -0.059636   0.006509  -9.161  &lt; 2e-16 ***
## kgmilk_ct_sq    0.002244   0.000615   3.648 0.000276 ***
## parity_ct       0.574849   0.069058   8.324 2.43e-16 ***
## parity_ct_sq   -0.062466   0.014629  -4.270 2.12e-05 ***
## factor(breed)2  0.204097   0.117247   1.741 0.081999 .  
## factor(breed)3 -0.794119   0.138230  -5.745 1.18e-08 ***
## factor(breed)8 -0.090508   0.129543  -0.699 0.484900    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.281 on 1131 degrees of freedom
##   (1 observation effacée parce que manquante)
## Multiple R-squared:  0.1679, Adjusted R-squared:  0.1628 
## F-statistic:  32.6 on 7 and 1131 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>Évaluez si les suppositions de votre modèle final sont respectées.</li>
</ol>
<p><strong>Réponse:</strong> Homoscédasticité semble OK (voir figure plus bas). Il ne semble pas y avoir d’augmentation ou de diminution flagrante de la variance des résiduels (à l’exception des extrémités, mais il y a très peu d’observations avec une valeur prédite &gt; 6).</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="régression-linéaire.html#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final, <span class="dv">1</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-220"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-220-1.png" alt="Graphiques des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.26: Graphiques des résiduels x valeurs prédites.
</p>
</div>
<p><strong>Réponse:</strong> Normalité des résiduels semble OK (voir figure plus bas). Il y a à peine une 30aine d’observations qui ne tombent pas sur la droite de 45 degrés).</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="régression-linéaire.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final, <span class="dv">2</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-221"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-221-1.png" alt="Graphiques Q-Q des résiduels" width="672" />
<p class="caption">
Figure 6.27: Graphiques Q-Q des résiduels
</p>
</div>
<ol start="10" style="list-style-type: decimal">
<li>Évaluez les observations extrêmes, leviers et influentes (nombre, profil commun).<br />
10.1. Quelle est la valeur de <em>cellcount</em> pour les observations avec les résiduels négatifs les plus larges?</li>
</ol>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="régression-linéaire.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb140-2"><a href="régression-linéaire.html#cb140-2" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(model_final) <span class="co">#Nous créons un nouveau jeu de données dans laquelle les résiduels, distance de cook, etc, se trouvent maintenant</span></span>
<span id="cb140-3"><a href="régression-linéaire.html#cb140-3" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, (.std.resid <span class="sc">&lt;</span> <span class="sc">-</span><span class="fl">3.0</span>)) <span class="co">#Gardons seulement les résiduels standardisés &lt;-3.0</span></span>
<span id="cb140-4"><a href="régression-linéaire.html#cb140-4" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> diag_res[<span class="fu">order</span>(<span class="sc">-</span>diag_res<span class="sc">$</span>.std.resid),] <span class="co">#Plaçons les résiduels en ordre décroissant</span></span>
<span id="cb140-5"><a href="régression-linéaire.html#cb140-5" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(diag_res) <span class="co">#Enlever les valeurs manquantes</span></span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-223">Table 6.6: </span>Observations avec les résiduels négatifs les plus larges.
</caption>
<thead>
<tr>
<th style="text-align:left;">
.rownames
</th>
<th style="text-align:right;">
log_cell
</th>
<th style="text-align:right;">
kgmilk_ct
</th>
<th style="text-align:right;">
kgmilk_ct_sq
</th>
<th style="text-align:right;">
parity_ct
</th>
<th style="text-align:right;">
parity_ct_sq
</th>
<th style="text-align:left;">
factor(breed)
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.resid
</th>
<th style="text-align:right;">
.hat
</th>
<th style="text-align:right;">
.sigma
</th>
<th style="text-align:right;">
.cooksd
</th>
<th style="text-align:right;">
.std.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
107
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.4
</td>
<td style="text-align:right;">
5.76
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
3.994707
</td>
<td style="text-align:right;">
-3.994707
</td>
<td style="text-align:right;">
0.0069269
</td>
<td style="text-align:right;">
1.276052
</td>
<td style="text-align:right;">
0.0085374
</td>
<td style="text-align:right;">
-3.129175
</td>
</tr>
<tr>
<td style="text-align:left;">
114
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.1
</td>
<td style="text-align:right;">
4.41
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
4.009569
</td>
<td style="text-align:right;">
-4.009569
</td>
<td style="text-align:right;">
0.0068426
</td>
<td style="text-align:right;">
1.276011
</td>
<td style="text-align:right;">
0.0084950
</td>
<td style="text-align:right;">
-3.140684
</td>
</tr>
<tr>
<td style="text-align:left;">
100
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.2
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
4.136926
</td>
<td style="text-align:right;">
-4.136926
</td>
<td style="text-align:right;">
0.0062477
</td>
<td style="text-align:right;">
1.275652
</td>
<td style="text-align:right;">
0.0082471
</td>
<td style="text-align:right;">
-3.239472
</td>
</tr>
<tr>
<td style="text-align:left;">
595
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3.1
</td>
<td style="text-align:right;">
9.61
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
4.152829
</td>
<td style="text-align:right;">
-4.152829
</td>
<td style="text-align:right;">
0.0052622
</td>
<td style="text-align:right;">
1.275612
</td>
<td style="text-align:right;">
0.0069859
</td>
<td style="text-align:right;">
-3.250314
</td>
</tr>
<tr>
<td style="text-align:left;">
594
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.3
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
4.334230
</td>
<td style="text-align:right;">
-4.334230
</td>
<td style="text-align:right;">
0.0048561
</td>
<td style="text-align:right;">
1.275078
</td>
<td style="text-align:right;">
0.0070164
</td>
<td style="text-align:right;">
-3.391600
</td>
</tr>
<tr>
<td style="text-align:left;">
155
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.0
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
4.402063
</td>
<td style="text-align:right;">
-4.402063
</td>
<td style="text-align:right;">
0.0070718
</td>
<td style="text-align:right;">
1.274856
</td>
<td style="text-align:right;">
0.0105873
</td>
<td style="text-align:right;">
-3.448521
</td>
</tr>
<tr>
<td style="text-align:left;">
785
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.0
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
4.402063
</td>
<td style="text-align:right;">
-4.402063
</td>
<td style="text-align:right;">
0.0070718
</td>
<td style="text-align:right;">
1.274856
</td>
<td style="text-align:right;">
0.0105873
</td>
<td style="text-align:right;">
-3.448521
</td>
</tr>
<tr>
<td style="text-align:left;">
151
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1.2
</td>
<td style="text-align:right;">
1.44
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
4.587153
</td>
<td style="text-align:right;">
-4.587153
</td>
<td style="text-align:right;">
0.0065241
</td>
<td style="text-align:right;">
1.274278
</td>
<td style="text-align:right;">
0.0105943
</td>
<td style="text-align:right;">
-3.592527
</td>
</tr>
<tr>
<td style="text-align:left;">
781
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1.2
</td>
<td style="text-align:right;">
1.44
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
4.587153
</td>
<td style="text-align:right;">
-4.587153
</td>
<td style="text-align:right;">
0.0065241
</td>
<td style="text-align:right;">
1.274278
</td>
<td style="text-align:right;">
0.0105943
</td>
<td style="text-align:right;">
-3.592527
</td>
</tr>
<tr>
<td style="text-align:left;">
113
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-3.0
</td>
<td style="text-align:right;">
9.00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
4.605745
</td>
<td style="text-align:right;">
-4.605745
</td>
<td style="text-align:right;">
0.0074727
</td>
<td style="text-align:right;">
1.274212
</td>
<td style="text-align:right;">
0.0122567
</td>
<td style="text-align:right;">
-3.608812
</td>
</tr>
<tr>
<td style="text-align:left;">
250
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.8
</td>
<td style="text-align:right;">
7.84
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.361186
</td>
<td style="text-align:right;">
-5.361186
</td>
<td style="text-align:right;">
0.0036766
</td>
<td style="text-align:right;">
1.271613
</td>
<td style="text-align:right;">
0.0081088
</td>
<td style="text-align:right;">
-4.192724
</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> le log(<em>cellcount</em>) est 0.0 (donc un <em>cellcount</em> de 1 x 1000 cellules/ml).</p>
<p>10.2. Une valeur de 1,000 cell./ml est assez inusitée pour un comptage des cellules somatiques. En fait la limite analytique du Fossomatic cell counter est généralement de 10,000 cell./ml. Vous appelez donc le laboratoire pour en savoir plus sur ces résultats. On vous dit qu’on donne la valeur « 1 » aux échantillons qui ne peuvent être analysés (échappés, mal conservés, etc). Il s’agit donc d’observations manquantes! Vous pouvez donc ré-évaluer le modèle en excluant ces observations (et en priant pour que les résultats changent peu).</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="régression-linéaire.html#cb141-1" aria-hidden="true" tabindex="-1"></a>milk2_corrected <span class="ot">&lt;-</span> <span class="fu">subset</span>(milk2, milk2<span class="sc">$</span>cellcount<span class="sc">&gt;</span><span class="dv">10</span>)</span>
<span id="cb141-2"><a href="régression-linéaire.html#cb141-2" aria-hidden="true" tabindex="-1"></a>milk2_corrected<span class="sc">$</span>breed <span class="ot">&lt;-</span> <span class="fu">factor</span>(milk2_corrected<span class="sc">$</span>breed)</span>
<span id="cb141-3"><a href="régression-linéaire.html#cb141-3" aria-hidden="true" tabindex="-1"></a>model_final2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2_corrected, </span>
<span id="cb141-4"><a href="régression-linéaire.html#cb141-4" aria-hidden="true" tabindex="-1"></a>                   log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq <span class="sc">+</span> breed)</span>
<span id="cb141-5"><a href="régression-linéaire.html#cb141-5" aria-hidden="true" tabindex="-1"></a>                   )</span>
<span id="cb141-6"><a href="régression-linéaire.html#cb141-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_final2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + parity_ct + 
##     parity_ct_sq + breed), data = milk2_corrected)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6932 -0.8179 -0.1134  0.7179  4.0391 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.5993247  0.1070076  42.981  &lt; 2e-16 ***
## kgmilk_ct    -0.0472845  0.0060207  -7.854 9.61e-15 ***
## kgmilk_ct_sq  0.0014894  0.0005636   2.643  0.00834 ** 
## parity_ct     0.5513005  0.0638717   8.631  &lt; 2e-16 ***
## parity_ct_sq -0.0595009  0.0135340  -4.396 1.21e-05 ***
## breed2        0.0759856  0.1090067   0.697  0.48591    
## breed3       -0.6004440  0.1300708  -4.616 4.37e-06 ***
## breed8       -0.1529191  0.1207002  -1.267  0.20545    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.168 on 1093 degrees of freedom
##   (1 observation effacée parce que manquante)
## Multiple R-squared:  0.1512, Adjusted R-squared:  0.1458 
## F-statistic: 27.81 on 7 and 1093 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="régression-linéaire.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final2, <span class="dv">1</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-224"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-224-1.png" alt="Graphiques des résiduels x valeurs prédites." width="672" />
<p class="caption">
Figure 6.28: Graphiques des résiduels x valeurs prédites.
</p>
</div>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="régression-linéaire.html#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final2, <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-225"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-225-1.png" alt="Graphiques Q-Q des résiduels." width="672" />
<p class="caption">
Figure 6.29: Graphiques Q-Q des résiduels.
</p>
</div>
<p>Notez comment votre Q-Q plot et l’histogramme des résiduels sont encore mieux sans ces observations. Combien d’observations avec un résiduel large (&gt;3 ou &lt;-3) avez-vous? Ces observations ont-elles quelque chose en commun?</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="régression-linéaire.html#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb145-2"><a href="régression-linéaire.html#cb145-2" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(model_final2) </span>
<span id="cb145-3"><a href="régression-linéaire.html#cb145-3" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, (.std.resid <span class="sc">&lt;</span> <span class="sc">-</span><span class="fl">3.0</span> <span class="sc">|</span> .std.resid <span class="sc">&gt;</span> <span class="fl">3.0</span>)) <span class="co">#Gardons seulement les résiduels standardisés &lt;-3.0 ou &gt;3.0</span></span>
<span id="cb145-4"><a href="régression-linéaire.html#cb145-4" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> diag_res[<span class="fu">order</span>(diag_res<span class="sc">$</span>.std.resid),] <span class="co">#Plaçons les résiduels en ordre croissant</span></span>
<span id="cb145-5"><a href="régression-linéaire.html#cb145-5" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(diag_res) <span class="co">#Enlever les valeurs manquantes</span></span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-227">Table 6.7: </span>Observations avec les résiduels négatifs et positifs les plus larges.
</caption>
<thead>
<tr>
<th style="text-align:left;">
.rownames
</th>
<th style="text-align:right;">
log_cell
</th>
<th style="text-align:right;">
kgmilk_ct
</th>
<th style="text-align:right;">
kgmilk_ct_sq
</th>
<th style="text-align:right;">
parity_ct
</th>
<th style="text-align:right;">
parity_ct_sq
</th>
<th style="text-align:left;">
breed
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.resid
</th>
<th style="text-align:right;">
.hat
</th>
<th style="text-align:right;">
.sigma
</th>
<th style="text-align:right;">
.cooksd
</th>
<th style="text-align:right;">
.std.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1078
</td>
<td style="text-align:right;">
8.214465
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
4.599325
</td>
<td style="text-align:right;">
3.615140
</td>
<td style="text-align:right;">
0.0083997
</td>
<td style="text-align:right;">
1.162928
</td>
<td style="text-align:right;">
0.0102372
</td>
<td style="text-align:right;">
3.109376
</td>
</tr>
<tr>
<td style="text-align:left;">
327
</td>
<td style="text-align:right;">
8.667852
</td>
<td style="text-align:right;">
-5.5
</td>
<td style="text-align:right;">
30.25
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
4.980429
</td>
<td style="text-align:right;">
3.687423
</td>
<td style="text-align:right;">
0.0038030
</td>
<td style="text-align:right;">
1.162744
</td>
<td style="text-align:right;">
0.0047777
</td>
<td style="text-align:right;">
3.164221
</td>
</tr>
<tr>
<td style="text-align:left;">
856
</td>
<td style="text-align:right;">
8.731498
</td>
<td style="text-align:right;">
-4.8
</td>
<td style="text-align:right;">
23.04
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
4.707686
</td>
<td style="text-align:right;">
4.023811
</td>
<td style="text-align:right;">
0.0053392
</td>
<td style="text-align:right;">
1.161708
</td>
<td style="text-align:right;">
0.0080121
</td>
<td style="text-align:right;">
3.455545
</td>
</tr>
<tr>
<td style="text-align:left;">
444
</td>
<td style="text-align:right;">
8.575462
</td>
<td style="text-align:right;">
-1.8
</td>
<td style="text-align:right;">
3.24
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
4.536343
</td>
<td style="text-align:right;">
4.039119
</td>
<td style="text-align:right;">
0.0050420
</td>
<td style="text-align:right;">
1.161661
</td>
<td style="text-align:right;">
0.0076191
</td>
<td style="text-align:right;">
3.468173
</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> Il y a seulement 4 observations extrêmes. Seulement des résiduels positifs (i.e. le modèle sous-estime la vraie valeur). Toutes des 1ère lactation. Un cellcount élevé (i.e. &gt; 3,000,000 cell./ml), mais des production assez moyennes. Différentes races. Le modèle a donc de la difficulté (i.e. il sous estime) la valeur de <em>cellcount</em> pour les vaches de 1ère lactation avec un <em>cellcount</em> élevé.</p>
<p>10.3. Vérifiez maintenant les 10 observations avec les leviers les plus grands. Ont-elles quelque chose en commun?</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="régression-linéaire.html#cb146-1" aria-hidden="true" tabindex="-1"></a>diag_hat <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.hat),]</span>
<span id="cb146-2"><a href="régression-linéaire.html#cb146-2" aria-hidden="true" tabindex="-1"></a>levier <span class="ot">&lt;-</span> <span class="fu">head</span>(diag_hat, <span class="dv">10</span>)</span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-229">Table 6.8: </span>Observations avec les leviers les plus grands.
</caption>
<thead>
<tr>
<th style="text-align:left;">
.rownames
</th>
<th style="text-align:right;">
log_cell
</th>
<th style="text-align:right;">
kgmilk_ct
</th>
<th style="text-align:right;">
kgmilk_ct_sq
</th>
<th style="text-align:right;">
parity_ct
</th>
<th style="text-align:right;">
parity_ct_sq
</th>
<th style="text-align:left;">
breed
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.resid
</th>
<th style="text-align:right;">
.hat
</th>
<th style="text-align:right;">
.sigma
</th>
<th style="text-align:right;">
.cooksd
</th>
<th style="text-align:right;">
.std.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
445
</td>
<td style="text-align:right;">
6.975414
</td>
<td style="text-align:right;">
14.0
</td>
<td style="text-align:right;">
196.00
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.248804
</td>
<td style="text-align:right;">
1.7266102
</td>
<td style="text-align:right;">
0.0842281
</td>
<td style="text-align:right;">
1.166829
</td>
<td style="text-align:right;">
0.0274545
</td>
<td style="text-align:right;">
1.5453153
</td>
</tr>
<tr>
<td style="text-align:left;">
812
</td>
<td style="text-align:right;">
6.042633
</td>
<td style="text-align:right;">
-5.4
</td>
<td style="text-align:right;">
29.16
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
5.241207
</td>
<td style="text-align:right;">
0.8014259
</td>
<td style="text-align:right;">
0.0815466
</td>
<td style="text-align:right;">
1.167832
</td>
<td style="text-align:right;">
0.0056933
</td>
<td style="text-align:right;">
0.7162279
</td>
</tr>
<tr>
<td style="text-align:left;">
84
</td>
<td style="text-align:right;">
5.669881
</td>
<td style="text-align:right;">
-3.8
</td>
<td style="text-align:right;">
14.44
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
5.143628
</td>
<td style="text-align:right;">
0.5262528
</td>
<td style="text-align:right;">
0.0814274
</td>
<td style="text-align:right;">
1.167988
</td>
<td style="text-align:right;">
0.0024506
</td>
<td style="text-align:right;">
0.4702774
</td>
</tr>
<tr>
<td style="text-align:left;">
761
</td>
<td style="text-align:right;">
5.669881
</td>
<td style="text-align:right;">
-3.8
</td>
<td style="text-align:right;">
14.44
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
5.143628
</td>
<td style="text-align:right;">
0.5262528
</td>
<td style="text-align:right;">
0.0814274
</td>
<td style="text-align:right;">
1.167988
</td>
<td style="text-align:right;">
0.0024506
</td>
<td style="text-align:right;">
0.4702774
</td>
</tr>
<tr>
<td style="text-align:left;">
446
</td>
<td style="text-align:right;">
3.688880
</td>
<td style="text-align:right;">
10.8
</td>
<td style="text-align:right;">
116.64
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.281918
</td>
<td style="text-align:right;">
-1.5930382
</td>
<td style="text-align:right;">
0.0801917
</td>
<td style="text-align:right;">
1.167024
</td>
<td style="text-align:right;">
0.0220562
</td>
<td style="text-align:right;">
-1.4226366
</td>
</tr>
<tr>
<td style="text-align:left;">
500
</td>
<td style="text-align:right;">
3.912023
</td>
<td style="text-align:right;">
23.1
</td>
<td style="text-align:right;">
533.61
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.630969
</td>
<td style="text-align:right;">
-1.7189460
</td>
<td style="text-align:right;">
0.0571116
</td>
<td style="text-align:right;">
1.166877
</td>
<td style="text-align:right;">
0.0174049
</td>
<td style="text-align:right;">
-1.5161721
</td>
</tr>
<tr>
<td style="text-align:left;">
1116
</td>
<td style="text-align:right;">
4.499810
</td>
<td style="text-align:right;">
21.8
</td>
<td style="text-align:right;">
475.24
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.470710
</td>
<td style="text-align:right;">
-0.9709003
</td>
<td style="text-align:right;">
0.0447326
</td>
<td style="text-align:right;">
1.167719
</td>
<td style="text-align:right;">
0.0042371
</td>
<td style="text-align:right;">
-0.8508022
</td>
</tr>
<tr>
<td style="text-align:left;">
733
</td>
<td style="text-align:right;">
6.327937
</td>
<td style="text-align:right;">
-1.0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
5.813870
</td>
<td style="text-align:right;">
0.5140673
</td>
<td style="text-align:right;">
0.0403140
</td>
<td style="text-align:right;">
1.167998
</td>
<td style="text-align:right;">
0.0010607
</td>
<td style="text-align:right;">
0.4494401
</td>
</tr>
<tr>
<td style="text-align:left;">
813
</td>
<td style="text-align:right;">
4.812184
</td>
<td style="text-align:right;">
0.4
</td>
<td style="text-align:right;">
0.16
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
5.593501
</td>
<td style="text-align:right;">
-0.7813167
</td>
<td style="text-align:right;">
0.0380738
</td>
<td style="text-align:right;">
1.167857
</td>
<td style="text-align:right;">
0.0023032
</td>
<td style="text-align:right;">
-0.6822957
</td>
</tr>
<tr>
<td style="text-align:left;">
210
</td>
<td style="text-align:right;">
4.663439
</td>
<td style="text-align:right;">
20.9
</td>
<td style="text-align:right;">
436.81
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.456029
</td>
<td style="text-align:right;">
-0.7925905
</td>
<td style="text-align:right;">
0.0377796
</td>
<td style="text-align:right;">
1.167850
</td>
<td style="text-align:right;">
0.0023504
</td>
<td style="text-align:right;">
-0.6920349
</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> Beaucoup de parité 8, <em>production</em>, <em>race</em> et <em>cellcount</em> assez variés. En fait, être une 8ième lactation, peu importe le niveau des autres prédicteurs, semble être une combinaison de prédicteurs inusitée.</p>
<p>10.4. Vérifiez maintenant les 10 observations les plus influentes. Ont-elles quelque chose en commun?</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="régression-linéaire.html#cb147-1" aria-hidden="true" tabindex="-1"></a>diag_cook <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.cooksd),]</span>
<span id="cb147-2"><a href="régression-linéaire.html#cb147-2" aria-hidden="true" tabindex="-1"></a>influent <span class="ot">&lt;-</span> <span class="fu">head</span>(diag_cook, <span class="dv">10</span>)</span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-231">Table 6.9: </span>Observations les plus influentes.
</caption>
<thead>
<tr>
<th style="text-align:left;">
.rownames
</th>
<th style="text-align:right;">
log_cell
</th>
<th style="text-align:right;">
kgmilk_ct
</th>
<th style="text-align:right;">
kgmilk_ct_sq
</th>
<th style="text-align:right;">
parity_ct
</th>
<th style="text-align:right;">
parity_ct_sq
</th>
<th style="text-align:left;">
breed
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.resid
</th>
<th style="text-align:right;">
.hat
</th>
<th style="text-align:right;">
.sigma
</th>
<th style="text-align:right;">
.cooksd
</th>
<th style="text-align:right;">
.std.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
445
</td>
<td style="text-align:right;">
6.975414
</td>
<td style="text-align:right;">
14.0
</td>
<td style="text-align:right;">
196.00
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.248804
</td>
<td style="text-align:right;">
1.726610
</td>
<td style="text-align:right;">
0.0842281
</td>
<td style="text-align:right;">
1.166829
</td>
<td style="text-align:right;">
0.0274545
</td>
<td style="text-align:right;">
1.545315
</td>
</tr>
<tr>
<td style="text-align:left;">
446
</td>
<td style="text-align:right;">
3.688880
</td>
<td style="text-align:right;">
10.8
</td>
<td style="text-align:right;">
116.64
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.281918
</td>
<td style="text-align:right;">
-1.593038
</td>
<td style="text-align:right;">
0.0801917
</td>
<td style="text-align:right;">
1.167024
</td>
<td style="text-align:right;">
0.0220562
</td>
<td style="text-align:right;">
-1.422637
</td>
</tr>
<tr>
<td style="text-align:left;">
214
</td>
<td style="text-align:right;">
7.634821
</td>
<td style="text-align:right;">
20.2
</td>
<td style="text-align:right;">
408.04
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.192483
</td>
<td style="text-align:right;">
2.442337
</td>
<td style="text-align:right;">
0.0341968
</td>
<td style="text-align:right;">
1.165683
</td>
<td style="text-align:right;">
0.0200522
</td>
<td style="text-align:right;">
2.128520
</td>
</tr>
<tr>
<td style="text-align:left;">
874
</td>
<td style="text-align:right;">
7.903966
</td>
<td style="text-align:right;">
9.8
</td>
<td style="text-align:right;">
96.04
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.520732
</td>
<td style="text-align:right;">
2.383233
</td>
<td style="text-align:right;">
0.0344921
</td>
<td style="text-align:right;">
1.165798
</td>
<td style="text-align:right;">
0.0192701
</td>
<td style="text-align:right;">
2.077328
</td>
</tr>
<tr>
<td style="text-align:left;">
500
</td>
<td style="text-align:right;">
3.912023
</td>
<td style="text-align:right;">
23.1
</td>
<td style="text-align:right;">
533.61
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.630969
</td>
<td style="text-align:right;">
-1.718946
</td>
<td style="text-align:right;">
0.0571116
</td>
<td style="text-align:right;">
1.166877
</td>
<td style="text-align:right;">
0.0174049
</td>
<td style="text-align:right;">
-1.516172
</td>
</tr>
<tr>
<td style="text-align:left;">
916
</td>
<td style="text-align:right;">
8.984318
</td>
<td style="text-align:right;">
-14.0
</td>
<td style="text-align:right;">
196.00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.629210
</td>
<td style="text-align:right;">
3.355108
</td>
<td style="text-align:right;">
0.0154246
</td>
<td style="text-align:right;">
1.163616
</td>
<td style="text-align:right;">
0.0164238
</td>
<td style="text-align:right;">
2.895999
</td>
</tr>
<tr>
<td style="text-align:left;">
488
</td>
<td style="text-align:right;">
8.999619
</td>
<td style="text-align:right;">
1.9
</td>
<td style="text-align:right;">
3.61
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.859827
</td>
<td style="text-align:right;">
3.139793
</td>
<td style="text-align:right;">
0.0143365
</td>
<td style="text-align:right;">
1.164179
</td>
<td style="text-align:right;">
0.0133392
</td>
<td style="text-align:right;">
2.708651
</td>
</tr>
<tr>
<td style="text-align:left;">
880
</td>
<td style="text-align:right;">
6.853299
</td>
<td style="text-align:right;">
18.8
</td>
<td style="text-align:right;">
353.44
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
4.948457
</td>
<td style="text-align:right;">
1.904842
</td>
<td style="text-align:right;">
0.0306928
</td>
<td style="text-align:right;">
1.166638
</td>
<td style="text-align:right;">
0.0108686
</td>
<td style="text-align:right;">
1.657084
</td>
</tr>
<tr>
<td style="text-align:left;">
1078
</td>
<td style="text-align:right;">
8.214465
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
4.599325
</td>
<td style="text-align:right;">
3.615140
</td>
<td style="text-align:right;">
0.0083997
</td>
<td style="text-align:right;">
1.162928
</td>
<td style="text-align:right;">
0.0102372
</td>
<td style="text-align:right;">
3.109376
</td>
</tr>
<tr>
<td style="text-align:left;">
1080
</td>
<td style="text-align:right;">
3.850148
</td>
<td style="text-align:right;">
11.4
</td>
<td style="text-align:right;">
129.96
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.495597
</td>
<td style="text-align:right;">
-1.645449
</td>
<td style="text-align:right;">
0.0354268
</td>
<td style="text-align:right;">
1.167005
</td>
<td style="text-align:right;">
0.0094531
</td>
<td style="text-align:right;">
-1.434938
</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> Il y a peu d’observations influentes et on voit difficilement un profil type en termes de parité, production, race (beaucoup de Holstein, mais c’est aussi la race la plus fréquente dans le jeu de données) ou de CCS.</p>
<ol start="11" style="list-style-type: decimal">
<li>Présentation des résultats.<br />
11.1. Présentez les résultats de votre modèle dans une table que vous pourriez soumettre dans une publication scientifique.</li>
</ol>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="régression-linéaire.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le package jtools et la fonction summ permettent de générer des tables de résultats un peu plus attrayantes que la fonction summary</span></span>
<span id="cb148-2"><a href="régression-linéaire.html#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jtools)</span>
<span id="cb148-3"><a href="régression-linéaire.html#cb148-3" aria-hidden="true" tabindex="-1"></a>j <span class="ot">&lt;-</span> <span class="fu">summ</span>(model_final2, </span>
<span id="cb148-4"><a href="régression-linéaire.html#cb148-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">confint =</span> <span class="cn">TRUE</span>) <span class="co">#Nous créons un objet j qui contiendra différents éléments. Ici nous avons demandé d&#39;utiliser les IC95 (plutôt que les erreur-types).</span></span>
<span id="cb148-5"><a href="régression-linéaire.html#cb148-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-6"><a href="régression-linéaire.html#cb148-6" aria-hidden="true" tabindex="-1"></a>j<span class="sc">$</span>coeftable <span class="co">#L&#39;élément de j qui se nomme coeftable contient les coefficients, les IC95 (ou les erreur-types), les valeurs de T, las valeurs de P.</span></span></code></pre></div>
<pre><code>##                     Est.          2.5%        97.5%     t val.             p
## (Intercept)   4.59932473  4.3893612016  4.809288257 42.9812943 4.033724e-237
## kgmilk_ct    -0.04728450 -0.0590979988 -0.035471011 -7.8536177  9.609453e-15
## kgmilk_ct_sq  0.00148937  0.0003835792  0.002595162  2.6427669  8.340726e-03
## parity_ct     0.55130050  0.4259755597  0.676625440  8.6313784  2.110234e-17
## parity_ct_sq -0.05950089 -0.0860565013 -0.032945281 -4.3963925  1.207990e-05
## breed2        0.07598558 -0.1379004787  0.289871635  0.6970725  4.859056e-01
## breed3       -0.60044404 -0.8556607831 -0.345227288 -4.6162853  4.369817e-06
## breed8       -0.15291913 -0.3897495271  0.083911261 -1.2669331  2.054491e-01</code></pre>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="régression-linéaire.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Dans RMarkdown, pour une sortie plus &#39;propre&#39;, nous pouvons créer une table avec la fonction kable du package knitr. </span></span>
<span id="cb150-2"><a href="régression-linéaire.html#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb150-3"><a href="régression-linéaire.html#cb150-3" aria-hidden="true" tabindex="-1"></a>Pres_table <span class="ot">&lt;-</span> <span class="fu">kable</span>(j<span class="sc">$</span>coeftable,  </span>
<span id="cb150-4"><a href="régression-linéaire.html#cb150-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">caption=</span><span class="st">&quot;Modèle de régression linéaire multiple sur l’effet de la production laitière journalière (en kg) sur le log du comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) basé sur l’étude de 1128 vaches.&quot;</span>, <span class="co">#Titre de la table.</span></span>
<span id="cb150-5"><a href="régression-linéaire.html#cb150-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">digits=</span><span class="dv">3</span>, <span class="co">#Indique le nombre de décimales que nous désirons présenter.</span></span>
<span id="cb150-6"><a href="régression-linéaire.html#cb150-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;Estimés&#39;</span>, <span class="st">&#39;IC 95 inférieure&#39;</span>, <span class="st">&#39;IC95 supérieure&#39;</span>, <span class="st">&#39;Statistique de T&#39;</span>,<span class="st">&#39;Valeur de P&#39;</span>)</span>
<span id="cb150-7"><a href="régression-linéaire.html#cb150-7" aria-hidden="true" tabindex="-1"></a>                    ) <span class="co">#Renommer les titres des colonnes</span></span>
<span id="cb150-8"><a href="régression-linéaire.html#cb150-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-9"><a href="régression-linéaire.html#cb150-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Le package KableExtra permet d&#39;ajouter des &#39;footnotes&#39; à la table que nous venons de créer</span></span>
<span id="cb150-10"><a href="régression-linéaire.html#cb150-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb150-11"><a href="régression-linéaire.html#cb150-11" aria-hidden="true" tabindex="-1"></a><span class="fu">add_footnote</span>(Pres_table, <span class="st">&quot;L&#39;intercept représente le log du CCS (en 1000 cellules/ml) pour une vache Ayrshire de 1ère lactation et produisant 20kg de lait. Les variables Parity et Breed sont incluses dans le modèle comme facteurs confondants. La race Ayrshire est utilisée comme valeur de référence pour la variable Breed; breed2=Holstein, breed3=Jersey et breed8=autres races.&quot;</span>,</span>
<span id="cb150-12"><a href="régression-linéaire.html#cb150-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">notation =</span> <span class="st">&quot;none&quot;</span></span>
<span id="cb150-13"><a href="régression-linéaire.html#cb150-13" aria-hidden="true" tabindex="-1"></a>             )<span class="sc">%&gt;%</span></span>
<span id="cb150-14"><a href="régression-linéaire.html#cb150-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-233">Table 6.10: </span>Modèle de régression linéaire multiple sur l’effet de la production laitière journalière (en kg) sur le log du comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) basé sur l’étude de 1128 vaches.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Estimés
</th>
<th style="text-align:right;">
IC 95 inférieure
</th>
<th style="text-align:right;">
IC95 supérieure
</th>
<th style="text-align:right;">
Statistique de T
</th>
<th style="text-align:right;">
Valeur de P
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
4.599
</td>
<td style="text-align:right;">
4.389
</td>
<td style="text-align:right;">
4.809
</td>
<td style="text-align:right;">
42.981
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
kgmilk_ct
</td>
<td style="text-align:right;">
-0.047
</td>
<td style="text-align:right;">
-0.059
</td>
<td style="text-align:right;">
-0.035
</td>
<td style="text-align:right;">
-7.854
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
kgmilk_ct_sq
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.003
</td>
<td style="text-align:right;">
2.643
</td>
<td style="text-align:right;">
0.008
</td>
</tr>
<tr>
<td style="text-align:left;">
parity_ct
</td>
<td style="text-align:right;">
0.551
</td>
<td style="text-align:right;">
0.426
</td>
<td style="text-align:right;">
0.677
</td>
<td style="text-align:right;">
8.631
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
parity_ct_sq
</td>
<td style="text-align:right;">
-0.060
</td>
<td style="text-align:right;">
-0.086
</td>
<td style="text-align:right;">
-0.033
</td>
<td style="text-align:right;">
-4.396
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
breed2
</td>
<td style="text-align:right;">
0.076
</td>
<td style="text-align:right;">
-0.138
</td>
<td style="text-align:right;">
0.290
</td>
<td style="text-align:right;">
0.697
</td>
<td style="text-align:right;">
0.486
</td>
</tr>
<tr>
<td style="text-align:left;">
breed3
</td>
<td style="text-align:right;">
-0.600
</td>
<td style="text-align:right;">
-0.856
</td>
<td style="text-align:right;">
-0.345
</td>
<td style="text-align:right;">
-4.616
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
breed8
</td>
<td style="text-align:right;">
-0.153
</td>
<td style="text-align:right;">
-0.390
</td>
<td style="text-align:right;">
0.084
</td>
<td style="text-align:right;">
-1.267
</td>
<td style="text-align:right;">
0.205
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border:0;" colspan="100%">
<sup></sup> L’intercept représente le log du CCS (en 1000 cellules/ml) pour une vache Ayrshire de 1ère lactation et produisant 20kg de lait. Les variables Parity et Breed sont incluses dans le modèle comme facteurs confondants. La race Ayrshire est utilisée comme valeur de référence pour la variable Breed; breed2=Holstein, breed3=Jersey et breed8=autres races.
</td>
</tr>
</tfoot>
</table>
<p>L’effet de la production laitière n’est plus sur l’échelle originale. En plus, la relation entre production et CCS n’est pas linéaire. Tout ça rend votre modèle difficile à interpréter et il faudrait possiblement trouver une manière de rendre l’information plus digestible pour vos lecteurs.</p>
<p>11.2. Vous pourriez présenter comment le CCS varie en fonction de la production laitière pour différents scénarios. Vous pourriez, par exemple, compléter la table suivante, en calculant la valeur prédite pour chaque scénario à l’aide de votre modèle, puis en retransformant ces valeurs sur l’échelle originale:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-236">Table 6.11: </span>Valeurs prédites de comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) d’une vache Ayrshire pour différentes combinaisons de production et parité.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Production
</th>
<th style="text-align:center;">
1ère lactation
</th>
<th style="text-align:center;">
2ième lactation
</th>
<th style="text-align:center;">
3ième et plus
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
10kg/jour
</td>
<td style="text-align:center;">
185
</td>
<td style="text-align:center;">
303
</td>
<td style="text-align:center;">
440
</td>
</tr>
<tr>
<td style="text-align:left;">
20kg/jour
</td>
<td style="text-align:center;">
99
</td>
<td style="text-align:center;">
163
</td>
<td style="text-align:center;">
236
</td>
</tr>
<tr>
<td style="text-align:left;">
30kg/jour
</td>
<td style="text-align:center;">
72
</td>
<td style="text-align:center;">
118
</td>
<td style="text-align:center;">
171
</td>
</tr>
</tbody>
</table>
<p>11.3. Encore mieux : à partir d’une table <code>R</code> contenant les valeurs prédites, retransformez la valeur prédite sur l’échelle originale en créant une nouvelle variable <span class="math inline">\(CCS=exp(valeur prédite)\)</span>. Ensuite, vous pourrez utiliser le package <code>ggplot2</code> pour représenter dans un graphique nuage de points la relation entre la production laitière (en x) et la valeur prédite de CCS (en y).<br />
C’est plus simple à comprendre ainsi n’est-ce pas?</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="régression-linéaire.html#cb151-1" aria-hidden="true" tabindex="-1"></a>diag<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">exp</span>(diag<span class="sc">$</span>.fitted) <span class="co">#Une variable de CCS sur l&#39;échelle originale</span></span>
<span id="cb151-2"><a href="régression-linéaire.html#cb151-2" aria-hidden="true" tabindex="-1"></a>diag<span class="sc">$</span>kgmilk <span class="ot">&lt;-</span> diag<span class="sc">$</span>kgmilk_ct<span class="sc">+</span><span class="dv">20</span> <span class="co">#Recréer la variable kgmilk originale</span></span>
<span id="cb151-3"><a href="régression-linéaire.html#cb151-3" aria-hidden="true" tabindex="-1"></a>diag<span class="sc">$</span>parity <span class="ot">&lt;-</span> <span class="fu">factor</span>(diag<span class="sc">$</span>parity_ct<span class="sc">+</span><span class="dv">1</span>) <span class="co">#Recréer la variable parité originale</span></span>
<span id="cb151-4"><a href="régression-linéaire.html#cb151-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb151-5"><a href="régression-linéaire.html#cb151-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb151-6"><a href="régression-linéaire.html#cb151-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diag, </span>
<span id="cb151-7"><a href="régression-linéaire.html#cb151-7" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x=</span>kgmilk, <span class="at">y=</span>pred)</span>
<span id="cb151-8"><a href="régression-linéaire.html#cb151-8" aria-hidden="true" tabindex="-1"></a>       ) <span class="sc">+</span></span>
<span id="cb151-9"><a href="régression-linéaire.html#cb151-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">colour=</span>parity)) <span class="sc">+</span>  </span>
<span id="cb151-10"><a href="régression-linéaire.html#cb151-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Production (en kg/j)&quot;</span>, </span>
<span id="cb151-11"><a href="régression-linéaire.html#cb151-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">y=</span><span class="st">&quot;CCS (en 1000 cellules/ml)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb151-12"><a href="régression-linéaire.html#cb151-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-237"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-237-1.png" alt="Valeurs de CCS (par 1000 cell./ml) prédites par le modèle en fonction de la production laitière (en kg/j) et du nombre de lactations." width="672" />
<p class="caption">
Figure 6.30: Valeurs de CCS (par 1000 cell./ml) prédites par le modèle en fonction de la production laitière (en kg/j) et du nombre de lactations.
</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="r-markdown.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="régression-logistique.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Labo R Bookdown project.pdf", "Labo R Bookdown project.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
