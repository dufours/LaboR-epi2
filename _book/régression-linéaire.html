<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 6 Régression linéaire | Épidémiologie 2 - Labo informatique R (PTM-6675)</title>
  <meta name="description" content="Chapitre 7" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 6 Régression linéaire | Épidémiologie 2 - Labo informatique R (PTM-6675)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Chapitre 7" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 6 Régression linéaire | Épidémiologie 2 - Labo informatique R (PTM-6675)" />
  
  <meta name="twitter:description" content="Chapitre 7" />
  

<meta name="author" content="Simon Dufour (Professeur à la Faculté de Médecine vétérinaire de l’Université de Montréal)" />


<meta name="date" content="2021-03-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="r-markdown.html"/>
<link rel="next" href="régression-logistique.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Épidémiologie 2 - Labo informatique R (PTM-6675)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> À propos</a></li>
<li class="chapter" data-level="2" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html"><i class="fa fa-check"></i><b>2</b> Bonnes pratiques de gestion de projet</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#organiser-son-projet-de-recherche"><i class="fa fa-check"></i><b>2.1</b> Organiser son projet de recherche</a></li>
<li class="chapter" data-level="2.2" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#où-sauvegarder-son-projet"><i class="fa fa-check"></i><b>2.2</b> Où sauvegarder son projet</a></li>
<li class="chapter" data-level="2.3" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#où-sauvegarder-ses-données"><i class="fa fa-check"></i><b>2.3</b> Où sauvegarder ses données</a></li>
<li class="chapter" data-level="2.4" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#scripts-danalyse"><i class="fa fa-check"></i><b>2.4</b> Scripts d’analyse</a></li>
<li class="chapter" data-level="2.5" data-path="bonnes-pratiques-de-gestion-de-projet.html"><a href="bonnes-pratiques-de-gestion-de-projet.html#copies-de-sécurité"><i class="fa fa-check"></i><b>2.5</b> Copies de sécurité</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="obtention-des-données-pour-les-travaux-pratiques.html"><a href="obtention-des-données-pour-les-travaux-pratiques.html"><i class="fa fa-check"></i><b>3</b> Obtention des données pour les travaux pratiques</a></li>
<li class="chapter" data-level="4" data-path="aide-de-r.html"><a href="aide-de-r.html"><i class="fa fa-check"></i><b>4</b> Aide de R</a></li>
<li class="chapter" data-level="5" data-path="r-markdown.html"><a href="r-markdown.html"><i class="fa fa-check"></i><b>5</b> R Markdown</a></li>
<li class="chapter" data-level="6" data-path="régression-linéaire.html"><a href="régression-linéaire.html"><i class="fa fa-check"></i><b>6</b> Régression linéaire</a>
<ul>
<li class="chapter" data-level="6.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#généralités"><i class="fa fa-check"></i><b>6.1</b> Généralités</a></li>
<li class="chapter" data-level="6.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#ajouter-des-intervalles-de-confiance"><i class="fa fa-check"></i><b>6.2</b> Ajouter des intervalles de confiance</a></li>
<li class="chapter" data-level="6.3" data-path="régression-linéaire.html"><a href="régression-linéaire.html#test-de-f-pour-comparer-modèles-complet-vs.-réduit"><i class="fa fa-check"></i><b>6.3</b> Test de <em>F</em> pour comparer modèles complet <em>vs.</em> réduit</a></li>
<li class="chapter" data-level="6.4" data-path="régression-linéaire.html"><a href="régression-linéaire.html#transformer-une-variable"><i class="fa fa-check"></i><b>6.4</b> Transformer une variable</a></li>
<li class="chapter" data-level="6.5" data-path="régression-linéaire.html"><a href="régression-linéaire.html#choisir-la-valeur-de-référence-pour-une-variable-catégorique"><i class="fa fa-check"></i><b>6.5</b> Choisir la valeur de référence pour une variable catégorique</a></li>
<li class="chapter" data-level="6.6" data-path="régression-linéaire.html"><a href="régression-linéaire.html#comparer-les-niveaux-dun-prédicteur-catégorique-avec-2-catégories"><i class="fa fa-check"></i><b>6.6</b> Comparer les niveaux d’un prédicteur catégorique avec &gt;2 catégories</a></li>
<li class="chapter" data-level="6.7" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluer-une-interaction-entre-2-variables"><i class="fa fa-check"></i><b>6.7</b> Évaluer une interaction entre 2 variables</a></li>
<li class="chapter" data-level="6.8" data-path="régression-linéaire.html"><a href="régression-linéaire.html#tol-et-vif---évaluer-colinéarité"><i class="fa fa-check"></i><b>6.8</b> TOL et VIF - Évaluer colinéarité</a></li>
<li class="chapter" data-level="6.9" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluation-du-modèle"><i class="fa fa-check"></i><b>6.9</b> Évaluation du modèle</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluer-la-linéarité-de-la-relation-à-laide-de-courbes-lissées-pour-prédicteur-quantitatif"><i class="fa fa-check"></i><b>6.9.1</b> Évaluer la linéarité de la relation à l’aide de courbes lissées (pour prédicteur quantitatif)</a></li>
<li class="chapter" data-level="6.9.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#méthodes-diagnostiques-pour-les-résiduels"><i class="fa fa-check"></i><b>6.9.2</b> Méthodes diagnostiques pour les résiduels</a></li>
<li class="chapter" data-level="6.9.3" data-path="régression-linéaire.html"><a href="régression-linéaire.html#évaluation-des-observations-extrêmes-etou-influentes"><i class="fa fa-check"></i><b>6.9.3</b> Évaluation des observations extrêmes et/ou influentes</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="régression-linéaire.html"><a href="régression-linéaire.html#travaux-pratiques-1---régression-linéaire---base"><i class="fa fa-check"></i><b>6.10</b> Travaux pratiques 1 - Régression linéaire - Base</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#exercices"><i class="fa fa-check"></i><b>6.10.1</b> Exercices</a></li>
<li class="chapter" data-level="6.10.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#code-r-et-réponses"><i class="fa fa-check"></i><b>6.10.2</b> Code R et réponses</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="régression-linéaire.html"><a href="régression-linéaire.html#travaux-pratiques-2---régression-linéaire---évaluation-du-modèle"><i class="fa fa-check"></i><b>6.11</b> Travaux pratiques 2 - Régression linéaire - Évaluation du modèle</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#exercices-1"><i class="fa fa-check"></i><b>6.11.1</b> Exercices</a></li>
<li class="chapter" data-level="6.11.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#code-r-et-réponses-1"><i class="fa fa-check"></i><b>6.11.2</b> Code R et réponses</a></li>
</ul></li>
<li class="chapter" data-level="6.12" data-path="régression-linéaire.html"><a href="régression-linéaire.html#travaux-pratiques-3---régression-linéaire---construction-de-modèle"><i class="fa fa-check"></i><b>6.12</b> Travaux pratiques 3 - Régression linéaire - Construction de modèle</a>
<ul>
<li class="chapter" data-level="6.12.1" data-path="régression-linéaire.html"><a href="régression-linéaire.html#exercices-2"><i class="fa fa-check"></i><b>6.12.1</b> Exercices</a></li>
<li class="chapter" data-level="6.12.2" data-path="régression-linéaire.html"><a href="régression-linéaire.html#code-r-et-réponses-2"><i class="fa fa-check"></i><b>6.12.2</b> Code R et réponses</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="régression-logistique.html"><a href="régression-logistique.html"><i class="fa fa-check"></i><b>7</b> Régression logistique</a>
<ul>
<li class="chapter" data-level="7.1" data-path="régression-logistique.html"><a href="régression-logistique.html#généralités-1"><i class="fa fa-check"></i><b>7.1</b> Généralités</a></li>
<li class="chapter" data-level="7.2" data-path="régression-logistique.html"><a href="régression-logistique.html#effectuer-un-test-de-rapport-de-vraisemblance"><i class="fa fa-check"></i><b>7.2</b> Effectuer un test de rapport de vraisemblance</a></li>
<li class="chapter" data-level="7.3" data-path="régression-logistique.html"><a href="régression-logistique.html#ajouter-des-ic95"><i class="fa fa-check"></i><b>7.3</b> Ajouter des IC95</a></li>
<li class="chapter" data-level="7.4" data-path="régression-logistique.html"><a href="régression-logistique.html#choisir-valeur-de-référence-pour-les-variables-catégoriques"><i class="fa fa-check"></i><b>7.4</b> Choisir valeur de référence pour les variables catégoriques</a></li>
<li class="chapter" data-level="7.5" data-path="régression-logistique.html"><a href="régression-logistique.html#produire-des-tables-de-résultats"><i class="fa fa-check"></i><b>7.5</b> Produire des tables de résultats</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="régression-logistique.html"><a href="régression-logistique.html#présenter-les-rapport-de-cotes-plutôt-que-les-log-odds"><i class="fa fa-check"></i><b>7.5.1</b> Présenter les rapport de cotes plutôt que les log odds</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="régression-logistique.html"><a href="régression-logistique.html#spécifier-pour-quelle-augmentation-dun-prédicteur-continu-le-rapport-de-cotes-est-calculé"><i class="fa fa-check"></i><b>7.6</b> Spécifier pour quelle augmentation d’un prédicteur continu le rapport de cotes est calculé</a></li>
<li class="chapter" data-level="7.7" data-path="régression-logistique.html"><a href="régression-logistique.html#évaluer-une-interaction-entre-2-variables-1"><i class="fa fa-check"></i><b>7.7</b> Évaluer une interaction entre 2 variables</a></li>
<li class="chapter" data-level="7.8" data-path="régression-logistique.html"><a href="régression-logistique.html#comparer-rapports-de-cotes-pour-une-combinaison-spécifique-de-prédicteurs"><i class="fa fa-check"></i><b>7.8</b> Comparer rapports de cotes pour une combinaison spécifique de prédicteurs</a></li>
<li class="chapter" data-level="7.9" data-path="régression-logistique.html"><a href="régression-logistique.html#présenter-leffet-des-prédicteurs-sur-une-échelle-de-probabilité"><i class="fa fa-check"></i><b>7.9</b> Présenter l’effet des prédicteurs sur une échelle de probabilité</a></li>
<li class="chapter" data-level="7.10" data-path="régression-logistique.html"><a href="régression-logistique.html#linéarité-de-la-relation-pour-prédicteur-quantitatif"><i class="fa fa-check"></i><b>7.10</b> Linéarité de la relation (pour prédicteur quantitatif)</a></li>
<li class="chapter" data-level="7.11" data-path="régression-logistique.html"><a href="régression-logistique.html#test-de-homer-lemeshow-de-pearson-et-de-déviance"><i class="fa fa-check"></i><b>7.11</b> Test de Homer-Lemeshow, de Pearson et de déviance</a></li>
<li class="chapter" data-level="7.12" data-path="régression-logistique.html"><a href="régression-logistique.html#évaluation-des-profils-extrêmes-etou-influents"><i class="fa fa-check"></i><b>7.12</b> Évaluation des profils extrêmes et/ou influents</a></li>
<li class="chapter" data-level="7.13" data-path="régression-logistique.html"><a href="régression-logistique.html#travaux-pratiques-4---régression-logistique---base"><i class="fa fa-check"></i><b>7.13</b> Travaux pratiques 4 - Régression logistique - Base</a>
<ul>
<li class="chapter" data-level="7.13.1" data-path="régression-logistique.html"><a href="régression-logistique.html#exercices-3"><i class="fa fa-check"></i><b>7.13.1</b> Exercices</a></li>
<li class="chapter" data-level="7.13.2" data-path="régression-logistique.html"><a href="régression-logistique.html#code-r-et-réponses-3"><i class="fa fa-check"></i><b>7.13.2</b> Code R et réponses</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publié avec bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Épidémiologie 2 - Labo informatique R (PTM-6675)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="régression-linéaire" class="section level1" number="6">
<h1><span class="header-section-number">Chapitre 6</span> Régression linéaire</h1>
<div id="généralités" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Généralités</h2>
<p>La fonction de base dans R pour la régression linéaire est la fonction <code>lm()</code>. Pour les exemples suivants, nous allons utiliser que les troupeaux du jeu de données Daisy2.xlsx avec h7=1.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="régression-linéaire.html#cb8-1" aria-hidden="true" tabindex="-1"></a>daisy2 <span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;daisy2.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>, <span class="at">sep=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb8-2"><a href="régression-linéaire.html#cb8-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">subset</span>(daisy2, h7<span class="sc">==</span><span class="dv">1</span>)</span></code></pre></div>
<p>Une régression linéaire dans sa plus simple expression pourrait être:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="régression-linéaire.html#cb9-1" aria-hidden="true" tabindex="-1"></a>modele<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (parity<span class="sc">+</span>twin)) <span class="co">#J&#39;ai créé un nouvel objet qui s&#39;appelle modele et qui est une régression des variables parity et twin sur milk120</span></span>
<span id="cb9-2"><a href="régression-linéaire.html#cb9-2" aria-hidden="true" tabindex="-1"></a>modele <span class="co">#Je demande à voir l&#39;objet modele</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (parity + twin), data = daisy2_mod)
## 
## Coefficients:
## (Intercept)       parity         twin  
##      2734.9        172.5       -150.6</code></pre>
<p>Les résultats présentés sont simplement l’intercept et les coefficients de <em>parity</em> et de <em>twin</em>. Pour une vache avec <em>parity</em>=0 et <em>twin</em>=0 le modèle prédit 2734,9kg de lait en 120 jours. On ajoute 172,5kg pour chaque augmentation de 1 unité de <em>parity</em> et on enlève 150,6kg lorsque <em>twin</em> est présent. Si vous préférez:</p>
<p><span class="math display">\[ milk120 = 2734,9 + 172,5*parity - 150,6*twin \]</span></p>
<p>Pour avoir un peu plus d’informations sur ce modèle, vous pouvez demander:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="régression-linéaire.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele) <span class="co">#Je demande un résumé de l&#39;objet modele</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (parity + twin), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1969.69  -434.13    -7.12   422.23  2147.50 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2734.865     32.313   84.64   &lt;2e-16 ***
## parity       172.513      9.923   17.39   &lt;2e-16 ***
## twin        -150.557    101.741   -1.48    0.139    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 650.3 on 1765 degrees of freedom
##   (208 observations deleted due to missingness)
## Multiple R-squared:  0.1463, Adjusted R-squared:  0.1453 
## F-statistic: 151.2 on 2 and 1765 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Quelques infos sont alors présentées sur:<br />
- Les <strong>résiduels</strong> (par exemple, le min et le max).<br />
- Votre modèle, mais cette fois avec les <strong>erreurs-types</strong> de chacun des coefficients et les <strong>valeurs de</strong> <em>P</em> <strong>pour le test de</strong> <em>T</em> <strong>de chaque coefficient</strong>.<br />
- <strong>L’erreur-type des résiduels</strong> est également rapportée (650.3) de même que les <strong>degrés de liberté</strong> (1765) et le <strong>nombre d’observations manquantes</strong> (208).<br />
- Le <strong><span class="math inline">\(R^2\)</span></strong> (le coefficient de détermination) est présenté. Dans ce cas 14.63% de la variation de <em>milk120</em> est expliquée par le modèle.<br />
- La <strong>valeur de</strong> <em>F</em> (151.2) qui teste si tous les coefficients=0 est aussi rapportée, de même que ses degrés de libertés (2 et 1765) et la valeur de <em>P</em> associée (P&lt;0.01).</p>
<p>Vous pouvez demander à voir la <strong>table ANOVA</strong> à l’aide de la fonction <code>aov()</code>.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="régression-linéaire.html#cb13-1" aria-hidden="true" tabindex="-1"></a>aov<span class="ot">&lt;-</span><span class="fu">aov</span>(modele) <span class="co">#Je créer un objet aov</span></span>
<span id="cb13-2"><a href="régression-linéaire.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(aov) <span class="co">#Je demande de résumer cet objet aov</span></span></code></pre></div>
<pre><code>##               Df    Sum Sq   Mean Sq F value Pr(&gt;F)    
## parity         1 126939726 126939726  300.21 &lt;2e-16 ***
## twin           1    925932    925932    2.19  0.139    
## Residuals   1765 746306281    422836                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 208 observations deleted due to missingness</code></pre>
<p>Finalement, notez que <em>parity</em> a été traitée comme une variable quantitative. <strong>Si vous désirez qu’elle soit traitée comme une variable catégorique</strong>, vous pourriez soit créer une nouvelle variable catégorique et l’utiliser dans le modele.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="régression-linéaire.html#cb15-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_cat<span class="ot">&lt;-</span><span class="fu">factor</span>(daisy2_mod<span class="sc">$</span>parity)</span></code></pre></div>
<p>Soit l’écrire directement dans le modele.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="régression-linéaire.html#cb16-1" aria-hidden="true" tabindex="-1"></a>modele1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (<span class="fu">factor</span>(parity)<span class="sc">+</span>twin)) <span class="co">#Factor() me permet d&#39;indiquer qu&#39;une variable est catégorique</span></span>
<span id="cb16-2"><a href="régression-linéaire.html#cb16-2" aria-hidden="true" tabindex="-1"></a>modele1 </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (factor(parity) + twin), data = daisy2_mod)
## 
## Coefficients:
##     (Intercept)  factor(parity)2  factor(parity)3  factor(parity)4  factor(parity)5  factor(parity)6  factor(parity)7             twin  
##          2630.9            719.3            798.9            836.2            818.8            937.6            793.9           -192.3</code></pre>
<p>Il y aura maintenant un coefficient pour chaque niveau de la variable <em>parity</em> sauf le niveau de référence (<em>parity</em>=1 a été choisi comme référence ici).</p>
</div>
<div id="ajouter-des-intervalles-de-confiance" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Ajouter des intervalles de confiance</h2>
<p>Des IC95% pour chacun des paramètres estimés seront obtenus comme suit à l’aide de la fonction <code>confint()</code>:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="régression-linéaire.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(modele, <span class="at">level=</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 2671.4897 2798.2413
## parity       153.0500  191.9752
## twin        -350.1027   48.9892</code></pre>
</div>
<div id="test-de-f-pour-comparer-modèles-complet-vs.-réduit" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Test de <em>F</em> pour comparer modèles complet <em>vs.</em> réduit</h2>
<p>Tester si quelques coefficients spécifiques sont différents de zéro (i.e., comparer un modèle complet et un modèle réduit) est très simple dans R. Il faut d’abbord faire rouler chaque modèle. Par exemple, dans le modèle suivant, pour tester les 4 problèmes de reproduction (<em>twin</em>, <em>dyst</em>, <em>rp</em> et <em>vag_disch</em>) ensemble, vous devrez exécuter les 2 modèles suivants</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="régression-linéaire.html#cb20-1" aria-hidden="true" tabindex="-1"></a>modele_complet <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (parity<span class="sc">+</span>twin<span class="sc">+</span>dyst<span class="sc">+</span>rp<span class="sc">+</span>vag_disch))</span>
<span id="cb20-2"><a href="régression-linéaire.html#cb20-2" aria-hidden="true" tabindex="-1"></a>modele_reduit <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (parity))</span></code></pre></div>
<p>Ensuite, ont peut utiliser la fonction <code>anova()</code> pour comparer les modèles.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="régression-linéaire.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele_complet, modele_reduit)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: milk120 ~ (parity + twin + dyst + rp + vag_disch)
## Model 2: milk120 ~ (parity)
##   Res.Df       RSS Df Sum of Sq      F Pr(&gt;F)
## 1   1762 744046844                           
## 2   1766 747232213 -4  -3185369 1.8858 0.1103</code></pre>
<p>Dans ce cas, on obtient une valeur de <em>P</em> de 0.11. Donc, le modèle complet n’est pas meilleur ou, si vous préférez, les coefficients de <em>twin</em>, <em>dyst</em>, <em>rp</em> et <em>vag_disch</em> ne sont pas différents de zéro.</p>
</div>
<div id="transformer-une-variable" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Transformer une variable</h2>
<p>Pour transformer une variable <strong>(e.g. centrer, mettre à l’échelle, mettre au carré ou au cube)</strong>, vous pouvez simplement utiliser les notions de base pour créer une nouvelle variable dans votre jeu de données. Vous pourrez ensuite utiliser cette nouvelle variable dans votre modèle. Par exemple, le code suivant permet de créer 3 nouvelles variables.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="régression-linéaire.html#cb23-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>parity_ct<span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>parity<span class="dv">-1</span> </span>
<span id="cb23-2"><a href="régression-linéaire.html#cb23-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct_sc <span class="ot">&lt;-</span>(daisy2_mod<span class="sc">$</span>herd_size<span class="dv">-250</span>)<span class="sc">/</span><span class="dv">100</span></span>
<span id="cb23-3"><a href="régression-linéaire.html#cb23-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_sq <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>herd_size_ct_sc<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct_sc</span></code></pre></div>
<ul>
<li>Une variable parity centrée sur la valeur 1 (i.e., le 1 devient le zéro pour cette nouvelle variable);<br />
</li>
<li>Une nouvelle variable herd_size_ct_sc centrée sur 250 vaches et mise à l’échelle pour représenter une augmentation de 100 vaches;<br />
</li>
<li>Une nouvelle variable herd_size_sq qui est la variable herd_size centrée, mise à l’échelle et élevé au carré (i.e. un terme polynomial qui pourra être utilisé afin de vérifier la linéarité de la relation entre herd_size et votre variable dépendante).</li>
</ul>
</div>
<div id="choisir-la-valeur-de-référence-pour-une-variable-catégorique" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Choisir la valeur de référence pour une variable catégorique</h2>
<p>Notez que pour les variables catégoriques, R décide (et pas toujours bien) de la valeur de référence. On peut tout de même forcer la valeur de référence qui nous intéresse. Dans le code suivant, j’ai indiqué en utilisant la fonction <code>relevel()</code> que, pour la variable <em>par_cat</em> créée précédemment, la valeur 2 sera la catégorie de référence. Lorsque j’utilise ensuite cette variable dans un modèle statistique, la valeur 2 est automatiquement utilisée comme référence.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="régression-linéaire.html#cb24-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">within</span>(daisy2_mod, par_cat<span class="ot">&lt;-</span><span class="fu">relevel</span>(par_cat, <span class="at">ref=</span><span class="dv">2</span>)) <span class="co">#Sélection de la valeur de référence par_cat=2</span></span>
<span id="cb24-2"><a href="régression-linéaire.html#cb24-2" aria-hidden="true" tabindex="-1"></a>modele2<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (par_cat<span class="sc">+</span>twin))</span>
<span id="cb24-3"><a href="régression-linéaire.html#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (par_cat + twin), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2240.03  -382.80     3.92   373.68  2180.58 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3350.23      30.80 108.777  &lt; 2e-16 ***
## par_cat1     -719.28      42.46 -16.938  &lt; 2e-16 ***
## par_cat3       79.60      44.96   1.771  0.07681 .  
## par_cat4      116.96      49.33   2.371  0.01785 *  
## par_cat5       99.49      51.56   1.930  0.05382 .  
## par_cat6      218.27      67.51   3.233  0.00125 ** 
## par_cat7       74.66     218.88   0.341  0.73308    
## twin         -192.25      96.06  -2.001  0.04550 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 612.9 on 1760 degrees of freedom
##   (208 observations deleted due to missingness)
## Multiple R-squared:  0.2436, Adjusted R-squared:  0.2406 
## F-statistic: 80.98 on 7 and 1760 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="comparer-les-niveaux-dun-prédicteur-catégorique-avec-2-catégories" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Comparer les niveaux d’un prédicteur catégorique avec &gt;2 catégories</h2>
<p>Pour un prédicteur catégorique avec plus de 2 catégories, on voudra d’abord savoir si le prédicteur est significativement associé à la variable dépendante (i.e. test de <em>F</em>). Si c’est le cas, on voudra alors comparer les niveaux entre eux (i.e. tests de <em>T</em>). Deux problèmes se posent alors :<br />
1) Problème de comparaisons multiples; on voudra ajuster nos valeurs de <em>P</em> ou nos <em>IC 95%</em> en fonction du nombre de comparaison effectuées.<br />
2) La table avec les coefficients de régression nous rapporte le test de <em>T</em> pour chaque coefficient lorsque comparé au niveau de référence, mais pas entre eux.<br />
Par exemple, avec une variable parity_cat avec 3 catégories : 1=parité 1, 2=parité 2 et 3=parité ≥ 3, on aura</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="régression-linéaire.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je créé une variable parity catégorique:</span></span>
<span id="cb26-2"><a href="régression-linéaire.html#cb26-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_cat <span class="ot">&lt;-</span> <span class="fu">cut</span>(daisy2_mod<span class="sc">$</span>parity, <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="cn">Inf</span>),</span>
<span id="cb26-3"><a href="régression-linéaire.html#cb26-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;First&quot;</span>, <span class="st">&quot;Second&quot;</span>, <span class="st">&quot;Third or more&quot;</span>))</span>
<span id="cb26-4"><a href="régression-linéaire.html#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Ma régression</span></span>
<span id="cb26-5"><a href="régression-linéaire.html#cb26-5" aria-hidden="true" tabindex="-1"></a>modele<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (par_cat))</span>
<span id="cb26-6"><a href="régression-linéaire.html#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (par_cat), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2234.73  -387.55     7.79   377.11  2176.01 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           2629.63      29.31   89.71   &lt;2e-16 ***
## par_catSecond          715.30      42.45   16.85   &lt;2e-16 ***
## par_catThird or more   824.66      35.54   23.20   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 613.5 on 1765 degrees of freedom
##   (208 observations deleted due to missingness)
## Multiple R-squared:  0.2402, Adjusted R-squared:  0.2393 
## F-statistic: 278.9 on 2 and 1765 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Dans les résultats, les tests de <em>T</em> nous indiquent que <em>Second</em> est différent de <em>First</em> (la catégorie de référence) et que <em>Third or more</em> est différent de <em>First</em>. Mais on ne peut comparer <em>Second</em> avec <em>Third or more</em> et ces valeurs de <em>T</em> ne sont pas ajustées pour les comparaisons multiples. La fonction <code>emmeans()</code> du package <code>emmeans</code> permettra de générer les informations nécessaires pour faire les contrastes. La fonction <code>pairs()</code> calculera ces contrastes. Par défaut la méthode d’ajustement <em>a posteriori</em> pour comparaison multiple de Tukey-Kramer est utilisée.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="régression-linéaire.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb28-2"><a href="régression-linéaire.html#cb28-2" aria-hidden="true" tabindex="-1"></a>contrast <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(modele, <span class="st">&quot;par_cat&quot;</span>) <span class="co">#Ici j&#39;ai créé un objet nommé contrast qui contient les éléments dont j&#39;aurai besoin pour comparer les catégories de par_cat</span></span>
<span id="cb28-3"><a href="régression-linéaire.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(contrast) <span class="co">#Je demande ensuite les estimés des différentes catégories. </span></span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df t.ratio p.value
##  First - Second             -715 42.5 1765 -16.848 &lt;.0001 
##  First - Third or more      -825 35.5 1765 -23.200 &lt;.0001 
##  Second - Third or more     -109 36.7 1765  -2.979 0.0082 
## 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>Nous voyons maintenant toutes les comparaisons possibles. Par exemple les 2ième lactation produisaient 109kg de lait de moins que les 3ième lactation. Et les valeurs de <em>P</em> présentées sont ajustées <em>a posteriori</em> pour les comparaisons multiples.Notez que vous pourriez aussi simplement faire un ajustement <em>a priori</em> (e.g. Bonferroni). Vous n’aurez pas alors à modifier le calcul des valeurs de <em>P</em> ou de vos <em>IC 95%</em>, mais simplement votre seuil <em>α</em>.</p>
<p>Si vous désirez plutôt l’estimé (i.e., le least square means) pour chaque catégorie et son intervalle de confiance, vous pouvez alors simplement utiliser la fonction <code>confint()</code> sur votre contraste:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="régression-linéaire.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">pairs</span>(contrast))</span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df lower.CL upper.CL
##  First - Second             -715 42.5 1765     -815   -615.7
##  First - Third or more      -825 35.5 1765     -908   -741.3
##  Second - Third or more     -109 36.7 1765     -195    -23.3
## 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>On verra alors les différences de production moyenne par catégorie et leurs <em>IC 95</em>. Par exemple, les 1ères lactation produisaient en moyenne 715kg de moins que les 2ième (<em>IC 95</em>: 616, 815). Ces <em>IC 95</em> sont également ajusté pour les comparaisons multiples.</p>
</div>
<div id="évaluer-une-interaction-entre-2-variables" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Évaluer une interaction entre 2 variables</h2>
<p>L’interaction entre 2 variables peut être modélisée de manière très simple, vous n’avez qu’à indiquer dans votre modèle l’interaction entre les variables (<em>parity</em> x <em>dyst</em>). La fonction <code>lm()</code> se chargera alors d’inclure tous les termes nécessaires (i.e., <em>dyst</em> + <em>parity</em> + <em>dyst</em> x <em>parity</em>).</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="régression-linéaire.html#cb32-1" aria-hidden="true" tabindex="-1"></a>modele<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (parity<span class="sc">*</span>dyst)) <span class="co">#parity*dyst demandera d&#39;inclure dans le modèle: dyst + parity + dyst*parity</span></span>
<span id="cb32-2"><a href="régression-linéaire.html#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = milk120 ~ (parity * dyst), data = daisy2_mod)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1970.32  -437.44   -17.17   422.63  2149.86 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2741.50      33.93  80.805   &lt;2e-16 ***
## parity        169.51      10.27  16.506   &lt;2e-16 ***
## dyst          -89.58     115.00  -0.779    0.436    
## parity:dyst    30.42      44.90   0.678    0.498    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 650.7 on 1764 degrees of freedom
##   (208 observations deleted due to missingness)
## Multiple R-squared:  0.1455, Adjusted R-squared:  0.1441 
## F-statistic: 100.1 on 3 and 1764 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="régression-linéaire.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: milk120
##               Df    Sum Sq   Mean Sq  F value Pr(&gt;F)    
## parity         1 126939726 126939726 299.7720 &lt;2e-16 ***
## dyst           1     64457     64457   0.1522 0.6965    
## parity:dyst    1    194401    194401   0.4591 0.4981    
## Residuals   1764 746973355    423454                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Ici, on voit les estimés du modèle et le test de <em>F</em> pour l’interaction (<em>P</em>=0.498).</p>
<p>C’est également possible de demander à voir un graphique illustrant cette interaction (ce sera parfois plus facile à interpréter). Le package <code>sjPlot</code> permet de générer toutes sortes de graphiques à partir de modèles estimés à l’aide des fonctions <code>lm</code>, <code>glm</code>, <code>lme</code>, <code>lmerMod</code>, etc. La fonction <code>plot_model</code> permet de générer une figure, j’indique le nom du modèle (dans ce cas, je l’avais simplement nommé <code>modele</code>) et le type de figure demandée. Ici je demande une figure <code>int</code> illustrant les effets des termes d’intéractions. Le fonction <code>plot_model</code> cherchera les termes d’interaction dans le modèle et fera une figure à l’aide de ceux-ci. La variable apparaissant en premier dans le modèle sera utilisée pour l’axe des x. Pour plus de détails voir <a href="https://cran.r-project.org/web/packages/sjPlot/vignettes/plot_interactions.html">Plotting interaction effects of regression models</a>.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="régression-linéaire.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb36-2"><a href="régression-linéaire.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(modele, <span class="at">type=</span><span class="st">&quot;int&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-100"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-100-1.png" alt="Effet de parité et dystocie sur la production laitière entre 0 et 120 jours en lait." width="672" />
<p class="caption">
Figure 6.1: Effet de parité et dystocie sur la production laitière entre 0 et 120 jours en lait.
</p>
</div>
<p>Notez que, si un de vos termes d’interaction est catégorique avec &gt; 2 catégories et que vous avez utilisé la fonction <code>factor()</code> qui vous aura permis de bien identifier que cette variable est catégorique, les variables indicateurs seront alors créées automatiquement pour vous (ce qui sera très utile lorsque vous aurez des interactions avec des prédicteurs catégoriques avec &gt; 2 catégories).</p>
</div>
<div id="tol-et-vif---évaluer-colinéarité" class="section level2" number="6.8">
<h2><span class="header-section-number">6.8</span> TOL et VIF - Évaluer colinéarité</h2>
<p>Afin de détecter les problèmes de colinéarité, on peut demander le calcul du « variance inflation factor » (VIF) à l’aide du package <code>car</code> et de la fonction <code>vif</code>. La tolérance sera simplement (1/VIF). Un VIF &gt; 10 (ou tolérance &lt; 0.10) indiquera un problème sévère de colinéarité.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="régression-linéaire.html#cb37-1" aria-hidden="true" tabindex="-1"></a>modele1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, milk120 <span class="sc">~</span> (dyst <span class="sc">+</span> parity))</span>
<span id="cb37-2"><a href="régression-linéaire.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span></code></pre></div>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## Registered S3 methods overwritten by &#39;car&#39;:
##   method                          from
##   influence.merMod                lme4
##   cooks.distance.influence.merMod lme4
##   dfbeta.influence.merMod         lme4
##   dfbetas.influence.merMod        lme4</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="régression-linéaire.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(modele1)</span></code></pre></div>
<pre><code>##     dyst   parity 
## 1.017337 1.017337</code></pre>
<p>On a donc un VIF de 1.02 (ou une tolérance de 0.98).</p>
</div>
<div id="évaluation-du-modèle" class="section level2" number="6.9">
<h2><span class="header-section-number">6.9</span> Évaluation du modèle</h2>
<p>L’évaluation du modèle est basée sur différentes procédures diagnostiques. L’évaluation de graphiques constitue une part importante de ce travail.</p>
<div id="évaluer-la-linéarité-de-la-relation-à-laide-de-courbes-lissées-pour-prédicteur-quantitatif" class="section level3" number="6.9.1">
<h3><span class="header-section-number">6.9.1</span> Évaluer la linéarité de la relation à l’aide de courbes lissées (pour prédicteur quantitatif)</h3>
<p>La linéarité de la relation est une supposition importante du modèle. Pour les prédicteurs quantitatifs, vous devrez toujours vérifier si cette supposition est bien respectée. Vous pouvez le faire à l’aide du modèle polynomial (en ajoutant le prédicteur^2 ou le prédicteur^2 et le prédicteur^3 dans votre modèle). Si les coefficients de ces termes sont significativement différents de zéro (i.e. P &lt; 0.05), ont concluera que la relation est une courbe, ou une courbe avec un ou plusieurs points d’inflexion, respectivement.<br />
Mais une représentation graphique de la relation facilite toujours la compréhension. Les courbes lissées (e.g. loess, kernel) permettent de bien visualiser cette relation. Le package <code>ggplot2</code> et les fonctions <code>ggplot</code>, <code>geom_point</code> et <code>geom_smooth</code> vous permet de réaliser ce genre de graphique. Le code suivant permet de visualiser la relation entre 2 variables continues (<code>wpc</code> et <code>milk120</code>). En jouant avec l’argument <code>span</code> vous pouvez changer le lissage de la courbe. Une petite valeur produira une courbe qui sautille beaucoup, une plus grande valeur produira une courbe plus lisse.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="régression-linéaire.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb42-2"><a href="régression-linéaire.html#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, <span class="fu">aes</span>(wpc, milk120)) <span class="sc">+</span> <span class="co">#Ici j&#39;ai simplement indiqué le jeu de données, puis les variables d&#39;intérêt</span></span>
<span id="cb42-3"><a href="régression-linéaire.html#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  <span class="co">#Je demande d&#39;ajouter le nuage de points (un &#39;scatterplot&#39;)</span></span>
<span id="cb42-4"><a href="régression-linéaire.html#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="dv">2</span>)<span class="sc">+</span> <span class="co">#Je demande d&#39;ajouter la courbe lissée de type loess. L&#39;argument span me permet d&#39;ajuster le lissage </span></span>
<span id="cb42-5"><a href="régression-linéaire.html#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="co">#J&#39;aime bien avoir un fond blanc pour mes figures (un thème noir et blanc; theme_bw). C&#39;est futile, mais bon...</span></span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-102"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-102-1.png" alt="Relation entre le nombre de jours jusqu’à la saillie fécondante (wpc) et la production de lait en 120j (milk120) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.2: Relation entre le nombre de jours jusqu’à la saillie fécondante (wpc) et la production de lait en 120j (milk120) avec courbe lissée avec un facteur de 2.
</p>
</div>
</div>
<div id="méthodes-diagnostiques-pour-les-résiduels" class="section level3" number="6.9.2">
<h3><span class="header-section-number">6.9.2</span> Méthodes diagnostiques pour les résiduels</h3>
<p>La fonction <code>plot()</code> demande les principaux graphiques qui serviront à évaluer l’adéquation du modèle (i.e. l’homoscédasticité et la normalité des résiduels).<br />
Les plus intéressants sont probablement :<br />
• Le graphique des Résiduels x valeurs prédites (Residual vs Fitted). Ce graphique vous permettra de visualiser si la variance est homogène en fonction des valeurs prédites. On désire une « bande » horizontale égale (semble assez problématique pour cette exemple; la bande va en augmentant)<br />
• Le graphique des quantiles x résiduels (Normal Q-Q) permet d’évaluer la normalité des résiduels. On désire que les points forment une ligne de 45º qui se superpose à la ligne pointillée dans la figure (encore assez problématique dans cet exemple)</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="régression-linéaire.html#cb43-1" aria-hidden="true" tabindex="-1"></a>modele2<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (dyst <span class="sc">+</span> parity <span class="sc">+</span> herd_size <span class="sc">+</span> twin))</span>
<span id="cb43-2"><a href="régression-linéaire.html#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele2, <span class="dv">1</span>) <span class="co">#Je demande la première figure du &#39;pannel plot&#39; de diagnostique (c&#39;est la figure Residual vs Fitted)</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="régression-linéaire.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele2, <span class="dv">2</span>) <span class="co">#Je demande la 2ième figure du &#39;pannel plot&#39; de diagnostique (c&#39;est la figure Normal Q-Q)</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-103-2.png" width="672" /></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="régression-linéaire.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Alternativement, je peux ne pas spécifier les figures qui m&#39;intéressent et simplement tout demander ainsi:</span></span>
<span id="cb45-2"><a href="régression-linéaire.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele2)</span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-103-3.png" width="672" /><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-103-4.png" width="672" /><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-103-5.png" width="672" /><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-103-6.png" width="672" /></p>
</div>
<div id="évaluation-des-observations-extrêmes-etou-influentes" class="section level3" number="6.9.3">
<h3><span class="header-section-number">6.9.3</span> Évaluation des observations extrêmes et/ou influentes</h3>
<p>Certaines observations peuvent être très différentes des autres et avoir un effet important sur les résultats
de la régression. Cette observation peut être une observation extrême (outlier), c’est-à-dire une observation avec une combinaison inhabituelle de valeurs pour la variable dépendante et les variables indépendantes. Ce peut être une observation avec une valeur extrême pour un prédicteur, que l’on appelle variable à effet levier (leverage). Enfin ce peut être une observation qui, si elle est soustraite à l’analyse, change les estimés des coefficients (influence).</p>
<p>Dans R, vous pouvez facilement ajouter dans votre base de données les valeurs prédites par le modèle, les résiduels, distances de Cook, leviers, etc avec la fonction <code>augment()</code> du package <code>broom</code>. Vous pourrez ensuite trier cette table pour identifier, par exemple, les observations avec les résiduels, leviers ou distance de Cook les plus extrêmes et essayer de comprendre si ces observations ont quelque chose en commun.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="régression-linéaire.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb46-2"><a href="régression-linéaire.html#cb46-2" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(modele2) <span class="co">#Je viens de créer une nouvelle table dans laquelle les résiduels, distance de cook, etc se trouvent maintenant</span></span>
<span id="cb46-3"><a href="régression-linéaire.html#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diag)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 12
##   .rownames   wpc  dyst parity herd_size  twin .fitted .resid    .hat .sigma   .cooksd .std.resid
##   &lt;chr&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;     &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;
## 1 3            67     0      5       294     0    78.0  -11.0 0.00239   50.4 0.0000230     -0.219
## 2 4             9     0      5       294     0    78.0  -69.0 0.00239   50.4 0.000901      -1.37 
## 3 5            61     0      5       294     0    78.0  -17.0 0.00239   50.4 0.0000548     -0.338
## 4 8           117     0      5       294     0    78.0   39.0 0.00239   50.4 0.000287       0.775
## 5 9            36     0      6       294     0    79.2  -43.2 0.00397   50.4 0.000588      -0.859
## 6 11           19     0      5       294     0    78.0  -59.0 0.00239   50.4 0.000659      -1.17</code></pre>
<p>Les nouvelles variables correspondent à:<br />
- Valeur prédite (<code>.fitted</code>)<br />
- Résiduel (<code>.resid</code>)<br />
- Levier (<code>.hat</code>)<br />
- Distance de Cook (<code>.cooksd</code>)<br />
- Résiduel standardisé (<code>.std.resid</code>)</p>
<p>À l’aide de la fonction <code>ggplot</code> vous pourrez alors produire les graphiques qui vous intéressent. Par exemple :</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="régression-linéaire.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diag, <span class="fu">aes</span>(wpc, .std.resid, <span class="at">colour=</span>.std.resid)) <span class="sc">+</span> <span class="co">#J&#39;indique les variables d&#39;intérêt. Je me sui permis une petite fantaisie ici, je change la couleur des points en fonction de la valeur du résiduel standardisé</span></span>
<span id="cb48-2"><a href="régression-linéaire.html#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="co">#Je demande un graphique nuage de points</span></span>
<span id="cb48-3"><a href="régression-linéaire.html#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="dv">3</span>)) <span class="sc">+</span> <span class="co">#Une autre fantaisie, ajoutons des barres horizontales qui permettent de marquer les valeurs -3 et +3 (pour identifier les résiduels &#39;extrêmes&#39;)</span></span>
<span id="cb48-4"><a href="régression-linéaire.html#cb48-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="sc">-</span><span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb48-5"><a href="régression-linéaire.html#cb48-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="co">#Mon fameux fond blanc!</span></span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-105"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-105-1.png" alt="Graphique des résiduels de Student par jours jusqu’à la saillie fécondante (wpc)." width="672" />
<p class="caption">
Figure 6.3: Graphique des résiduels de Student par jours jusqu’à la saillie fécondante (wpc).
</p>
</div>
<p>Dans ce cas, on voit que seulement les vaches avec un WPC long (&gt; 250j) ont des résiduels larges (i.e. &gt; 3.0 ou &lt; -3.0). Le modèle semble donc avoir de la difficulté à bien prédire ces observations.</p>

</div>
</div>
<div id="travaux-pratiques-1---régression-linéaire---base" class="section level2" number="6.10">
<h2><span class="header-section-number">6.10</span> Travaux pratiques 1 - Régression linéaire - Base</h2>
<div id="exercices" class="section level3" number="6.10.1">
<h3><span class="header-section-number">6.10.1</span> Exercices</h3>
<p>Pour ce TP utilisez le fichier DAISY2 (voir description VER p.809).</p>
<p><strong>Ne sélectionnez que les 7 troupeaux avec h7=1. </strong></p>
<p><strong>1)</strong> Considérons le <strong>nombre de jours jusqu’à la saillie fécondante (WPC) comme variable dépendante</strong> et vérifions comment différents prédicteurs permettent de prédire cet intervalle.</p>
<p><strong>a.</strong> Représenter graphiquement l’association entre milk120 et WPC. Pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<p><strong>b.</strong> Faites varier le lissage (e.g. 0.1 ou 1) et décrivez comment la courbe lissée change en fonction de ce lissage.</p>
<p><strong>c.</strong> Maintenant, représenter graphiquement la relation entre parity et wpc. Dans ce cas, pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<p><strong>d.</strong> À partir du diagramme de dispersion, il est raisonnable de penser que l’intervalle WPC change linéairement avec parity. Cette relation linéaire peut être exprimée par le modèle <span class="math inline">\(WPC= β_0 + β_1*parity\)</span>. À l’aide d’un modèle de régression linéaire, estimer les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span>. Écrivez l’équation de régression sous la forme donnée ci-dessus, avec ces estimés dans l’équation. Comment interprétez-vous ces estimés ?</p>
<p><strong>e.</strong> Un test de <em>F</em> vous est rapporté pour le modèle de même qu’un test de <em>T</em> pour le coefficient de régression de parity (i.e. <span class="math inline">\(β_1\)</span>). Quelles sont les hypothèses nulles pour chacun de ces tests? Dans ce cas, ces 2 tests sont-ils réellement différents?</p>
<p><strong>f.</strong> Quel serait l’IC95% pour le coefficient de régression de parity?</p>
<p><strong>g.</strong> Existe-t’il une relation linéaire statistiquement significative entre ces 2 variables?</p>
<p><strong>h.</strong> Le nombre de jours jusqu’à la saillie fécondante (WPC) pour une parité zéro n’a bien sûr pas de sens biologique. Pour repositionner ce paramètre à la parité minimale observée (i.e. parity=1), on peut remplacer la parité par une nouvelle variable (parity_ct) centrée sur parity=1. Créez cette nouvelle variable et, à l’aide d’un modèle de régression linéaire, estimez les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span> et interprétez les coefficients de régression comme à la question 1.d.</p>
<p><strong>2)</strong> À la question 1.a, nous avons vu que la relation entre milk120 et WPC ne semble pas être linéaire. Nous pourrions donc créer des termes polynomiaux afin de modéliser correctement cette association.</p>
<p><strong>a.</strong> Créer une nouvelle variable milk120_ct centrée sur la production moyenne. Puis créez 1 terme polynomial milk120_ct_sq (i.e. milk120 au carré). Vérifiez si l’ajout d’une courbe (i.e. le terme au carré) ajoute significativement au modèle.</p>
<p><strong>b.</strong> Selon votre analyse graphique réalisée à la question 1.a, pensez-vous que vous auriez besoin d’ajouter d’autres points d’inflexions pour bien représenter cette association? Vérifiez votre réponse en ajoutant un terme au cube pour milk120 en plus du terme au carré.</p>
<p><strong>c.</strong> Dans ce dernier modèle, vérifiez qu’il n’y a pas de problème sévère de colinéarité.</p>
<p><strong>3)</strong> Dans le modèle suivant <span class="math inline">\(wpc = β_0 +β_1parityct + β_2twin + β_3dyst\)</span> vous vous demandez si les problèmes de vêlage (i.e. twin et dyst ensemble) apporte significativement au modèle. Quel test pourriez-vous réaliser afin de répondre à cette question? Quel est le résultat de ce test et votre interprétation de ce résultat?</p>
<p><strong>4)</strong> Recodez maintenant parity afin d’avoir une nouvelle variable catégorique (parity_cat) à 3 niveaux (parity 1, parity 2 et parity ≥3). Vérifiez la relation entre parity_cat et WPC en vous assurant d’avoir parity 1 comme valeur de référence.</p>
<p><strong>a.</strong> Est-ce que parity_cat (comme variable) est significativement associée à WPC?</p>
<p><strong>b.</strong> De combien WPC change pour une vache de 2ième parité comparativement à une vache de 1ère parité?</p>
<p><strong>c.</strong> Quel est le WPC pour une vache de 1ère parité?</p>
<p><strong>d.</strong> Quelle est la différence de WPC entre une 2ième et une 3ième parité et quel est l’IC 95% ajusté pour comparaisons multiples pour cette différence? Cette différence est-elle statistiquement significative?</p>
<p><strong>5)</strong> Vous supposez que l’effet d’une dystocie (dyst) sur WPC varie en fonction de la parité (catégorique 1ère, 2ième, ou ≥3ième). Par exemple, une vache plus vieille ayant une dystocie aura possiblement un délai plus long jusqu’à la saille fécondante comparativement à une vache plus jeune.</p>
<p><strong>a.</strong> Que devrez-vous tester pour vérifier cette hypothèse?</p>
<p><strong>b.</strong> Effectuer ce test. Est-ce que l’effet de dystocie varie de manière statistiquement significative en fonction de la parité?</p>
<p><strong>c.</strong> Quel est le nombre de jours moyen jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie (i.e. remplir le tableau suivant)? Pour quel niveau de parité les différences semblent les plus importantes?</p>
<table>
<caption><span id="tab:unnamed-chunk-108">Table 6.1: </span>Nombre moyen estimé de jours jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie</caption>
<thead>
<tr class="header">
<th align="left">Parite</th>
<th align="left">Dystocie_0</th>
<th align="left">Dystocie_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1ère lactation</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">2ième lactation</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">3ième ou plus</td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
</div>
<div id="code-r-et-réponses" class="section level3" number="6.10.2">
<h3><span class="header-section-number">6.10.2</span> Code R et réponses</h3>
<p>Pour ce TP utilisez le fichier DAISY2 (voir description VER p.809).<br />
<strong>Ne sélectionnez que les 7 troupeaux avec h7=1. </strong></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="régression-linéaire.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">#J&#39;ouvre le jeu de données</span></span>
<span id="cb49-2"><a href="régression-linéaire.html#cb49-2" aria-hidden="true" tabindex="-1"></a>daisy2 <span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;daisy2.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>, <span class="at">sep=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb49-3"><a href="régression-linéaire.html#cb49-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">subset</span>(daisy2, h7<span class="sc">==</span><span class="dv">1</span>)</span></code></pre></div>
<p><strong>1)</strong> Considérons le <strong>nombre de jours jusqu’à la saillie fécondante (WPC) comme variable dépendante</strong> et vérifions comment différents prédicteurs permettent de prédire cet intervalle.</p>
<p><strong>a.</strong> Représenter graphiquement l’association entre milk120 et WPC. Pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="régression-linéaire.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb50-2"><a href="régression-linéaire.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, <span class="fu">aes</span>(milk120, wpc)) <span class="sc">+</span> <span class="co">#Ici j&#39;ai simplement indiqué le jeu de données, puis les variables d&#39;intérêt</span></span>
<span id="cb50-3"><a href="régression-linéaire.html#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  <span class="co">#Je demande d&#39;ajouter le nuage de points (un &#39;scatterplot&#39;)</span></span>
<span id="cb50-4"><a href="régression-linéaire.html#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="dv">2</span>)<span class="sc">+</span> <span class="co">#Je demande d&#39;ajouter la courbe lissée de type loess. L&#39;argument span me permet d&#39;ajuster le lissage </span></span>
<span id="cb50-5"><a href="régression-linéaire.html#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="co">#J&#39;aime bien avoir un fond blanc pour mes figures (un thème noir et blanc; theme_bw). C&#39;est futile, mais bon...</span></span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-110"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-110-1.png" alt="Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.4: Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Non, relation semble légèrement curvilinéaire</p>
<p><strong>b.</strong> Faites varier le lissage (e.g. 0.1 ou 1) et décrivez comment la courbe lissée change en fonction de ce lissage.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="régression-linéaire.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, <span class="fu">aes</span>(milk120, wpc)) <span class="sc">+</span> </span>
<span id="cb51-2"><a href="régression-linéaire.html#cb51-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb51-3"><a href="régression-linéaire.html#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="fl">0.2</span>)<span class="sc">+</span> </span>
<span id="cb51-4"><a href="régression-linéaire.html#cb51-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-111"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-111-1.png" alt="Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 0.2." width="672" />
<p class="caption">
Figure 6.5: Relation entre la production de lait en 120j (milk120) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 0.2.
</p>
</div>
<p><strong>Réponse:</strong> Lorsqu’on réduit le <code>span</code>, la courbe permet de visualiser toutes les petites variations. Elle devient plus droite (i.e. plus insensible aux variations) lorsque le <code>span</code> augmente.</p>
<p><strong>c.</strong> Maintenant, représenter graphiquement la relation entre parity et wpc. Dans ce cas, pensez-vous qu’une ligne droite passant au travers des points capture adéquatement la relation entre ces deux variables ?</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="régression-linéaire.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, <span class="fu">aes</span>(parity, wpc)) <span class="sc">+</span> </span>
<span id="cb52-2"><a href="régression-linéaire.html#cb52-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb52-3"><a href="régression-linéaire.html#cb52-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="dv">2</span>)<span class="sc">+</span> </span>
<span id="cb52-4"><a href="régression-linéaire.html#cb52-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-112"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-112-1.png" alt="Relation entre parité (parity) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.6: Relation entre parité (parity) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Oui, semble mieux</p>
<p><strong>d.</strong> À partir du diagramme de dispersion, il est raisonnable de penser que l’intervalle WPC change linéairement avec parity. Cette relation linéaire peut être exprimée par le modèle <span class="math inline">\(WPC= β_0 + β_1*parity\)</span>. À l’aide d’un modèle de régression linéaire, estimer les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span>. Écrivez l’équation de régression sous la forme donnée ci-dessus, avec ces estimés dans l’équation. Comment interprétez-vous ces estimés ?</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="régression-linéaire.html#cb53-1" aria-hidden="true" tabindex="-1"></a>modele1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (parity)) <span class="co">#J&#39;ai créé un nouvel objet qui s&#39;appelle modele1 et qui est une régression des variables parity sur wpc</span></span>
<span id="cb53-2"><a href="régression-linéaire.html#cb53-2" aria-hidden="true" tabindex="-1"></a>modele1 <span class="co">#Je demande à voir l&#39;objet modele</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (parity), data = daisy2_mod)
## 
## Coefficients:
## (Intercept)       parity  
##      65.218        1.312</code></pre>
<p><strong>Réponse:</strong> <span class="math inline">\(WPC= 65.2 + 1.3*parity\)</span><br />
Intervalle WPC moyen quand parité=0 est de 65.2j. On ajoute ensuite 1.3 jours à chaque fois qu’on ajoute une parité.</p>
<p><strong>e.</strong> Un test de <em>F</em> vous est rapporté pour le modèle de même qu’un test de <em>T</em> pour le coefficient de régression de parity (i.e. <span class="math inline">\(β_1\)</span>). Quelles sont les hypothèses nulles pour chacun de ces tests? Dans ce cas, ces 2 tests sont-ils réellement différents?</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="régression-linéaire.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (parity), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -67.47 -38.47 -15.15  24.16 227.53 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  65.2181     2.7090  24.075   &lt;2e-16 ***
## parity        1.3118     0.8706   1.507    0.132    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.58 on 1572 degrees of freedom
##   (402 observations deleted due to missingness)
## Multiple R-squared:  0.001442,   Adjusted R-squared:  0.000807 
## F-statistic: 2.271 on 1 and 1572 DF,  p-value: 0.1321</code></pre>
<p><strong>Réponse:</strong> Test de <em>F</em> (<em>P</em>=0.132): tous les coefficients (outre <span class="math inline">\(β_0\)</span>, l’intercept) = 0<br />
Test de <em>T</em> (aussi <em>P</em>=0.132): le coefficient de parity (<span class="math inline">\(β_1\)</span>) = 0<br />
Non, puisqu’il y a un seul coefficient de régression dans l’équation les 2 tests sont équivalents.</p>
<p><strong>f.</strong> Quel serait l’IC95% pour le coefficient de régression de parity?</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="régression-linéaire.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(modele1)</span></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) 59.9045164 70.531662
## parity      -0.3958026  3.019367</code></pre>
<p><strong>Réponse:</strong> -0.4 à 3.0 jours</p>
<p><strong>g.</strong> Existe-t’il une relation linéaire statistiquement significative entre ces 2 variables?<br />
<strong>Réponse:</strong> Non (<em>P</em>=0.13 et <em>IC95%</em> inclus 0)</p>
<p><strong>h.</strong> Le nombre de jours jusqu’à la saillie fécondante (WPC) pour une parité zéro n’a bien sûr pas de sens biologique. Pour repositionner ce paramètre à la parité minimale observée (i.e. parity=1), on peut remplacer la parité par une nouvelle variable (parity_ct) centrée sur parity=1. Créez cette nouvelle variable et, à l’aide d’un modèle de régression linéaire, estimez les valeurs de <span class="math inline">\(β_0\)</span> et <span class="math inline">\(β_1\)</span> et interprétez les coefficients de régression comme à la question 1.d.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="régression-linéaire.html#cb59-1" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>parity<span class="dv">-1</span></span>
<span id="cb59-2"><a href="régression-linéaire.html#cb59-2" aria-hidden="true" tabindex="-1"></a>modele2<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (par_ct)) </span>
<span id="cb59-3"><a href="régression-linéaire.html#cb59-3" aria-hidden="true" tabindex="-1"></a>modele2</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (par_ct), data = daisy2_mod)
## 
## Coefficients:
## (Intercept)       par_ct  
##      66.530        1.312</code></pre>
<p><strong>Réponse:</strong> Intervalle <em>wpc</em> moyen quand parité=1 est de 66.5j. On ajoute ensuite 1.3 jours à chaque fois qu’on ajoute une parité.</p>
<p><strong>2)</strong> À la question 1.a, nous avons vu que la relation entre milk120 et WPC ne semble pas être linéaire. Nous pourrions donc créer des termes polynomiaux afin de modéliser correctement cette association.</p>
<p><strong>a.</strong> Créer une nouvelle variable milk120_ct centrée sur la production moyenne. Puis créez 1 terme polynomial milk120_ct_sq (i.e. milk120 au carré). Vérifiez si l’ajout d’une courbe (i.e. le terme au carré) ajoute significativement au modèle.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="régression-linéaire.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions d&#39;abord quelle est la moyenne de milk120</span></span>
<span id="cb61-2"><a href="régression-linéaire.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(daisy2_mod<span class="sc">$</span>milk120, <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 3225.311</code></pre>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="régression-linéaire.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je créé la variable centrée sur 3225 et celle au carré</span></span>
<span id="cb63-2"><a href="régression-linéaire.html#cb63-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>milk120_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>milk120<span class="dv">-3225</span></span>
<span id="cb63-3"><a href="régression-linéaire.html#cb63-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>milk120_ct_sq <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>milk120_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>milk120_ct</span>
<span id="cb63-4"><a href="régression-linéaire.html#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions que ça a bien focntionné</span></span>
<span id="cb63-5"><a href="régression-linéaire.html#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(daisy2_mod)</span></code></pre></div>
<pre><code>##   region herd cow study_lact herd_size mwp parity milk120    calv_dt cf fs cc wpc spc twin dyst rp vag_disch h7 par_ct milk120_ct milk120_ct_sq
## 1      1    1   1          1       294  26      5  3505.8 1996-11-11 80 NA NA  NA   6    0    0  0         0  1      4      280.8      78848.67
## 2      1    1   2          1       294  26      5  3691.3 1997-01-12 64 NA NA  NA   3    0    0  0         0  1      4      466.3     217435.74
## 3      1    1   3          1       294  26      5  4173.0 1997-01-17 71  0 93  67   2    0    0  0         0  1      4      948.0     898704.00
## 4      1    1   4          1       294  26      5  3727.3 1997-02-11 35  1 35   9   1    0    0  0         0  1      4      502.3     252305.34
## 5      1    1   5          1       294  26      5  3090.8 1997-06-26 47  0 87  61   2    0    0  0         0  1      4     -134.2      18009.63
## 6      1    1   6          1       294  26      4  5041.2 1996-10-16 NA NA NA  NA  NA    0    0  1         0  1      3     1816.2    3298583.15</code></pre>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="régression-linéaire.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je vérifie le modèle avec les termes polynomiaux</span></span>
<span id="cb65-2"><a href="régression-linéaire.html#cb65-2" aria-hidden="true" tabindex="-1"></a>modele3<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (milk120_ct<span class="sc">+</span>milk120_ct_sq)) </span>
<span id="cb65-3"><a href="régression-linéaire.html#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (milk120_ct + milk120_ct_sq), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -66.34 -38.70 -15.26  25.28 222.44 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    6.697e+01  1.639e+00  40.856   &lt;2e-16 ***
## milk120_ct    -2.545e-03  1.892e-03  -1.345   0.1787    
## milk120_ct_sq  4.089e-06  1.998e-06   2.046   0.0409 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.65 on 1533 degrees of freedom
##   (440 observations deleted due to missingness)
## Multiple R-squared:  0.003696,   Adjusted R-squared:  0.002396 
## F-statistic: 2.843 on 2 and 1533 DF,  p-value: 0.05854</code></pre>
<p><strong>Réponse:</strong> Oui, le terme au carré est significativement associé (i.e. <em>P</em> = 0.04) à wpc. Donc le terme représentant la courbe à un coefficient différent de 0.</p>
<p><strong>b.</strong> Selon votre analyse graphique réalisée à la question 1.a, pensez-vous que vous auriez besoin d’ajouter d’autres points d’inflexions pour bien représenter cette association? Vérifiez votre réponse en ajoutant un terme au cube pour milk120 en plus du terme au carré.</p>
<p><strong>Réponse:</strong> <em>a priori</em>, ça semblait être une simple courbe.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="régression-linéaire.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je créé une variable milk120 à la puissance 3</span></span>
<span id="cb67-2"><a href="régression-linéaire.html#cb67-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>milk120_ct_cu <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>milk120_ct_sq<span class="sc">*</span>daisy2_mod<span class="sc">$</span>milk120_ct</span>
<span id="cb67-3"><a href="régression-linéaire.html#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Je l&#39;ajoute au modèle</span></span>
<span id="cb67-4"><a href="régression-linéaire.html#cb67-4" aria-hidden="true" tabindex="-1"></a>modele4<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (milk120_ct<span class="sc">+</span>milk120_ct_sq<span class="sc">+</span>milk120_ct_cu)) </span>
<span id="cb67-5"><a href="régression-linéaire.html#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (milk120_ct + milk120_ct_sq + milk120_ct_cu), 
##     data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -68.71 -38.40 -15.64  25.59 223.22 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    6.724e+01  1.650e+00  40.761   &lt;2e-16 ***
## milk120_ct    -6.171e-03  3.163e-03  -1.951   0.0513 .  
## milk120_ct_sq  3.330e-06  2.067e-06   1.611   0.1073    
## milk120_ct_cu  2.651e-09  1.854e-09   1.430   0.1530    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.63 on 1532 degrees of freedom
##   (440 observations deleted due to missingness)
## Multiple R-squared:  0.005023,   Adjusted R-squared:  0.003075 
## F-statistic: 2.578 on 3 and 1532 DF,  p-value: 0.05222</code></pre>
<p>Effectivement, le terme au cube à <em>P</em>=0.15 (i.e. n’ajoute rien au modèle).</p>
<p><strong>c.</strong> Dans ce dernier modèle, vérifiez qu’il n’y a pas de problème sévère de colinéarité.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="régression-linéaire.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb69-2"><a href="régression-linéaire.html#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(modele4)</span></code></pre></div>
<pre><code>##    milk120_ct milk120_ct_sq milk120_ct_cu 
##      2.808468      1.074436      2.918711</code></pre>
<p><strong>Réponse:</strong> Les VIF sont tous &lt; 10, donc pas de problème.</p>
<p><strong>3)</strong> Dans le modèle suivant <span class="math inline">\(wpc = β_0 +β_1parityct + β_2twin + β_3dyst\)</span> vous vous demandez si les problèmes de vêlage (i.e. twin et dyst ensemble) apporte significativement au modèle. Quel test pourriez-vous réaliser afin de répondre à cette question? Quel est le résultat de ce test et votre interprétation de ce résultat?</p>
<p><strong>Réponse:</strong> Test de <em>F</em> pour comparer modèle complet (i.e. parity_ct, twin et dyst) vs. modèle réduit (i.e. parity_ct).</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="régression-linéaire.html#cb71-1" aria-hidden="true" tabindex="-1"></a>modele_complet <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (par_ct<span class="sc">+</span>twin<span class="sc">+</span>dyst))</span>
<span id="cb71-2"><a href="régression-linéaire.html#cb71-2" aria-hidden="true" tabindex="-1"></a>modele_reduit <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (par_ct))</span>
<span id="cb71-3"><a href="régression-linéaire.html#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele_complet, modele_reduit)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wpc ~ (par_ct + twin + dyst)
## Model 2: wpc ~ (par_ct)
##   Res.Df     RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1   1570 4167004                              
## 2   1572 4182050 -2    -15046 2.8345 0.05905 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><em>P</em> =0.06, donc ces variables, ensemble, n’apporte pas au modèle (i.e. les coefficients de régression ne sont pas différent de 0).</p>
<p><strong>4)</strong> Recodez maintenant parity afin d’avoir une nouvelle variable catégorique (parity_cat) à 3 niveaux (parity 1, parity 2 et parity ≥3). Vérifiez la relation entre parity_cat et WPC en vous assurant d’avoir parity 1 comme valeur de référence.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="régression-linéaire.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je créé une variable parity catégorique:</span></span>
<span id="cb73-2"><a href="régression-linéaire.html#cb73-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_cat <span class="ot">&lt;-</span> <span class="fu">cut</span>(daisy2_mod<span class="sc">$</span>parity, <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="cn">Inf</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;First&quot;</span>, <span class="st">&quot;Second&quot;</span>, <span class="st">&quot;Third or more&quot;</span>))</span>
<span id="cb73-3"><a href="régression-linéaire.html#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Je fixe le niveau de référence</span></span>
<span id="cb73-4"><a href="régression-linéaire.html#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co">#J&#39;écris le modèle</span></span>
<span id="cb73-5"><a href="régression-linéaire.html#cb73-5" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">within</span>(daisy2_mod, par_cat<span class="ot">&lt;-</span><span class="fu">relevel</span>(par_cat, <span class="at">ref=</span><span class="st">&quot;First&quot;</span>)) <span class="co">#Sélection de la valeur de référence par_cat=1</span></span>
<span id="cb73-6"><a href="régression-linéaire.html#cb73-6" aria-hidden="true" tabindex="-1"></a>modele5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (par_cat))</span>
<span id="cb73-7"><a href="régression-linéaire.html#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (par_cat), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -67.54 -38.21 -15.54  24.46 227.46 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           66.9520     2.5270  26.495   &lt;2e-16 ***
## par_catSecond          0.2592     3.6750   0.071    0.944    
## par_catThird or more   3.5895     3.1284   1.147    0.251    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.6 on 1571 degrees of freedom
##   (402 observations deleted due to missingness)
## Multiple R-squared:  0.001132,   Adjusted R-squared:  -0.0001392 
## F-statistic: 0.8905 on 2 and 1571 DF,  p-value: 0.4106</code></pre>
<p><strong>a.</strong> Est-ce que parity_cat (comme variable) est significativement associée à WPC?<br />
<strong>Réponse:</strong> Non, le test de <em>F</em> qui teste tous les coeffients ensemble donne <em>P</em>=0.41</p>
<p><strong>b.</strong> De combien WPC change pour une vache de 2ième parité comparativement à une vache de 1ère parité?<br />
<strong>Réponse:</strong> +0.3 jours</p>
<p><strong>c.</strong> Quel est le WPC pour une vache de 1ère parité?<br />
<strong>Réponse:</strong> 67.0 jours</p>
<p><strong>d.</strong> Quelle est la différence de WPC entre une 2ième et une 3ième parité et quel est l’IC 95% ajusté pour comparaisons multiples pour cette différence? Cette différence est-elle statistiquement significative?</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="régression-linéaire.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb75-2"><a href="régression-linéaire.html#cb75-2" aria-hidden="true" tabindex="-1"></a>contrast <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(modele5, <span class="st">&quot;par_cat&quot;</span>) <span class="co">#Ici j&#39;ai créé un objet nommé contrast qui contient les éléments dont j&#39;aurai besoin pour comparer les catégories de par_cat</span></span>
<span id="cb75-3"><a href="régression-linéaire.html#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(contrast) <span class="co">#Je demande ensuite de comparer les différentes catégories. </span></span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df t.ratio p.value
##  First - Second           -0.259 3.68 1571 -0.071  0.9973 
##  First - Third or more    -3.589 3.13 1571 -1.147  0.4850 
##  Second - Third or more   -3.330 3.24 1571 -1.027  0.5601 
## 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="régression-linéaire.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Pour voir les intervalle de confiance, je pourrais demander un confint() sur cet fonction pairs()</span></span>
<span id="cb77-2"><a href="régression-linéaire.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">pairs</span>(contrast))</span></code></pre></div>
<pre><code>##  contrast               estimate   SE   df lower.CL upper.CL
##  First - Second           -0.259 3.68 1571    -8.88     8.36
##  First - Third or more    -3.589 3.13 1571   -10.93     3.75
##  Second - Third or more   -3.330 3.24 1571   -10.94     4.28
## 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p><strong>Réponse:</strong> 3.3 jours de plus pour une 3ième parité (<em>vs</em>. 2ième). <em>IC95</em>: -4.3 à 10.9 jours de plus. Ce n’est pas une différence statistiquement significative (la valeur zéro est incluse dans l’<em>IC95</em>).</p>
<p><strong>5)</strong> Vous supposez que l’effet d’une dystocie (dyst) sur WPC varie en fonction de la parité (catégorique 1ère, 2ième, ou ≥3ième). Par exemple, une vache plus vieille ayant une dystocie aura possiblement un délai plus long jusqu’à la saille fécondante comparativement à une vache plus jeune.</p>
<p><strong>a.</strong> Que devrez-vous tester pour vérifier cette hypothèse?<br />
<strong>Réponse:</strong> L’interaction entre <em>dyst</em> et <em>par_cat</em>.</p>
<p><strong>b.</strong> Effectuer ce test. Est-ce que l’effet de dystocie varie de manière statistiquement significative en fonction de la parité?</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="régression-linéaire.html#cb79-1" aria-hidden="true" tabindex="-1"></a>modele6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (par_cat<span class="sc">*</span>dyst))</span>
<span id="cb79-2"><a href="régression-linéaire.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele6)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wpc ~ (par_cat * dyst), data = daisy2_mod)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -84.00 -37.65 -15.47  24.53 228.35 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                67.0249     2.7110  24.724   &lt;2e-16 ***
## par_catSecond               0.4429     3.8446   0.115   0.9083    
## par_catThird or more        2.6221     3.2911   0.797   0.4257    
## dyst                       -0.5428     7.3977  -0.073   0.9415    
## par_catSecond:dyst         -5.1015    14.7724  -0.345   0.7299    
## par_catThird or more:dyst  33.8958    13.5848   2.495   0.0127 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 51.51 on 1568 degrees of freedom
##   (402 observations deleted due to missingness)
## Multiple R-squared:  0.006688,   Adjusted R-squared:  0.00352 
## F-statistic: 2.111 on 5 and 1568 DF,  p-value: 0.0615</code></pre>
<p><strong>Réponse:</strong> Notez que j’ai maintenant 2 coefficients (<em>par_catSecond:dyst</em> et <em>par_catThird or more:dyst</em>) qui, ensemble, représente l’interaction entre <em>par_cat</em> et <em>dyst</em>. Je dois donc faire un test de <em>F</em> sur ces 2 coefficients à la fois.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="régression-linéaire.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle réduit sans les deux coefficients:</span></span>
<span id="cb81-2"><a href="régression-linéaire.html#cb81-2" aria-hidden="true" tabindex="-1"></a>modele_red <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (par_cat<span class="sc">+</span>dyst))</span>
<span id="cb81-3"><a href="régression-linéaire.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co">#La fonction anova() pour comparer les modèles:</span></span>
<span id="cb81-4"><a href="régression-linéaire.html#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modele6, modele_red)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wpc ~ (par_cat * dyst)
## Model 2: wpc ~ (par_cat + dyst)
##   Res.Df     RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1   1568 4160082                              
## 2   1570 4179615 -2    -19533 3.6812 0.02541 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Oui l’interaction est significative, j’obtiens une valeur de <em>P</em>=0.03 pour le test de <em>F</em>.</p>
<p><strong>c.</strong> Quel est le nombre de jours moyen jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie (i.e. remplir le tableau suivant)? Pour quel niveau de parité les différences semblent les plus importantes?</p>
<table>
<caption><span id="tab:unnamed-chunk-128">Table 6.2: </span>Nombre moyen estimé de jours jusqu’à la saillie fécondante pour chacune des catégories de parité et de dystocie</caption>
<thead>
<tr class="header">
<th align="left">Parite</th>
<th align="left">Dystocie_0</th>
<th align="left">Dystocie_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1ère lactation</td>
<td align="left">67.0 jours</td>
<td align="left">67.0-0.5=66.5 jours</td>
</tr>
<tr class="even">
<td align="left">2ième lactation</td>
<td align="left">67.0+0.4=67.4 jours</td>
<td align="left">67.0+0.4-0.5-5.1=61.8 jours</td>
</tr>
<tr class="odd">
<td align="left">3ième ou plus</td>
<td align="left">67.0+2.6=69.6 jours</td>
<td align="left">67.0+2.6-0.5+33.9=103.0 jours</td>
</tr>
</tbody>
</table>

</div>
</div>
<div id="travaux-pratiques-2---régression-linéaire---évaluation-du-modèle" class="section level2" number="6.11">
<h2><span class="header-section-number">6.11</span> Travaux pratiques 2 - Régression linéaire - Évaluation du modèle</h2>
<div id="exercices-1" class="section level3" number="6.11.1">
<h3><span class="header-section-number">6.11.1</span> Exercices</h3>
<p>Pour ce TP utilisez le fichier DAISY2 (voir description VER p.809).</p>
<p><strong>Ne sélectionnez que les 7 troupeaux avec h7=1. </strong></p>
<p>Nous nous intéresserons d’abord au modèle suivant qui permet d’évaluer l’effet de dystocie (<em>dyst</em>) sur le nombre de jours jusqu’à la saillie fécondante (<em>WPC</em>). Cette association est ajustée pour 3 facteurs confondants (<em>parity</em>, <em>herd_size</em> et <em>twin</em>). Un des confondants (<em>herd_size</em>) n’a pas une relation linéaire avec WPC. Cette relation a donc due être modélisée avec l’ajout d’un terme quadratique. Finalement, l’interaction entre dystocie et parité est également d’intérêt.</p>
<p><span class="math inline">\(wpc = β_0 +β_1dyst + β_2parity + β_3dyst*parity + β_4herdsize + β_5herdsize^2 + β_6twin\)</span></p>
<p><strong>1)</strong> D’abord vous pourriez créer les nouvelles variables centrées et quadratiques qui seront utilisées dans ce modèle.</p>
<p><span class="math inline">\(Parity\)</span> pourrait être centrée sur une première lactation.<br />
<span class="math inline">\(Herdsize\)</span> pourrait être centré sur 250 vaches.<br />
<span class="math inline">\(Herdsize^2\)</span> sera, en fait, votre variable <em>herd_size</em> centrée et mise au carré.</p>
<p>Maintenant, estimez ce modèle à l’aide de la fonction <code>lm</code> et évaluer d’abord graphiquement les suppositions de normalité des résiduels (i.e. l’histogramme des résiduel et le Q-Q plot) et d’homoscédasticité de la variance (i.e. les résiduels x valeurs prédites). Quels sont vos conclusions ? Notez qu’un simple histogramme de <em>WPC</em> vous aurait possiblement aussi indiqué les problèmes potentiels avec la variable <em>WPC</em>.</p>
<p><strong>2)</strong> Afin d’améliorer les suppositions du modèle (i.e. normalité des résiduels et homoscédasticité), vous pourriez tenter de transformer <em>WPC</em>. Essayez les transformations suivantes et utilisées les comme variables dépendantes dans votre modèle à la place de <em>WPC</em>. Dans quels cas les suppositions de normalité et d’homoscédasticité sont améliorées et quelle transformation préféreriez-vous utiliser?</p>
<ol style="list-style-type: lower-alpha">
<li>Le log naturel de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<ol start="2" style="list-style-type: lower-alpha">
<li>L’inverse de <em>WPC</em> (1/<em>WPC</em>)<br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<ol start="3" style="list-style-type: lower-alpha">
<li>La racine carrée de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<p><strong>3)</strong> Outre l’amélioration des suppositions du modèle, est-ce que la transformation par le logarithme naturel pourrait vous offrir d’autres avantages comparativement, par exemple, à la transformation par la racine carrée?</p>
<p><strong>4)</strong> Vous décidez donc de continuer à travailler avec le logarithme naturel de <em>WPC</em>. Rappelez-vous que lorsque vous aviez évalué la relation entre <em>herd_size</em> et <em>WPC</em>, cette relation semblait curvilinéaire. Est-ce que cela implique que la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em> est également curvilinéaire ?</p>
<p><strong>5)</strong> Évaluer graphiquement et à l’aide de termes quadratique et cubique la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em>. Avez-vous besoin d’inclure un terme au carré ? Un terme au cube ?</p>
<p><strong>6)</strong> Dans votre modèle avec le logarithme naturel de <em>WPC</em>, et <em>herd_size</em> modélisé avec les termes polynomiaux appropriés, est-ce que l’interaction entre <em>dyst</em> et <em>parity</em> est toujours statistiquement significative ?</p>
<p><strong>7)</strong> Si l’interaction n’est plus statistiquement significative cela signifie que:</p>
<ol style="list-style-type: lower-alpha">
<li>L’effet de dystocie ne varie pas en fonction de la parité<br />
</li>
<li>Le terme d’interaction n’est pas nécessaire dans le modèle<br />
</li>
<li>Le coefficient de régression pour le terme d’interaction n’est pas différent de zéro<br />
</li>
<li>Toutes ces réponses</li>
</ol>
<p><strong>8)</strong> Comme vous avez pu le noter, transformer la variable dépendante vous oblige à revoir pratiquement tout votre modèle de A à Z. Mais bon, votre modèle final pourrait donc être :</p>
<p><span class="math inline">\(log(wpc) = β_0 +β_1dyst + β_2parity_c + β_3herdsize _c + β_4herdsize_c^2 + β_5twin\)</span></p>
<p>Évaluez une dernière fois les suppositions de normalité des résiduels et d’homoscédasticité (puisque vous ne l’avez pas encore fait pour ce modèle sans l’interaction <span class="math inline">\(dyst*parity\)</span>) et calculez dans une nouvelle table les valeurs prédites, les résiduels de Student, les leviers et les distance de Cook.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Combien d’observations ont des résiduels larges (résiduels de Student &gt; 3.0 ou &lt; -3.0)? Ont-elles quelque chose en commun en ce qui a trait à leurs valeurs de <em>WPC</em>, <em>dyst</em>, <em>parity</em>, <em>herd_size</em> ou <em>twin</em>?</p></li>
<li><p>Vous pourriez représenter graphiquement les résiduels de Student en fonction de <em>WPC</em> pour mieux visualiser où se situent ses résiduels larges. Quel genre d’observations (en termes de <em>WPC</em>) le modèle semble avoir de la difficulté à prédire?</p></li>
<li><p>Évaluer maintenant les 5 ou 10 observations avec les leviers les plus élevés. Encore une fois, ont-elles quelque chose en commun?</p></li>
<li><p>Les observations avec des résiduels ou des leviers larges (ou les deux) sont des observations qui peuvent potentiellement influencer le modèle de régression. Les distances de Cook nous permettrons d’identifier quelles observations avaient effectivement une influence sur le modèle. Évaluer donc maintenant les 5 ou 10 observations avec les distances de Cook les plus élevées. Ont-elles quelque chose en commun ?</p></li>
<li><p>Vérifiez maintenant jusqu’à quel point ces observations influencent vos résultats en calculant de nouveau votre modèle mais sans les observations avec les distance de Cook les plus élevées (e.g. les 7 observations avec les distances de Cook &gt; 0.010). Est-ce que les conclusions des tests de <em>F</em> ou de <em>T</em> changent comparativement au modèle calculé au début de la question 8? Est-ce que les estimés obtenus changent beaucoup ? Pour quel paramètre l’estimé semble être le plus affecté ? Est-ce en accord avec votre réponse à la question 8.d. ?</p></li>
</ol>
</div>
<div id="code-r-et-réponses-1" class="section level3" number="6.11.2">
<h3><span class="header-section-number">6.11.2</span> Code R et réponses</h3>
<p><strong>1)</strong> D’abord vous pourriez créer les nouvelles variables centrées et quadratiques qui seront utilisées dans ce modèle. Maintenant, estimez ce modèle à l’aide de la fonction <code>lm</code> et évaluer d’abord graphiquement les suppositions de normalité des résiduels (i.e. l’histogramme des résiduel et le Q-Q plot) et d’homoscédasticité de la variance (i.e. les résiduels x valeurs prédites). Quels sont vos conclusions? Notez qu’un simple histogramme de <em>WPC</em> vous aurait possiblement aussi indiqué les problèmes potentiels avec la variable <em>WPC</em>.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="régression-linéaire.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co">#J&#39;ouvre le jeu de données</span></span>
<span id="cb83-2"><a href="régression-linéaire.html#cb83-2" aria-hidden="true" tabindex="-1"></a>daisy2 <span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;daisy2.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>, <span class="at">sep=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb83-3"><a href="régression-linéaire.html#cb83-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="ot">&lt;-</span><span class="fu">subset</span>(daisy2, h7<span class="sc">==</span><span class="dv">1</span>)</span>
<span id="cb83-4"><a href="régression-linéaire.html#cb83-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-5"><a href="régression-linéaire.html#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère les nouvelles variables</span></span>
<span id="cb83-6"><a href="régression-linéaire.html#cb83-6" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>par_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>parity<span class="dv">-1</span></span>
<span id="cb83-7"><a href="régression-linéaire.html#cb83-7" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct <span class="ot">&lt;-</span> daisy2_mod<span class="sc">$</span>herd_size<span class="dv">-250</span></span>
<span id="cb83-8"><a href="régression-linéaire.html#cb83-8" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct_sq <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>herd_size_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct</span>
<span id="cb83-9"><a href="régression-linéaire.html#cb83-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-10"><a href="régression-linéaire.html#cb83-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère le modèle</span></span>
<span id="cb83-11"><a href="régression-linéaire.html#cb83-11" aria-hidden="true" tabindex="-1"></a>modele1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin))</span>
<span id="cb83-12"><a href="régression-linéaire.html#cb83-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele1, <span class="dv">2</span>) <span class="co">#Je demande la 2 figure Normal Q-Q</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-130-1.png" width="672" /></p>
<p><strong>Réponse:</strong> La normalité des résiduels est problématique</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="régression-linéaire.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele1, <span class="dv">1</span>) <span class="co">#Je demande la la figure Residual vs Fitted</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-131-1.png" width="672" /></p>
<p><strong>Réponse:</strong> Il semble aussi y avoir un problème d’hétéroscédascticité (<em>i.e.</em> la variance augmente avec l’augmentation des valeurs prédites).</p>
<p><strong>2)</strong> Afin d’améliorer les suppositions du modèle (i.e. normalité des résiduels et homoscédasticité), vous pourriez tenter de transformer <em>WPC</em>. Essayez les transformations suivantes et utilisées les comme variables dépendantes dans votre modèle à la place de <em>WPC</em>. Dans quels cas les suppositions de normalité et d’homoscédasticité sont améliorées et quelle transformation préféreriez-vous utiliser?</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="régression-linéaire.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère les nouvelles variables en bloc:</span></span>
<span id="cb85-2"><a href="régression-linéaire.html#cb85-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>ln_wpc <span class="ot">&lt;-</span> <span class="fu">log</span>(daisy2_mod<span class="sc">$</span>wpc)</span>
<span id="cb85-3"><a href="régression-linéaire.html#cb85-3" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>inv_wpc <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>daisy2_mod<span class="sc">$</span>wpc</span>
<span id="cb85-4"><a href="régression-linéaire.html#cb85-4" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>sqr_wpc <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(daisy2_mod<span class="sc">$</span>wpc)</span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Le log naturel de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="régression-linéaire.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère le modèle pour log_wpc</span></span>
<span id="cb86-2"><a href="régression-linéaire.html#cb86-2" aria-hidden="true" tabindex="-1"></a>modele_log<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, ln_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin))</span>
<span id="cb86-3"><a href="régression-linéaire.html#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_log, <span class="dv">2</span>) <span class="co">#Je demande la 2 figure Normal Q-Q</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-133-1.png" width="672" /></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="régression-linéaire.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_log, <span class="dv">1</span>) <span class="co">#Je demande la la figure Residual vs Fitted</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-133-2.png" width="672" /></p>
<p><strong>Réponse:</strong> Normalité est très améliorée; homoscédasticité est beaucoup mieux. Peut-être une légère diminution de la variance avec augmentation des valeurs prédites.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>L’inverse de <em>WPC</em> (1/<em>WPC</em>)<br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="régression-linéaire.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère le modèle pour inv_wpc</span></span>
<span id="cb88-2"><a href="régression-linéaire.html#cb88-2" aria-hidden="true" tabindex="-1"></a>modele_inv<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, inv_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin))</span>
<span id="cb88-3"><a href="régression-linéaire.html#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_inv, <span class="dv">2</span>) <span class="co">#Je demande la 2 figure Normal Q-Q</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-134-1.png" width="672" /></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="régression-linéaire.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_inv, <span class="dv">1</span>) <span class="co">#Je demande la la figure Residual vs Fitted</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-134-2.png" width="672" /></p>
<p><strong>Réponse:</strong> Normalité est pire; homoscédasticité est pire aussi,variance augmente clairement avec augmentation des valeurs prédites.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>La racine carrée de <em>WPC</em><br />
</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Normalité des résiduels ?<br />
</li>
<li>Homoscédasticité ?</li>
</ol>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="régression-linéaire.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère le modèle pour sqr_wpc</span></span>
<span id="cb90-2"><a href="régression-linéaire.html#cb90-2" aria-hidden="true" tabindex="-1"></a>modele_sqr<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, sqr_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin))</span>
<span id="cb90-3"><a href="régression-linéaire.html#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_sqr, <span class="dv">2</span>) <span class="co">#Je demande la 2 figure Normal Q-Q</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-135-1.png" width="672" /></p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="régression-linéaire.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_sqr, <span class="dv">1</span>) <span class="co">#Je demande la la figure Residual vs Fitted</span></span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-135-2.png" width="672" /></p>
<p><strong>Réponse:</strong> Normalité des résiduels est un peu mieux que <em>WPC</em> mais encore problématique (<em>ln_wpc</em> était meilleur de ce côté). L’homoscédasticité est beaucoup mieux. Peut-être même un peu mieux que <em>ln_wpc</em> sur cet aspect.</p>
<p><strong>3)</strong> Outre l’amélioration des suppositions du modèle, est-ce que la transformation par le logarithme naturel pourrait vous offrir d’autres avantages comparativement, par exemple, à la transformation par la racine carrée?</p>
<p><strong>Réponse:</strong> Oui, côté interprétation ce sera plus facile parce que nous pourrons directement retransformer et plus facilement interpréter l’estimé (i.e. l’exposant de <span class="math inline">\(β_1\)</span>) et son IC 95%. Par exemple, avec le <span class="math inline">\(β\)</span> de dyst (et IC 95%) de 0.027 (-0.163, 0.218) nous obtiendrons des valeurs retransformées de 1.03 (0.85, 1.24). Nous pourrons interpréter ces valeurs comme suit : <em>WPC</em> est multiplié par un facteur de 1.03 lorsque dystocie est présente, et nous avons 95% de certitude que la vraie valeur se situe entre une multiplication par 0.85 (i.e. une diminution du nombre de jours) et une multiplication par 1.24.</p>
<p><strong>4)</strong> Vous décidez donc de continuer à travailler avec le logarithme naturel de <em>WPC</em>. Rappelez-vous que lorsque vous aviez évalué la relation entre <em>herd_size</em> et <em>WPC</em>, cette relation semblait curvilinéaire. Est-ce que cela implique que la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em> est également curvilinéaire ?</p>
<p><strong>Réponse:</strong> Pas nécessairement, <em>ln_wpc</em> est une variable différente.</p>
<p><strong>5)</strong> Évaluer graphiquement et à l’aide de termes quadratique et cubique la relation entre <em>herd_size</em> et le logarithme naturel de <em>WPC</em>. Avez-vous besoin d’inclure un terme au carré ? Un terme au cube ?</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="régression-linéaire.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb92-2"><a href="régression-linéaire.html#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(daisy2_mod, <span class="fu">aes</span>(herd_size, ln_wpc)) <span class="sc">+</span> </span>
<span id="cb92-3"><a href="régression-linéaire.html#cb92-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb92-4"><a href="régression-linéaire.html#cb92-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="dv">2</span>)<span class="sc">+</span> </span>
<span id="cb92-5"><a href="régression-linéaire.html#cb92-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-136"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-136-1.png" alt="Relation entre taille de troupeau (herd_size) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.7: Relation entre taille de troupeau (herd_size) et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Graphiquement, la relation avec <em>ln_wpc</em> semble aussi curvilinéaire.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="régression-linéaire.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère le modèle avec le terme au carré</span></span>
<span id="cb93-2"><a href="régression-linéaire.html#cb93-2" aria-hidden="true" tabindex="-1"></a>modele_log2<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, ln_wpc <span class="sc">~</span> (herd_size_ct <span class="sc">+</span> herd_size_ct_sq))</span>
<span id="cb93-3"><a href="régression-linéaire.html#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_log2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (herd_size_ct + herd_size_ct_sq), data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9279 -0.5420 -0.0283  0.5442  1.7717 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.881e+00  2.568e-02 151.147  &lt; 2e-16 ***
## herd_size_ct    3.357e-03  3.145e-04  10.676  &lt; 2e-16 ***
## herd_size_ct_sq 1.922e-05  4.564e-06   4.212 2.68e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7402 on 1571 degrees of freedom
##   (402 observations deleted due to missingness)
## Multiple R-squared:  0.06839,    Adjusted R-squared:  0.06721 
## F-statistic: 57.67 on 2 and 1571 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Aussi, le terme au carré est significatif (<em>P</em> &lt; 0.001), cela confirme la relation curvilinéaire.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="régression-linéaire.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je genère la variable au cube</span></span>
<span id="cb95-2"><a href="régression-linéaire.html#cb95-2" aria-hidden="true" tabindex="-1"></a>daisy2_mod<span class="sc">$</span>herd_size_ct_cu <span class="ot">&lt;-</span>daisy2_mod<span class="sc">$</span>herd_size_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct<span class="sc">*</span>daisy2_mod<span class="sc">$</span>herd_size_ct</span>
<span id="cb95-3"><a href="régression-linéaire.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère le modèle avec le terme au cube</span></span>
<span id="cb95-4"><a href="régression-linéaire.html#cb95-4" aria-hidden="true" tabindex="-1"></a>modele_log3<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, ln_wpc <span class="sc">~</span> (herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> herd_size_ct_cu))</span>
<span id="cb95-5"><a href="régression-linéaire.html#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_log3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (herd_size_ct + herd_size_ct_sq + herd_size_ct_cu), 
##     data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9243 -0.5377 -0.0293  0.5416  1.7768 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.879e+00  2.754e-02 140.868  &lt; 2e-16 ***
## herd_size_ct    3.230e-03  6.862e-04   4.707 2.73e-06 ***
## herd_size_ct_sq 2.012e-05  6.254e-06   3.217  0.00132 ** 
## herd_size_ct_cu 1.687e-08  8.074e-08   0.209  0.83452    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7404 on 1570 degrees of freedom
##   (402 observations deleted due to missingness)
## Multiple R-squared:  0.06842,    Adjusted R-squared:  0.06664 
## F-statistic: 38.44 on 3 and 1570 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Par contre le terme au cube n’est pas nécessaire (<em>P</em>=0.83) je pourrais l’enlever du modèle.</p>
<p><strong>6)</strong> Dans votre modèle avec le logarithme naturel de <em>WPC</em>, et <em>herd_size</em> modélisé avec les termes polynomiaux appropriés, est-ce que l’interaction entre <em>dyst</em> et <em>parity</em> est toujours statistiquement significative ?</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="régression-linéaire.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère le modèle pour log_wpc</span></span>
<span id="cb97-2"><a href="régression-linéaire.html#cb97-2" aria-hidden="true" tabindex="-1"></a>modele_log<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, ln_wpc <span class="sc">~</span> (dyst<span class="sc">*</span>par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin))</span>
<span id="cb97-3"><a href="régression-linéaire.html#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_log)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (dyst * par_ct + herd_size_ct + herd_size_ct_sq + 
##     twin), data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9054 -0.5348 -0.0242  0.5413  1.7691 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.851e+00  3.446e-02 111.734  &lt; 2e-16 ***
## dyst            2.747e-02  9.715e-02   0.283  0.77735    
## par_ct          6.599e-03  1.292e-02   0.511  0.60960    
## herd_size_ct    3.438e-03  3.163e-04  10.872  &lt; 2e-16 ***
## herd_size_ct_sq 2.029e-05  4.580e-06   4.430 1.01e-05 ***
## twin            4.577e-01  1.438e-01   3.184  0.00148 ** 
## dyst:par_ct     1.031e-01  6.160e-02   1.673  0.09449 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7373 on 1567 degrees of freedom
##   (402 observations deleted due to missingness)
## Multiple R-squared:  0.07782,    Adjusted R-squared:  0.07429 
## F-statistic: 22.04 on 6 and 1567 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Non, <em>P</em> =0.0945</p>
<p><strong>7)</strong> Si l’interaction n’est plus statistiquement significative cela signifie que:</p>
<ol style="list-style-type: lower-alpha">
<li>L’effet de dystocie ne varie pas en fonction de la parité<br />
</li>
<li>Le terme d’interaction n’est pas nécessaire dans le modèle<br />
</li>
<li>Le coefficient de régression pour le terme d’interaction n’est pas différent de zéro<br />
</li>
<li>Toutes ces réponses</li>
</ol>
<p><strong>Réponse:</strong> d. Toutes ces réponses.</p>
<p><strong>8)</strong> Comme vous avez pu le noter, transformer la variable dépendante vous oblige à revoir pratiquement tout votre modèle de A à Z. Mais bon, votre modèle final pourrait donc être :</p>
<p><span class="math inline">\(log(wpc) = β_0 +β_1dyst + β_2parity_c + β_3herdsize _c + β_4herdsize_c^2 + β_5twin\)</span></p>
<p>Évaluez une dernière fois les suppositions de normalité des résiduels et d’homoscédasticité (puisque vous ne l’avez pas encore fait pour ce modèle sans l’interaction <span class="math inline">\(dyst*parity\)</span>) et calculez dans une nouvelle table les valeurs prédites, les résiduels de Student, les leviers et les distance de Cook.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="régression-linéaire.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Générons le modèle sans l&#39;interaction</span></span>
<span id="cb99-2"><a href="régression-linéaire.html#cb99-2" aria-hidden="true" tabindex="-1"></a>modele_final<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>daisy2_mod, ln_wpc <span class="sc">~</span> (dyst <span class="sc">+</span> par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin))</span>
<span id="cb99-3"><a href="régression-linéaire.html#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_final)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (dyst + par_ct + herd_size_ct + herd_size_ct_sq + 
##     twin), data = daisy2_mod)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9017 -0.5355 -0.0242  0.5342  1.7585 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.842e+00  3.413e-02 112.583  &lt; 2e-16 ***
## dyst            1.196e-01  8.008e-02   1.494  0.13548    
## par_ct          1.112e-02  1.264e-02   0.880  0.37911    
## herd_size_ct    3.440e-03  3.164e-04  10.870  &lt; 2e-16 ***
## herd_size_ct_sq 2.035e-05  4.582e-06   4.441 9.58e-06 ***
## twin            4.523e-01  1.438e-01   3.145  0.00169 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7378 on 1568 degrees of freedom
##   (402 observations deleted due to missingness)
## Multiple R-squared:  0.07617,    Adjusted R-squared:  0.07323 
## F-statistic: 25.86 on 5 and 1568 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="régression-linéaire.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions d&#39;abord les suppositions:</span></span>
<span id="cb101-2"><a href="régression-linéaire.html#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_final, <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-140-1.png" width="672" /></p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="régression-linéaire.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modele_final, <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-140-2.png" width="672" /></p>
<p><strong>Réponses:</strong> OK, les suppositions semblent respectées.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="régression-linéaire.html#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Enregistrons les valeurs prédites, les résiduels de Student, les leviers et les distance de Cook</span></span>
<span id="cb103-2"><a href="régression-linéaire.html#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb103-3"><a href="régression-linéaire.html#cb103-3" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(modele_final) <span class="co">#Je viens de créer une nouvelle table dans laquelle les résiduels, distance de cook, etc se trouvent maintenant</span></span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Combien d’observations ont des résiduels larges (résiduels de Student &gt; 3.0 ou &lt; -3.0)? Ont-elles quelque chose en commun en ce qui a trait à leurs valeurs de <em>WPC</em>, <em>dyst</em>, <em>parity</em>, <em>herd_size</em> ou <em>twin</em>?</li>
</ol>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="régression-linéaire.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je pourrais maintenant filtrer cette table pour ne conserver que les résiduels standardisés larges</span></span>
<span id="cb104-2"><a href="régression-linéaire.html#cb104-2" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, (.std.resid <span class="sc">&gt;=</span><span class="fl">3.0</span> <span class="sc">|</span> .std.resid<span class="sc">&lt;=-</span><span class="fl">3.0</span>))</span>
<span id="cb104-3"><a href="régression-linéaire.html#cb104-3" aria-hidden="true" tabindex="-1"></a>diag_res</span></code></pre></div>
<pre><code>## # A tibble: 5 x 13
##   .rownames ln_wpc  dyst par_ct herd_size_ct herd_size_ct_sq  twin .fitted .resid    .hat .sigma .cooksd .std.resid
##   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;        &lt;dbl&gt;           &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;
## 1 445         1.10     0      3          -15             225     0    3.83  -2.73 0.00189  0.735 0.00432      -3.70
## 2 1091        1.39     0      3          -49            2401     0    3.76  -2.37 0.00190  0.736 0.00328      -3.22
## 3 1144        0        0      1          -49            2401     0    3.73  -3.73 0.00153  0.732 0.00657      -5.06
## 4 1177        1.39     0      0          -49            2401     0    3.72  -2.34 0.00223  0.736 0.00375      -3.17
## 5 2500        0        0      1           13             169     0    3.90  -3.90 0.00134  0.731 0.00624      -5.29</code></pre>
<p><strong>Réponse:</strong> 5 observations ont des résiduels larges. Elles ont toutes des WPC très courts (<em>i.e.</em> des <em>log_wpc</em> près de 0 ou 1), pas de jumeaux (<em>twin</em>=0) et pas de dystocie (<em>dyst</em>=0).</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Vous pourriez représenter graphiquement les résiduels de Student en fonction de <em>WPC</em> pour mieux visualiser où se situent ses résiduels larges. Quel genre d’observations (en termes de <em>WPC</em>) le modèle semble avoir de la difficulté à prédire?</li>
</ol>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="régression-linéaire.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb106-2"><a href="régression-linéaire.html#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diag, <span class="fu">aes</span>(ln_wpc, .std.resid, <span class="at">colour=</span>.std.resid)) <span class="sc">+</span> </span>
<span id="cb106-3"><a href="régression-linéaire.html#cb106-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  </span>
<span id="cb106-4"><a href="régression-linéaire.html#cb106-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb106-5"><a href="régression-linéaire.html#cb106-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="dv">3</span>)) <span class="sc">+</span> </span>
<span id="cb106-6"><a href="régression-linéaire.html#cb106-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span> (<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="sc">-</span><span class="dv">3</span>))</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-143"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-143-1.png" alt="Relation entre résiduels standardisés et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.8: Relation entre résiduels standardisés et le nombre de jours jusqu’à la saillie fécondante (wpc) avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Le modèle semble avoir de la difficulté à prédire les vaches avec <em>log_WPC</em> très courts.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Évaluer maintenant les 5 ou 10 observations avec les leviers les plus élevés. Encore une fois, ont-elles quelque chose en commun?</li>
</ol>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="régression-linéaire.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je pourrais maintenant ordonner cette table pour voir les 10 observations avec les leviers les plus larges</span></span>
<span id="cb107-2"><a href="régression-linéaire.html#cb107-2" aria-hidden="true" tabindex="-1"></a>diag_hat <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.hat),]</span>
<span id="cb107-3"><a href="régression-linéaire.html#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diag_hat, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 13
##    .rownames ln_wpc  dyst par_ct herd_size_ct herd_size_ct_sq  twin .fitted  .resid   .hat .sigma    .cooksd .std.resid
##    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;        &lt;dbl&gt;           &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1 48          4.60     1      1           44            1936     1    4.62 -0.0211 0.0473  0.738 0.00000710    -0.0293
##  2 5628        3.14     1      0          -65            4225     1    4.28 -1.14   0.0470  0.737 0.0207        -1.58  
##  3 1148        3.47     1      1          -49            2401     1    4.31 -0.840  0.0461  0.738 0.0110        -1.17  
##  4 1363        4.36     0      2         -125           15625     1    4.20  0.152  0.0439  0.738 0.000339       0.210 
##  5 791         3.64     0      4           83            6889     1    4.76 -1.13   0.0405  0.737 0.0171        -1.56  
##  6 313         4.79     0      0           44            1936     1    4.49  0.302  0.0395  0.738 0.00120        0.418 
##  7 377         5.15     0      5          -15             225     1    4.30  0.844  0.0393  0.738 0.00930        1.17  
##  8 2627        3.97     0      5           13             169     1    4.40 -0.428  0.0393  0.738 0.00239       -0.592 
##  9 2628        4.66     0      5           13             169     1    4.40  0.265  0.0393  0.738 0.000914       0.366 
## 10 2513        4.70     0      0           13             169     1    4.34  0.358  0.0392  0.738 0.00166        0.494</code></pre>
<p><strong>Réponse:</strong> Ces vaches ont toutes eu des jumeaux.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Les observations avec des résiduels ou des leviers larges (ou les deux) sont des observations qui peuvent potentiellement influencer le modèle de régression. Les distances de Cook nous permettrons d’identifier quelles observations avaient effectivement une influence sur le modèle. Évaluer donc maintenant les 5 ou 10 observations avec les distances de Cook les plus élevées. Ont-elles quelque chose en commun ?</li>
</ol>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="régression-linéaire.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je pourrais maintenant ordonner cette table pour voir les 10 observations avec les distance de Cook les plus larges</span></span>
<span id="cb109-2"><a href="régression-linéaire.html#cb109-2" aria-hidden="true" tabindex="-1"></a>diag_cook <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.cooksd),]</span>
<span id="cb109-3"><a href="régression-linéaire.html#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diag_cook, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 13
##    .rownames ln_wpc  dyst par_ct herd_size_ct herd_size_ct_sq  twin .fitted .resid   .hat .sigma .cooksd .std.resid
##    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;        &lt;dbl&gt;           &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;
##  1 491         2.64     0      2          -15             225     1    4.27 -1.63  0.0375  0.737 0.0330       -2.25
##  2 5628        3.14     1      0          -65            4225     1    4.28 -1.14  0.0470  0.737 0.0207       -1.58
##  3 791         3.64     0      4           83            6889     1    4.76 -1.13  0.0405  0.737 0.0171       -1.56
##  4 1148        3.47     1      1          -49            2401     1    4.31 -0.840 0.0461  0.738 0.0110       -1.17
##  5 1239        5.45     1      4          -49            2401     0    3.89  1.56  0.0138  0.737 0.0106        2.13
##  6 1230        5.53     1      3          -49            2401     0    3.88  1.66  0.0122  0.737 0.0106        2.26
##  7 5527        5.48     1      3          -65            4225     0    3.86  1.62  0.0124  0.737 0.0102        2.21
##  8 377         5.15     0      5          -15             225     1    4.30  0.844 0.0393  0.738 0.00930       1.17
##  9 2543        2.40     1      0           13             169     0    4.01 -1.61  0.0112  0.737 0.00916      -2.20
## 10 2753        2.40     1      1           13             169     0    4.02 -1.62  0.0111  0.737 0.00913      -2.21</code></pre>
<p><strong>Réponse:</strong> Les vaches qui ont eu des jumeaux sont les pires. Les <em>log_WPC</em> courts (i.e. résiduels larges) ne semble pas influencer beaucoup le modèle.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Vérifiez maintenant jusqu’à quel point ces observations influencent vos résultats en calculant de nouveau votre modèle mais sans les observations avec les distance de Cook les plus élevées (e.g. les 7 observations avec les distances de Cook &gt; 0.010).</li>
</ol>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="régression-linéaire.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Je génère un jeu de données sans les 7 observations avec les distances de Cook les plus grandes</span></span>
<span id="cb111-2"><a href="régression-linéaire.html#cb111-2" aria-hidden="true" tabindex="-1"></a>outlier <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, .cooksd<span class="sc">&lt;</span><span class="fl">0.01</span>)</span>
<span id="cb111-3"><a href="régression-linéaire.html#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Je refais le modèle sur ce jeu de données réduit</span></span>
<span id="cb111-4"><a href="régression-linéaire.html#cb111-4" aria-hidden="true" tabindex="-1"></a>modele_outlier<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>outlier, ln_wpc <span class="sc">~</span> (dyst <span class="sc">+</span> par_ct <span class="sc">+</span> herd_size_ct <span class="sc">+</span> herd_size_ct_sq <span class="sc">+</span> twin))</span>
<span id="cb111-5"><a href="régression-linéaire.html#cb111-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modele_outlier)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ln_wpc ~ (dyst + par_ct + herd_size_ct + herd_size_ct_sq + 
##     twin), data = outlier)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9025 -0.5359 -0.0304  0.5329  1.7697 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.847e+00  3.397e-02 113.257  &lt; 2e-16 ***
## dyst            8.378e-02  8.160e-02   1.027    0.305    
## par_ct          6.913e-03  1.260e-02   0.548    0.583    
## herd_size_ct    3.485e-03  3.148e-04  11.070  &lt; 2e-16 ***
## herd_size_ct_sq 2.079e-05  4.557e-06   4.562 5.46e-06 ***
## twin            6.656e-01  1.546e-01   4.306 1.77e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7329 on 1561 degrees of freedom
## Multiple R-squared:  0.0826, Adjusted R-squared:  0.07966 
## F-statistic: 28.11 on 5 and 1561 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Est-ce que les conclusions des tests de <em>F</em> ou de <em>T</em> changent comparativement au modèle calculé au début de la question 8?</p>
<p><strong>Réponse:</strong> Les valeurs de <em>P</em> changent un peu mais aucune des conclusions n’est modifiée.</p>
<p>Est-ce que les estimés obtenus changent beaucoup ? Pour quel paramètre l’estimé semble être le plus affecté ? Est-ce en accord avec votre réponse à la question 8.d. ?</p>
<p><strong>Réponse:</strong> Les estimés ne changent pas beaucoup. Le paramètre qui semble être le plus affecté est <em>twin</em>. Ce dernier passe de +0.45 <em>log_wpc</em> à +0.66 <em>log_wpc</em> lorsque les observations influentes sont retirées. C’est bien certainement en accord avec le fait que les observations les plus influentes sont des observations où <em>twin</em>=1.</p>

</div>
</div>
<div id="travaux-pratiques-3---régression-linéaire---construction-de-modèle" class="section level2" number="6.12">
<h2><span class="header-section-number">6.12</span> Travaux pratiques 3 - Régression linéaire - Construction de modèle</h2>
<div id="exercices-2" class="section level3" number="6.12.1">
<h3><span class="header-section-number">6.12.1</span> Exercices</h3>
<p>Les données utilisées pour ce TP sont obtenues à partir de la page du cours sur Studium. La base de données <em>milk2</em> est disponible en format ASCII délimité (.csv).</p>
<p>Le jeu de données <em>milk2</em> comprend 5 variables et 1140 observations:</p>
<p><strong>breed</strong> race de la vache (1 = Ayrshire, 2 = Holstein, 3 = Jersey, 8 =mixed)<br />
<strong>parity</strong> numéro de lactation<br />
<strong>kgmilk</strong> production journalière de lait en kg<br />
<strong>cellcount</strong> comptage en cellules somatiques x 10^3 cell./ml de lait<br />
<strong>cowid</strong> identification de la vache</p>
<p>Vous êtes intéressé à savoir quel est l’effet de la production laitière sur le comptage des cellules somatiques. Votre diagramme causal est le suivant:</p>
<div class="figure">
<img src="Figures/Diag%20causal%20tp3.png" alt="" />
<p class="caption">Diagramme causal de la relation entre production laitière et comptage des cellules somatiques.</p>
</div>
<p>À partir du jeu de données fourni (<em>milk2</em>), répondre aux questions suivantes :</p>
<ol style="list-style-type: decimal">
<li><p>Quels sont les variables confondantes que vous devrez possiblement contrôler pour répondre à votre question de recherche?</p></li>
<li><p>Quel serait votre modèle maximum ?</p></li>
<li><p>Quelles sont les étapes que vous aurez à réaliser afin de développer et évaluer ce modèle statistique ?</p></li>
</ol>
<p>Évidemment, ce serait difficile de tout faire cela dans un TP de 3hrs. Dans les questions suivantes, vous n’aurez qu’à évaluer certains aspects de ce travail.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Que pensez-vous de la variable <em>cellcount</em> (données manquantes, distribution)? Pensez-vous que cette variable causera des problèmes plus tard? Si oui, que pourriez-vous faire ?</p></li>
<li><p>Évaluez la variable parity. Peu de vaches ont eu 5, 6, 7 ou 8 lactations. Pensez-vous qu’il serait préférable de catégoriser cette variable (e.g. 1ère vs. 2ième vs. 3ième vs. 4ième vs. &gt; 4ième)?</p></li>
<li><p>À propose de la relation entre <em>kgmilk</em> et <em>cellcount</em> :</p>
<p>6.1. Comment se comportent les résiduels (normalité et homoscédasticité) dans un model simple:<br />
<span class="math inline">\(cellcount=β_0 + β_1*kgmilk\)</span> ?<br />
Et avec <span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk\)</span>?</p>
<p>Comme noté à la question 4, il semble qu’il serait mieux de travailler avec le logarithme naturel de <em>cellcount</em> qu’avec la variable originale. Continuez donc avec le log(<em>cellcount</em>) pour les analyses suivantes.</p>
<p>6.2. Comment est-ce que log(<em>cellcount</em>) varie en fonction de kgmilk? Est-ce que cette relation est linéaire? Comment allez-vous modéliser cette relation dans vos analyses subséquentes?</p></li>
<li><p>Associations conditionnelles.</p>
<p>7.1. La relation entre <em>parity</em> et <em>cellcount</em> également n’était pas linéaire et vous devrez donc modéliser cette relation à l’aide de 2 termes : <span class="math inline">\(parity centrée\)</span> et <span class="math inline">\(parity centrée^2\)</span>. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour le facteur confondant parité ?<br />
i.e. le modèle:<br />
<span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk centré + β_2*kgmilk centré^2 + β_3*kgmilk centré^3 + β_4*parity centrée + β_5*parity centrée^2\)</span></p>
<p>7.2. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour <em>race</em>?</p></li>
<li><p>Afin de réduire votre modèle maximum, vous décidez de retirer du modèle les facteurs confondants hypothétique qui causaient une modification relative &lt; 10% de la mesure d’effet de <em>kgmilk</em>. Quel(s) facteurs confondant gardez-vous? Y-a-t’il d’autre variables que vous désirez maintenant retirer du modèle? Quel serait votre modèle final?</p></li>
<li><p>Évaluez si les suppositions de votre modèle final sont respectées.</p></li>
<li><p>Évaluez les observations extrêmes, leviers et influentes (nombre, profil commun).<br />
10.1. Quelle est la valeur de <em>cellcount</em> pour les observations avec les résiduels négatifs les plus larges?<br />
10.2. Une valeur de 1,000 cell./ml est assez inusitée pour un comptage des cellules somatiques. En fait la limite analytique du Fossomatic cell counter est généralement de 10,000 cell./ml. Vous appellez donc le laboratoire pour en savoir plus sur ces résultats. On vous dit qu’on donne la valeur « 1 » aux échantillons qui ne peuvent être analysés (échapé, mal conservé, etc). Il s’agit donc d’observations manquantes! Vous pouvez donc ré-évaluer le modèle en excluant ces observations (et en priant pour que les résultats changent peu).<br />
Notez comment votre Q-Q plot et l’histogramme des résiduels sont encore mieux sans ces observations. Combien d’observations avec un résiduel large (&gt;3 ou &lt;-3) avez-vous? Ces observations ont-elles quelquechose en commun?<br />
10.3. Vérifiez maintenant les 10 observations avec les leviers les plus grands. Ont-elles quelquechose en commun?<br />
10.4. Vérifiez maintenant les 10 observations les plus influentes. Ont-elles quelquechose en commun?</p></li>
<li><p>Présentation des résultats.<br />
11.1. Présentez les résultats de votre modèle dans une table que vous pourriez soumettre dans une publication scientifique.<br />
L’effet de la production laitière n’est plus sur l’échelle originale. En plus, la relation entre production et CCS n’est pas linéaire. Tout ça rend votre modèle difficile à interpréter et il faudrait possiblement trouver une manière de rendre l’information plus digestible pour vos lecteurs.<br />
11.2. Vous pourriez présenter comment le CCS varie en fonction de la production laitière pour différents scénarios. Vous pourriez, par exemple, compléter la table suivante, en calculant la valeur prédite pour chaque scénario à l’aide de votre modèle, puis en retransformant ces valeurs sur l’échelle originale:</p></li>
</ol>
<table>
<caption><span id="tab:unnamed-chunk-149">Table 6.3: </span>Valeurs prédites de comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) d’une vache Ayrshire pour différentes combinaisons de production et parité.</caption>
<thead>
<tr class="header">
<th align="left">Production</th>
<th align="center">1ère lactation</th>
<th align="center">2ième lactation</th>
<th align="center">3ième et plus</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">10kg/jour</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">20kg/jour</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">30kg/jour</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>11.3. Encore mieux : à partir d’une table <code>R</code> contenant les valeurs prédites, retransformez la valeur prédite sur l’échelle originale en créant une nouvelle variable <span class="math inline">\(CCS=exp(valeur prédite)\)</span>. Ensuite, vous pourrez utiliser le package <code>ggplot2</code> pour représenter dans un graphique nuage de points la relation entre la production laitière (en x) et la valeur prédite de CCS (en y).<br />
C’est plus simple à comprendre ainsi n’est-ce pas?</p>
</div>
<div id="code-r-et-réponses-2" class="section level3" number="6.12.2">
<h3><span class="header-section-number">6.12.2</span> Code R et réponses</h3>
<p>Les données utilisées pour ce TP sont obtenues à partir de la page du cours sur Studium. La base de données <em>milk2</em> est disponible en format ASCII délimité (.csv).</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="régression-linéaire.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co">#J&#39;ouvre le jeu de données</span></span>
<span id="cb113-2"><a href="régression-linéaire.html#cb113-2" aria-hidden="true" tabindex="-1"></a>milk2 <span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">&quot;milk2.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>, <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Quels sont les variables confondantes que vous devrez possiblement contrôler pour répondre à votre question de recherche?<br />
<strong>Réponse:</strong> Parité et Race</p></li>
<li><p>Quel serait votre modèle maximum ?<br />
<strong>Réponse:</strong> <span class="math inline">\(cellcount = β_0 + β_1*kgmilk + β_2*breed + β_3*parity\)</span></p></li>
<li><p>Quelles sont les étapes que vous aurez à réaliser afin de développer et évaluer ce modèle statistique ?<br />
<strong>Réponse:</strong></p>
<ol style="list-style-type: decimal">
<li>Évaluer <em>cellcount</em> seul (données manquantes, distribution, transformation…)<br />
</li>
<li>Évaluer individuellement <em>kgmilk</em>, <em>breed</em> et <em>parity</em> (données manquantes, distributions, table de fréquence, transformations pour centrer ou mettre à l’échelle, décider des catégories de référence…)<br />
</li>
<li>Évaluer association inconditionnelle entre chaque prédicteur et <em>cellcount</em> (graphiques et modèles, linéarité de la relation pour les variables continues):<br />
Pour <em>Kgmilk</em>:<br />
</li>
</ol>
<ul>
<li>Nuage de points <em>kgmilk</em> x <em>cellcount</em> avec courbe loess pour linéarité<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*kgmilk\)</span><br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*kgmilk + β_2*kgmilk^2\)</span> (pour évaluer forme de la relation)<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*kgmilk + β_2*kgmilk^2 + kgmilk^3\)</span> (pour évaluer forme de la relation)<br />
Pour <em>Breed</em>:<br />
</li>
<li>Box-plot <em>cellcount</em> x <em>breed</em><br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*breed\)</span><br />
Pour <em>Parity</em>:<br />
</li>
<li>Nuage de points avec loess ou box-plot <em>cellcount</em> x <em>parity</em> pour linéarité<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*parity\)</span><br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*parity + β_2*parity^2\)</span> (pour évaluer forme de la relation)<br />
</li>
<li>Modèle <span class="math inline">\(cellcount = β_0 + β_1*parity + β_2*parity^2 + parity^3\)</span> (pour évaluer forme de la relation)<br />
</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Évaluer associations inconditionnelle entre prédicteurs<br />
Pour <em>Kgmilk</em> et <em>breed</em>:<br />
</li>
</ol>
<ul>
<li>Boxplot <em>kgmilk</em> x <em>breed</em><br />
</li>
<li>Modèle <span class="math inline">\(kgmilk=β_0 + β_1*breed\)</span><br />
Pour <em>Parity</em> et <em>breed</em>:<br />
</li>
<li>Boxplot <em>parity</em> x <em>breed</em><br />
</li>
<li>Modèle <span class="math inline">\(parity=β_0 + β_1*breed\)</span><br />
Pour <em>Kgmilk</em> et <em>parity</em>:</li>
<li>Nuage de points <em>kgmilk</em> x <em>parity</em> avec courbe loess<br />
</li>
<li>Modèle <span class="math inline">\(kgmilk=β_0 + β_1*parity\)</span><br />
</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Évaluer associations conditionnelles (i.e. après avoir ajouté un confondant):<br />
<em>Breed</em> (confondant)<br />
</li>
</ol>
<ul>
<li>Modèle <span class="math inline">\(cellcount=β_0 + β_1*kgmilk + β_2*breed\)</span><br />
<em>Parity</em> (confondant)<br />
</li>
<li>Modèle <span class="math inline">\(cellcount=β_0 + β_1*kgmilk + β_2*Parity\)</span><br />
Notez : s’il y avait eu une interaction à investiguer, c’est à ce stade-ci que vous auriez pu évaluer le modèle avec juste l’interaction. Par exemple: <span class="math inline">\(cellcount= β_0 + β_1*kgmilk + β_2*parity + β_3*kgmilk*parity\)</span></li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>Établir une stratégie de sélection des covariables qui permettra de réduire le modèle maximum<br />
Confondants : par exemple on peut choisir de réduire le nombre de facteurs confondants en vérifiant si association conditionnelle et inconditionnelle diffèrent par plus de 10%<br />
Notez : s’il y avait eu une interaction à investiguer, c’est à ce stade-ci que vous auriez pu spécifier quels critères seront utilisés pour décider des interactions à retenir. Par exemple : si terme(s) d’interaction à une valeur de P &lt; 0.05, alors garder l’interaction et les termes principaux.<br />
</li>
<li>Évaluer le modèle<br />
Suppositions (homoscédasticité et normalité)<br />
Observations:<br />
</li>
</ol>
<ul>
<li>Extrêmes (résiduels)<br />
</li>
<li>Combinaisons de prédicteurs (leviers)<br />
</li>
<li>Influentes (Cook’s distance)</li>
</ul></li>
</ol>
<p>Évidemment, ce serait difficile de tout faire cela dans un TP de 3hrs. Dans les questions suivantes, vous n’aurez qu’à évaluer certains aspects de ce travail.</p>
<ol start="4" style="list-style-type: decimal">
<li>Que pensez-vous de la variable <em>cellcount</em> (données manquantes, distribution)? Pensez-vous que cette variable causera des problèmes plus tard? Si oui, que pourriez-vous faire ?</li>
</ol>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="régression-linéaire.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co">#J&#39;aime beaucoup le package summarytools pour les analyses descriptives. Ici j&#39;ai demandé les stats descriptives pour toute les variables de milk2.</span></span>
<span id="cb114-2"><a href="régression-linéaire.html#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="co">#J&#39;aurais aussi pu spécifier milk2$cellcount pour ne voir que cellcount.</span></span>
<span id="cb114-3"><a href="régression-linéaire.html#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Dans mon cas, comme je travaille avec RMarkdown, j&#39;ai du spécifier method=&#39;render&#39;. Cet argument n&#39;est pas nécessaire sinon.</span></span>
<span id="cb114-4"><a href="régression-linéaire.html#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(summarytools)</span>
<span id="cb114-5"><a href="régression-linéaire.html#cb114-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dfSummary</span>(milk2), <span class="at">method=</span><span class="st">&#39;render&#39;</span>)</span></code></pre></div>
<div class="container st-container">
<h3>Data Frame Summary</h3>
<h4>milk2</h4>
<strong>Dimensions</strong>: 1140 x 5
  <br/><strong>Duplicates</strong>: 54
<br/>
<table class="table table-striped table-bordered st-table st-table-striped st-table-bordered st-multiline ">
  <thead>
    <tr>
      <th align="center" class="st-protect-top-border"><strong>No</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Variable</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Stats / Values</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Freqs (% of Valid)</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Graph</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Valid</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Missing</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="center">1</td>
      <td align="left">breed
[integer]</td>
      <td align="left">Mean (sd) : 3.4 (2.6)
min < med < max:
1 < 2 < 8
IQR (CV) : 1 (0.8)</td>
      <td align="left" style="padding:0;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">1</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">161</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">14.1%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">2</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">518</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">45.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">3</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">196</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">17.2%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">8</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">265</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">23.2%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr></table></td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent"><img style="border:none;background-color:transparent;padding:0" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAFEAAABmBAMAAABB3mAQAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5QMXEycY1/oCfQAAAGlJREFUWMPt1EEKgCAQRmGP0Nwg7AZ2/7u5KUqcnEGoEN9bfwsVfkMYp3glessht/0sIZHIQvp3JGZvymi2Vnd/ComcVfp39O/eO3+Gpry/UkIikdKzIzH7bO/qYbW76w+ARM4q/TsaoQx1OaBjvjFCTwAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMS0wMy0yM1QxOTozOToyNCswMDowMIwRJZUAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjEtMDMtMjNUMTk6Mzk6MjQrMDA6MDD9TJ0pAAAAAElFTkSuQmCC"></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
    <tr>
      <td align="center">2</td>
      <td align="left">parity
[integer]</td>
      <td align="left">Mean (sd) : 2.3 (1.4)
min < med < max:
1 < 2 < 8
IQR (CV) : 2 (0.6)</td>
      <td align="left" style="padding:0;vertical-align:middle"><table style="border-collapse:collapse;border:none;margin:0"><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">1</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">421</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">37.0%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">2</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">311</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">27.3%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">3</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">200</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">17.6%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">4</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">125</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">11.0%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">5</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">45</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">4.0%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">6</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">27</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">2.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">7</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">5</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">0.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr><tr style="background-color:transparent"><td style="padding:0 2px 0 7px;margin:0;border:0" align="right">8</td><td style="padding:0 2px;border:0;" align="left">:</td><td style="padding:0 4px 0 6px;margin:0;border:0" align="right">5</td><td style="padding:0;border:0" align="left">(</td><td style="padding:0 2px;margin:0;border:0" align="right">0.4%</td><td style="padding:0 4px 0 0;border:0" align="left">)</td></tr></table></td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent"><img style="border:none;background-color:transparent;padding:0" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAEQAAADEBAMAAADUjZpZAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5QMXEycY1/oCfQAAAItJREFUWMPt07ENwCAMRNGs4BEIG5D9d0uTBskYF2Cj6F/9Cp90vq6zchv5SH2GaRBIGnFsV4wsJeoRPdEaNQgkmzi2m/NHRSVdIwgkhDiGKUay/qiMSdX7QiAbiWOYYiThj8qEVL0vBLKROIYpRuL/aEpqg0CiiWOYIkGkQCD/JRJFTioNgSwmp+QFVhggu7WwNhMAAAAldEVYdGRhdGU6Y3JlYXRlADIwMjEtMDMtMjNUMTk6Mzk6MjQrMDA6MDCMESWVAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIxLTAzLTIzVDE5OjM5OjI0KzAwOjAw/UydKQAAAABJRU5ErkJggg=="></td>
      <td align="center">1139
(99.9%)</td>
      <td align="center">1
(0.1%)</td>
    </tr>
    <tr>
      <td align="center">3</td>
      <td align="left">kgmilk
[numeric]</td>
      <td align="left">Mean (sd) : 19.9 (6.5)
min < med < max:
3.2 < 19.6 < 43.1
IQR (CV) : 8.3 (0.3)</td>
      <td align="left" style="vertical-align:middle">269 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent"><img style="border:none;background-color:transparent;padding:0" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5QMXEycY1/oCfQAAAJRJREFUaN7t2c0NgCAMhmFWwA3EDWT/3Uy0PdDIj9iTvt+lCQlPyoXQEAKZSbxPkqxxKG1sy1fAwMB+gOnt4YJJ3cHAwMDAwMDAvo0t8oTywUoEDAzsxDqTyjMstzsEAwMDAwMDA2tj+jLpYJV/GoOZXTVMKhgYmBtmZwzBUjnhD2K6bLDKrkFMW3HBdNkc810CmckBq/EjtWaIAf0AAAAldEVYdGRhdGU6Y3JlYXRlADIwMjEtMDMtMjNUMTk6Mzk6MjQrMDA6MDCMESWVAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIxLTAzLTIzVDE5OjM5OjI0KzAwOjAw/UydKQAAAABJRU5ErkJggg=="></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
    <tr>
      <td align="center">4</td>
      <td align="left">cellcount
[integer]</td>
      <td align="left">Mean (sd) : 369.9 (739.8)
min < med < max:
1 < 138 < 8100
IQR (CV) : 305 (2)</td>
      <td align="left" style="vertical-align:middle">422 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent"><img style="border:none;background-color:transparent;padding:0" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5QMXEycY1/oCfQAAAGhJREFUaN7t2bENgDAMAMGswAiEDfD+u0Ek0qBQ4KS8l9yeXLhzKcpU7/Zttgc7IgIGg8FgMBgMBoPBYDAYDAaDwWAwGAwGW4G1R1ZdhbU5YbAPbOrW3tjUdiMsvd0I62DvL1aXVJTpAofjHfXbt3AuAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIxLTAzLTIzVDE5OjM5OjI0KzAwOjAwjBEllQAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMS0wMy0yM1QxOTozOToyNCswMDowMP1MnSkAAAAASUVORK5CYII="></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
    <tr>
      <td align="center">5</td>
      <td align="left">cowid
[integer]</td>
      <td align="left">Mean (sd) : 227807355 (155552851)
min < med < max:
25930370 < 117880788 < 455261650
IQR (CV) : 271260050 (0.7)</td>
      <td align="left" style="vertical-align:middle">1086 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent"><img style="border:none;background-color:transparent;padding:0" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5QMXEycY1/oCfQAAAH5JREFUaN7t2MEJgDAMQNGsUDcwbqD77yaYXFJCkZCL8v8ll/JaeilUhCoNS6191IrYcT2BgYGBgYGBgYGBgYGBgYGBlbHNfyt6MFtxgoGBgYF9EJtehBRbfHFPWDxnii0OmGO+ew/m43+Y31IPlg4wMDAwsBqmoReYtiRU6QbCPrxcn2TkwAAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMS0wMy0yM1QxOTozOToyNCswMDowMIwRJZUAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjEtMDMtMjNUMTk6Mzk6MjQrMDA6MDD9TJ0pAAAAAElFTkSuQmCC"></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
  </tbody>
</table>
<p>Generated by <a href='https://github.com/dcomtois/summarytools'>summarytools</a> 0.9.8 (<a href='https://www.r-project.org/'>R</a> version 4.0.4)<br/>2021-03-23</p>
</div>
<p><strong>Réponse:</strong> Pour <code>cellcount</code>, il n’y a pas de données manquantes, la distribution est skewed à droite. Oui, les résiduels seront probablement skewed aussi. Je pourrais déjà vérifier si une transformation (par exemple un log naturel) améliorerait sa distribution :</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="régression-linéaire.html#cb115-1" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>log_cell <span class="ot">&lt;-</span> <span class="fu">log</span>(milk2<span class="sc">$</span>cellcount)</span>
<span id="cb115-2"><a href="régression-linéaire.html#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dfSummary</span>(milk2<span class="sc">$</span>log_cell), <span class="at">method=</span><span class="st">&#39;render&#39;</span>)</span></code></pre></div>
<pre><code>## milk2$log_cell was converted to a data frame</code></pre>
<div class="container st-container">
<h3>Data Frame Summary</h3>
<h4>milk2</h4>
<strong>Dimensions</strong>: 1140 x 1
  <br/><strong>Duplicates</strong>: 718
<br/>
<table class="table table-striped table-bordered st-table st-table-striped st-table-bordered st-multiline ">
  <thead>
    <tr>
      <th align="center" class="st-protect-top-border"><strong>No</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Variable</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Stats / Values</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Freqs (% of Valid)</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Graph</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Valid</strong></th>
      <th align="center" class="st-protect-top-border"><strong>Missing</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="center">1</td>
      <td align="left">log_cell
[numeric]</td>
      <td align="left">Mean (sd) : 5 (1.4)
min < med < max:
0 < 4.9 < 9
IQR (CV) : 1.9 (0.3)</td>
      <td align="left" style="vertical-align:middle">422 distinct values</td>
      <td align="left" style="vertical-align:middle;padding:0;background-color:transparent"><img style="border:none;background-color:transparent;padding:0" src="data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuBAMAAAApJ8cWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAD1BMVEX////9/v2mpqbw8PD///+xh0SBAAAAAnRSTlMAAHaTzTgAAAABYktHRACIBR1IAAAAB3RJTUUH5QMXEycY1/oCfQAAAIxJREFUaN7t2MEJwCAMheGs0G5Qu0Gz/26Fkhz0oNUIpe3/LkLQDy+BEBEykqWeZGlcu4fteuUAA3sd1uiEPkzrPwQDAwMDAwMD68J8UCkxK29dmCFaYnaCgYGBgYGBgYH9Hlvz8TOI5QgY2JNYuQMOYV4GAwObhnmPTsG8bFjKdygxzF99HEtTImQkJyiqUC9GnpymAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIxLTAzLTIzVDE5OjM5OjI0KzAwOjAwjBEllQAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMS0wMy0yM1QxOTozOToyNCswMDowMP1MnSkAAAAASUVORK5CYII="></td>
      <td align="center">1140
(100.0%)</td>
      <td align="center">0
(0.0%)</td>
    </tr>
  </tbody>
</table>
<p>Generated by <a href='https://github.com/dcomtois/summarytools'>summarytools</a> 0.9.8 (<a href='https://www.r-project.org/'>R</a> version 4.0.4)<br/>2021-03-23</p>
</div>
<ol start="5" style="list-style-type: decimal">
<li>Évaluez la variable parity. Peu de vaches ont eu 5, 6, 7 ou 8 lactations. Pensez-vous qu’il serait préférable de catégoriser cette variable (e.g. 1ère vs. 2ième vs. 3ième vs. 4ième vs. &gt; 4ième)?</li>
</ol>
<p><strong>Réponse:</strong> Voir mes résultats descriptifs précédents. Non, parce qu’elle est utilisée comme facteur confondant. Je préfère donc conserver la mesure la plus précise possible afin d’avoir le meilleur contrôle possible. S’il s’agissait d’une exposition, nous pourrions effectivement considérer cette catégorisation.</p>
<ol start="6" style="list-style-type: decimal">
<li><p>À propose de la relation entre <em>kgmilk</em> et <em>cellcount</em> :</p>
<p>6.1. Comment se comportent les résiduels (normalité et homoscédasticité) dans un model simple:<br />
<span class="math inline">\(cellcount=β_0 + β_1*kgmilk\)</span> ?<br />
Et avec <span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk\)</span>?</p></li>
</ol>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="régression-linéaire.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle avec cellcount et les figures de Dx des résiduels</span></span>
<span id="cb117-2"><a href="régression-linéaire.html#cb117-2" aria-hidden="true" tabindex="-1"></a>model_cellcount <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, cellcount <span class="sc">~</span> kgmilk)</span>
<span id="cb117-3"><a href="régression-linéaire.html#cb117-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_cellcount, <span class="dv">1</span>) </span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-153-1.png" width="672" /></p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="régression-linéaire.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_cellcount, <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-153-2.png" width="672" /></p>
<p><strong>Réponse:</strong> Problème de normalité et possiblement homoscédasticité!</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="régression-linéaire.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le modèle avec le logarithme de cellcount et les figures de Dx des résiduels</span></span>
<span id="cb119-2"><a href="régression-linéaire.html#cb119-2" aria-hidden="true" tabindex="-1"></a>model_log_cell <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, log_cell <span class="sc">~</span> kgmilk)</span>
<span id="cb119-3"><a href="régression-linéaire.html#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_log_cell, <span class="dv">1</span>) </span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-154-1.png" width="672" /></p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="régression-linéaire.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_log_cell, <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-154-2.png" width="672" /></p>
<p><strong>Réponse:</strong> Dans le modèle avec le logarithme naturel de <em>cellcount</em> c’est beaucoup mieux.</p>
<p>Comme noté à la question 4, il semble qu’il serait mieux de travailler avec le logarithme naturel de <em>cellcount</em> qu’avec la variable originale. Continuez donc avec le log(<em>cellcount</em>) pour les analyses suivantes.</p>
<p>6.2. Comment est-ce que log(<em>cellcount</em>) varie en fonction de kgmilk? Est-ce que cette relation est linéaire? Comment allez-vous modéliser cette relation dans vos analyses subséquentes?</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="régression-linéaire.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb121-2"><a href="régression-linéaire.html#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(milk2, <span class="fu">aes</span>(kgmilk, log_cell)) <span class="sc">+</span> </span>
<span id="cb121-3"><a href="régression-linéaire.html#cb121-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  <span class="co">#</span></span>
<span id="cb121-4"><a href="régression-linéaire.html#cb121-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="dv">2</span>)<span class="sc">+</span>  </span>
<span id="cb121-5"><a href="régression-linéaire.html#cb121-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-155"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-155-1.png" alt="Relation entre la production laitière (en kg/j) et le logarithme naturel de cellcount avec courbe lissée avec un facteur de 2." width="672" />
<p class="caption">
Figure 6.9: Relation entre la production laitière (en kg/j) et le logarithme naturel de cellcount avec courbe lissée avec un facteur de 2.
</p>
</div>
<p><strong>Réponse:</strong> Le logarithme de <em>cellcount</em> diminue avec la production puis augmente (i.e. une courbe). La relation n’est pas linéaire. Vérifions avec les termes polynomiaux…</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="régression-linéaire.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co">#D&#39;abord, centrons kgmilk sur une valeur près de la moyenne (pour éviter la colinéarité)</span></span>
<span id="cb122-2"><a href="régression-linéaire.html#cb122-2" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>kgmilk_ct <span class="ot">&lt;-</span> milk2<span class="sc">$</span>kgmilk<span class="dv">-20</span></span>
<span id="cb122-3"><a href="régression-linéaire.html#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Puis créons des terme au carré et au cube</span></span>
<span id="cb122-4"><a href="régression-linéaire.html#cb122-4" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>kgmilk_ct_sq <span class="ot">&lt;-</span> milk2<span class="sc">$</span>kgmilk_ct<span class="sc">*</span>milk2<span class="sc">$</span>kgmilk_ct </span>
<span id="cb122-5"><a href="régression-linéaire.html#cb122-5" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>kgmilk_ct_cu <span class="ot">&lt;-</span> milk2<span class="sc">$</span>kgmilk_ct<span class="sc">*</span>milk2<span class="sc">$</span>kgmilk_ct<span class="sc">*</span>milk2<span class="sc">$</span>kgmilk_ct</span>
<span id="cb122-6"><a href="régression-linéaire.html#cb122-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions le modèle avec le terme au carré</span></span>
<span id="cb122-7"><a href="régression-linéaire.html#cb122-7" aria-hidden="true" tabindex="-1"></a>model_sq <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, log_cell <span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq))</span>
<span id="cb122-8"><a href="régression-linéaire.html#cb122-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_sq)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9196 -0.9167 -0.0497  0.8787  4.2372 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.8028594  0.0491544  97.710  &lt; 2e-16 ***
## kgmilk_ct    -0.0281185  0.0064195  -4.380 1.30e-05 ***
## kgmilk_ct_sq  0.0035949  0.0006477   5.551 3.54e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.376 on 1137 degrees of freedom
## Multiple R-squared:  0.03517,    Adjusted R-squared:  0.03347 
## F-statistic: 20.72 on 2 and 1137 DF,  p-value: 1.448e-09</code></pre>
<p><strong>Réponse:</strong> Le terme au carré est significatif (<em>P</em> &lt; 0.05)</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="régression-linéaire.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions le modèle avec le terme au carré et le terme au cube</span></span>
<span id="cb124-2"><a href="régression-linéaire.html#cb124-2" aria-hidden="true" tabindex="-1"></a>model_cu <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, log_cell <span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu))</span>
<span id="cb124-3"><a href="régression-linéaire.html#cb124-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_cu)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu), 
##     data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.8668 -0.9016 -0.0672  0.8875  4.2224 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.787e+00  4.974e-02  96.235  &lt; 2e-16 ***
## kgmilk_ct    -1.282e-02  1.007e-02  -1.273   0.2031    
## kgmilk_ct_sq  4.236e-03  7.241e-04   5.850 6.41e-09 ***
## kgmilk_ct_cu -1.185e-04  6.014e-05  -1.970   0.0491 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.375 on 1136 degrees of freedom
## Multiple R-squared:  0.03845,    Adjusted R-squared:  0.03591 
## F-statistic: 15.14 on 3 and 1136 DF,  p-value: 1.145e-09</code></pre>
<p><strong>Réponse:</strong> Le terme au cube est aussi significatif (<em>P</em> &lt; 0.05). Cette relation devrait donc être modélisée en utilisant <span class="math inline">\(kgmilkcentré + kgmilkcentré^2 + kgmilk centré^3\)</span></p>
<ol start="7" style="list-style-type: decimal">
<li><p>Associations conditionnelles.</p>
<p>7.1. La relation entre <em>parity</em> et <em>cellcount</em> également n’était pas linéaire et vous devrez donc modéliser cette relation à l’aide de 2 termes : <span class="math inline">\(parity centrée\)</span> et <span class="math inline">\(parity centrée^2\)</span>. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour le facteur confondant parité ?<br />
i.e. le modèle:<br />
<span class="math inline">\(log(cellcount)=β_0 + β_1*kgmilk centré + + β_2*kgmilk centré^2 + β_3*kgmilk centré^3 + β_4*parity centrée + β_5*parity centrée^2\)</span></p></li>
</ol>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="régression-linéaire.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Générons ces nouvelles variables parité centrée sur parité 1</span></span>
<span id="cb126-2"><a href="régression-linéaire.html#cb126-2" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>parity_ct <span class="ot">&lt;-</span> milk2<span class="sc">$</span>parity<span class="dv">-1</span></span>
<span id="cb126-3"><a href="régression-linéaire.html#cb126-3" aria-hidden="true" tabindex="-1"></a>milk2<span class="sc">$</span>parity_ct_sq <span class="ot">&lt;-</span> milk2<span class="sc">$</span>parity_ct<span class="sc">*</span>milk2<span class="sc">$</span>parity_ct</span>
<span id="cb126-4"><a href="régression-linéaire.html#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions les modèles avec et sans ajustement pour parity (j&#39;ai déjà fait rouler celui sans parity à la question 6.2)</span></span>
<span id="cb126-5"><a href="régression-linéaire.html#cb126-5" aria-hidden="true" tabindex="-1"></a>model_parity <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq))</span>
<span id="cb126-6"><a href="régression-linéaire.html#cb126-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_parity)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu + 
##     parity_ct + parity_ct_sq), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.2194 -0.8303 -0.0055  0.8096  4.1204 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.383e+00  6.476e-02  67.679  &lt; 2e-16 ***
## kgmilk_ct    -3.452e-02  9.947e-03  -3.471 0.000539 ***
## kgmilk_ct_sq  2.985e-03  7.087e-04   4.212 2.73e-05 ***
## kgmilk_ct_cu -6.589e-05  5.816e-05  -1.133 0.257514    
## parity_ct     5.102e-01  7.125e-02   7.161 1.44e-12 ***
## parity_ct_sq -5.742e-02  1.514e-02  -3.794 0.000156 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.323 on 1133 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.1114, Adjusted R-squared:  0.1075 
## F-statistic: 28.41 on 5 and 1133 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Oui voir table suivante (notez que j’ai arrondi les estimés avant de faire les calculs). Notez aussi, le <span class="math inline">\(kgmilk^3\)</span> n’est plus significatif (<em>P</em> = 0.26) après avoir ajusté pour parité (i.e. <span class="math inline">\(kgmilk^3\)</span> ne serait plus nécessaire après ajustement pour parité).</p>
<table>
<caption><span id="tab:unnamed-chunk-160">Table 6.4: </span>Estimés de l’effet de la production laitière sans (inconditionelle) et avec (conditionelle) ajustement pour parity.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Inconditionnelle</th>
<th align="right">Conditionelle</th>
<th align="right">Diff_relative_parity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">kgmilk_ct</td>
<td align="right">-0.0128</td>
<td align="right">-0.0345</td>
<td align="right">-170</td>
</tr>
<tr class="even">
<td align="left">kgmilk_ct_sq</td>
<td align="right">0.0042</td>
<td align="right">0.0030</td>
<td align="right">29</td>
</tr>
<tr class="odd">
<td align="left">kgmilk_ct_cu</td>
<td align="right">-0.0001</td>
<td align="right">-0.0001</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>7.2. Trouvez-vous que les coefficients pour la production laitière changent beaucoup lorsqu’on ajuste pour <em>race</em>?</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="régression-linéaire.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vérifions les modèles avec ajustement pour race</span></span>
<span id="cb128-2"><a href="régression-linéaire.html#cb128-2" aria-hidden="true" tabindex="-1"></a>model_breed <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu <span class="sc">+</span> <span class="fu">factor</span>(breed)))</span>
<span id="cb128-3"><a href="régression-linéaire.html#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_breed)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu + 
##     factor(breed)), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9882 -0.8871 -0.0977  0.8370  4.0193 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     4.853e+00  1.117e-01  43.433  &lt; 2e-16 ***
## kgmilk_ct      -2.860e-02  1.026e-02  -2.787  0.00541 ** 
## kgmilk_ct_sq    3.754e-03  7.168e-04   5.237 1.94e-07 ***
## kgmilk_ct_cu   -7.864e-05  5.960e-05  -1.320  0.18726    
## factor(breed)2  1.880e-01  1.233e-01   1.524  0.12775    
## factor(breed)3 -5.860e-01  1.454e-01  -4.029 5.98e-05 ***
## factor(breed)8 -1.474e-01  1.361e-01  -1.083  0.27923    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.35 on 1133 degrees of freedom
## Multiple R-squared:  0.0749, Adjusted R-squared:   0.07 
## F-statistic: 15.29 on 6 and 1133 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Réponse:</strong> Notez que j’ai du indiquer que <em>breed</em> est une variable catégorique (parce que, dans la base de données, les catégories de races sont indiquées par des chiffres, ce qui peut laisser croire à <code>R</code> qu’il s’agit d’une variable quantitative). Voir la table suivante où je présente les estimés ajustés ou non pour <em>breed</em>.</p>
<table>
<caption><span id="tab:unnamed-chunk-163">Table 6.5: </span>Estimés de l’effet de la production laitière sans (inconditionelle) et avec (conditionelle) ajustement pour breed.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Inconditionnelle</th>
<th align="right">Conditionelle</th>
<th align="right">Diff_relative_breed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">kgmilk_ct</td>
<td align="right">-0.0128</td>
<td align="right">-0.0286</td>
<td align="right">-123</td>
</tr>
<tr class="even">
<td align="left">kgmilk_ct_sq</td>
<td align="right">0.0042</td>
<td align="right">0.0038</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="left">kgmilk_ct_cu</td>
<td align="right">-0.0001</td>
<td align="right">-0.0001</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<ol start="8" style="list-style-type: decimal">
<li>Afin de réduire votre modèle maximum, vous décidez de retirer du modèle les facteurs confondants hypothétique qui causaient une modification relative &lt; 10% de la mesure d’effet de <em>kgmilk</em>. Quel(s) facteurs confondant gardez-vous? Y-a-t’il d’autre variables que vous désirez maintenant retirer du modèle? Quel serait votre modèle final?</li>
</ol>
<p><strong>Réponse:</strong> Parité et race seront inclus comme facteur confondant (i.e. <span class="math inline">\(paritycentrée + paritycentrée^2 + breed\)</span>). Ces deux variables crééaient des changement importants (123 à 170% de différence relative) pour au moins un des termes <em>kgmilk</em>. Notez que l’ajout de point d’inflexion (i.e. <span class="math inline">\(kgmilk^3\)</span>) n’est plus nécessaire maintenant (voir résultats plus bas). Ce terme pourrait être retiré.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="régression-linéaire.html#cb130-1" aria-hidden="true" tabindex="-1"></a>model_max <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> kgmilk_ct_cu <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq <span class="sc">+</span> <span class="fu">factor</span>(breed)))</span>
<span id="cb130-2"><a href="régression-linéaire.html#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_max)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + kgmilk_ct_cu + 
##     parity_ct + parity_ct_sq + factor(breed)), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3616 -0.8233 -0.0648  0.8125  4.1456 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     4.406e+00  1.146e-01  38.463  &lt; 2e-16 ***
## kgmilk_ct      -5.924e-02  1.011e-02  -5.857 6.18e-09 ***
## kgmilk_ct_sq    2.260e-03  6.934e-04   3.259  0.00115 ** 
## kgmilk_ct_cu   -2.915e-06  5.701e-05  -0.051  0.95923    
## parity_ct       5.745e-01  6.950e-02   8.265 3.88e-16 ***
## parity_ct_sq   -6.241e-02  1.468e-02  -4.252 2.29e-05 ***
## factor(breed)2  2.043e-01  1.174e-01   1.741  0.08201 .  
## factor(breed)3 -7.932e-01  1.395e-01  -5.685 1.66e-08 ***
## factor(breed)8 -9.039e-02  1.296e-01  -0.697  0.48573    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.282 on 1130 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.1679, Adjusted R-squared:  0.162 
## F-statistic:  28.5 on 8 and 1130 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Le modèle final serait: <span class="math inline">\(Log(cellcount) = β_0 + β_1*kgmilk_ct + β_2*kgmilk_ct_sq + β_3*parity_ct + β_4*parity_ct_sq + β_5*breed\)</span> et voici les résultats de ce modèle:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="régression-linéaire.html#cb132-1" aria-hidden="true" tabindex="-1"></a>model_final <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2, log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq <span class="sc">+</span> <span class="fu">factor</span>(breed)))</span>
<span id="cb132-2"><a href="régression-linéaire.html#cb132-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_final)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + parity_ct + 
##     parity_ct_sq + factor(breed)), data = milk2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3612 -0.8246 -0.0672  0.8113  4.1447 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     4.406646   0.114237  38.574  &lt; 2e-16 ***
## kgmilk_ct      -0.059636   0.006509  -9.161  &lt; 2e-16 ***
## kgmilk_ct_sq    0.002244   0.000615   3.648 0.000276 ***
## parity_ct       0.574849   0.069058   8.324 2.43e-16 ***
## parity_ct_sq   -0.062466   0.014629  -4.270 2.12e-05 ***
## factor(breed)2  0.204097   0.117247   1.741 0.081999 .  
## factor(breed)3 -0.794119   0.138230  -5.745 1.18e-08 ***
## factor(breed)8 -0.090508   0.129543  -0.699 0.484900    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.281 on 1131 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.1679, Adjusted R-squared:  0.1628 
## F-statistic:  32.6 on 7 and 1131 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>Évaluez si les suppositions de votre modèle final sont respectées.</li>
</ol>
<p><strong>Réponse:</strong> Homoscédasticité semble OK (voir figure plus bas). Il ne semble pas y avoir d’augmentation ou de diminution flagrante de la variance des résiduels (à l’exception des extrémités, mais il y a très peu d’observations avec valeur prédite &gt; 6).</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="régression-linéaire.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final, <span class="dv">1</span>) </span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-166-1.png" width="672" /></p>
<p><strong>Réponse:</strong> Normalité des résiduels semble OK (voir figure plus bas). Il y a à peine une 30aine d’observations qui ne tombent pas sur la droite de 45 degré).</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="régression-linéaire.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final, <span class="dv">2</span>) </span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-167-1.png" width="672" /></p>
<ol start="10" style="list-style-type: decimal">
<li>Évaluez les observations extrêmes, leviers et influentes (nombre, profil commun).<br />
10.1. Quelle est la valeur de <em>cellcount</em> pour les observations avec les résiduels négatifs les plus larges?</li>
</ol>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="régression-linéaire.html#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb136-2"><a href="régression-linéaire.html#cb136-2" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(model_final) <span class="co">#Je viens de créer une nouvelle table dans laquelle les résiduels, distance de cook, etc se trouvent maintenant</span></span>
<span id="cb136-3"><a href="régression-linéaire.html#cb136-3" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, (.std.resid <span class="sc">&lt;</span> <span class="sc">-</span><span class="fl">3.0</span>)) <span class="co">#Gardons seulement les résiduels standardisés &lt;-3.0</span></span>
<span id="cb136-4"><a href="régression-linéaire.html#cb136-4" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> diag_res[<span class="fu">order</span>(<span class="sc">-</span>diag_res<span class="sc">$</span>.std.resid),] <span class="co">#Plaçons les résiduels en ordre décroissants</span></span>
<span id="cb136-5"><a href="régression-linéaire.html#cb136-5" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(diag_res) <span class="co">#Enlever les valeurs manquantes</span></span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-169">Table 6.6: </span>Observations avec les résiduels négatifs les plus larges.</caption>
<colgroup>
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
<col width="10%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">.rownames</th>
<th align="right">log_cell</th>
<th align="right">kgmilk_ct</th>
<th align="right">kgmilk_ct_sq</th>
<th align="right">parity_ct</th>
<th align="right">parity_ct_sq</th>
<th align="left">factor(breed)</th>
<th align="right">.fitted</th>
<th align="right">.hat</th>
<th align="right">.sigma</th>
<th align="right">.cooksd</th>
<th align="right">.std.resid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">107</td>
<td align="right">0</td>
<td align="right">2.4</td>
<td align="right">5.76</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">3</td>
<td align="right">3.994707</td>
<td align="right">0.0069269</td>
<td align="right">1.276052</td>
<td align="right">0.0085374</td>
<td align="right">-3.129175</td>
</tr>
<tr class="even">
<td align="left">114</td>
<td align="right">0</td>
<td align="right">2.1</td>
<td align="right">4.41</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">3</td>
<td align="right">4.009569</td>
<td align="right">0.0068426</td>
<td align="right">1.276011</td>
<td align="right">0.0084950</td>
<td align="right">-3.140684</td>
</tr>
<tr class="odd">
<td align="left">100</td>
<td align="right">0</td>
<td align="right">-0.2</td>
<td align="right">0.04</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">3</td>
<td align="right">4.136926</td>
<td align="right">0.0062477</td>
<td align="right">1.275652</td>
<td align="right">0.0082471</td>
<td align="right">-3.239472</td>
</tr>
<tr class="even">
<td align="left">595</td>
<td align="right">0</td>
<td align="right">3.1</td>
<td align="right">9.61</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">8</td>
<td align="right">4.152829</td>
<td align="right">0.0052622</td>
<td align="right">1.275612</td>
<td align="right">0.0069859</td>
<td align="right">-3.250314</td>
</tr>
<tr class="odd">
<td align="left">594</td>
<td align="right">0</td>
<td align="right">-0.3</td>
<td align="right">0.09</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">8</td>
<td align="right">4.334230</td>
<td align="right">0.0048561</td>
<td align="right">1.275078</td>
<td align="right">0.0070164</td>
<td align="right">-3.391600</td>
</tr>
<tr class="even">
<td align="left">155</td>
<td align="right">0</td>
<td align="right">2.0</td>
<td align="right">4.00</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="left">3</td>
<td align="right">4.402063</td>
<td align="right">0.0070718</td>
<td align="right">1.274856</td>
<td align="right">0.0105873</td>
<td align="right">-3.448521</td>
</tr>
<tr class="odd">
<td align="left">785</td>
<td align="right">0</td>
<td align="right">2.0</td>
<td align="right">4.00</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="left">3</td>
<td align="right">4.402063</td>
<td align="right">0.0070718</td>
<td align="right">1.274856</td>
<td align="right">0.0105873</td>
<td align="right">-3.448521</td>
</tr>
<tr class="even">
<td align="left">151</td>
<td align="right">0</td>
<td align="right">-1.2</td>
<td align="right">1.44</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="left">3</td>
<td align="right">4.587153</td>
<td align="right">0.0065241</td>
<td align="right">1.274278</td>
<td align="right">0.0105943</td>
<td align="right">-3.592527</td>
</tr>
<tr class="odd">
<td align="left">781</td>
<td align="right">0</td>
<td align="right">-1.2</td>
<td align="right">1.44</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="left">3</td>
<td align="right">4.587153</td>
<td align="right">0.0065241</td>
<td align="right">1.274278</td>
<td align="right">0.0105943</td>
<td align="right">-3.592527</td>
</tr>
<tr class="even">
<td align="left">113</td>
<td align="right">0</td>
<td align="right">-3.0</td>
<td align="right">9.00</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">1</td>
<td align="right">4.605745</td>
<td align="right">0.0074727</td>
<td align="right">1.274212</td>
<td align="right">0.0122567</td>
<td align="right">-3.608812</td>
</tr>
<tr class="odd">
<td align="left">250</td>
<td align="right">0</td>
<td align="right">2.8</td>
<td align="right">7.84</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="left">2</td>
<td align="right">5.361186</td>
<td align="right">0.0036766</td>
<td align="right">1.271613</td>
<td align="right">0.0081088</td>
<td align="right">-4.192724</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> le log(<em>cellcount</em>) est 0.0 (donc un <em>cellcount</em> de 1 x 1000 cellules/ml).</p>
<p>10.2. Une valeur de 1,000 cell./ml est assez inusitée pour un comptage des cellules somatiques. En fait la limite analytique du Fossomatic cell counter est généralement de 10,000 cell./ml. Vous appellez donc le laboratoire pour en savoir plus sur ces résultats. On vous dit qu’on donne la valeur « 1 » aux échantillons qui ne peuvent être analysés (échapé, mal conservé, etc). Il s’agit donc d’observations manquantes! Vous pouvez donc ré-évaluer le modèle en excluant ces observations (et en priant pour que les résultats changent peu).</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="régression-linéaire.html#cb137-1" aria-hidden="true" tabindex="-1"></a>milk2_corrected <span class="ot">&lt;-</span> <span class="fu">subset</span>(milk2, milk2<span class="sc">$</span>cellcount<span class="sc">&gt;</span><span class="dv">10</span>)</span>
<span id="cb137-2"><a href="régression-linéaire.html#cb137-2" aria-hidden="true" tabindex="-1"></a>milk2_corrected<span class="sc">$</span>breed <span class="ot">&lt;-</span> <span class="fu">factor</span>(milk2_corrected<span class="sc">$</span>breed)</span>
<span id="cb137-3"><a href="régression-linéaire.html#cb137-3" aria-hidden="true" tabindex="-1"></a>model_final2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>milk2_corrected, log_cell<span class="sc">~</span> (kgmilk_ct <span class="sc">+</span> kgmilk_ct_sq <span class="sc">+</span> parity_ct <span class="sc">+</span> parity_ct_sq <span class="sc">+</span> breed))</span>
<span id="cb137-4"><a href="régression-linéaire.html#cb137-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_final2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_cell ~ (kgmilk_ct + kgmilk_ct_sq + parity_ct + 
##     parity_ct_sq + breed), data = milk2_corrected)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6932 -0.8179 -0.1134  0.7179  4.0391 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.5993247  0.1070076  42.981  &lt; 2e-16 ***
## kgmilk_ct    -0.0472845  0.0060207  -7.854 9.61e-15 ***
## kgmilk_ct_sq  0.0014894  0.0005636   2.643  0.00834 ** 
## parity_ct     0.5513005  0.0638717   8.631  &lt; 2e-16 ***
## parity_ct_sq -0.0595009  0.0135340  -4.396 1.21e-05 ***
## breed2        0.0759856  0.1090067   0.697  0.48591    
## breed3       -0.6004440  0.1300708  -4.616 4.37e-06 ***
## breed8       -0.1529191  0.1207002  -1.267  0.20545    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.168 on 1093 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.1512, Adjusted R-squared:  0.1458 
## F-statistic: 27.81 on 7 and 1093 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="régression-linéaire.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final2, <span class="dv">1</span>) </span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-170-1.png" width="672" /></p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="régression-linéaire.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_final2, <span class="dv">2</span>) </span></code></pre></div>
<p><img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-170-2.png" width="672" /></p>
<p>Notez comment votre Q-Q plot et l’histogramme des résiduels sont encore mieux sans ces observations. Combien d’observations avec un résiduel large (&gt;3 ou &lt;-3) avez-vous? Ces observations ont-elles quelquechose en commun?</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="régression-linéaire.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb141-2"><a href="régression-linéaire.html#cb141-2" aria-hidden="true" tabindex="-1"></a>diag <span class="ot">&lt;-</span> <span class="fu">augment</span>(model_final2) <span class="co">#Je viens de créer une nouvelle table dans laquelle les résiduels, distance de cook, etc se trouvent maintenant</span></span>
<span id="cb141-3"><a href="régression-linéaire.html#cb141-3" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">subset</span>(diag, (.std.resid <span class="sc">&lt;</span> <span class="sc">-</span><span class="fl">3.0</span> <span class="sc">|</span> .std.resid <span class="sc">&gt;</span> <span class="fl">3.0</span>)) <span class="co">#Gardons seulement les résiduels standardisés &lt;-3.0 ou &gt;3.0</span></span>
<span id="cb141-4"><a href="régression-linéaire.html#cb141-4" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> diag_res[<span class="fu">order</span>(diag_res<span class="sc">$</span>.std.resid),] <span class="co">#Plaçons les résiduels en ordre croissants</span></span>
<span id="cb141-5"><a href="régression-linéaire.html#cb141-5" aria-hidden="true" tabindex="-1"></a>diag_res <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(diag_res) <span class="co">#Enlever les valeurs manquantes</span></span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-172">Table 6.7: </span>Observations avec les résiduels négatifs et positifs les plus larges.</caption>
<colgroup>
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
<col width="4%" />
<col width="6%" />
<col width="6%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">.rownames</th>
<th align="right">log_cell</th>
<th align="right">kgmilk_ct</th>
<th align="right">kgmilk_ct_sq</th>
<th align="right">parity_ct</th>
<th align="right">parity_ct_sq</th>
<th align="left">breed</th>
<th align="right">.fitted</th>
<th align="right">.resid</th>
<th align="right">.hat</th>
<th align="right">.sigma</th>
<th align="right">.cooksd</th>
<th align="right">.std.resid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1078</td>
<td align="right">8.214465</td>
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">1</td>
<td align="right">4.599325</td>
<td align="right">3.615140</td>
<td align="right">0.0083997</td>
<td align="right">1.162928</td>
<td align="right">0.0102372</td>
<td align="right">3.109376</td>
</tr>
<tr class="even">
<td align="left">327</td>
<td align="right">8.667852</td>
<td align="right">-5.5</td>
<td align="right">30.25</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">2</td>
<td align="right">4.980429</td>
<td align="right">3.687423</td>
<td align="right">0.0038030</td>
<td align="right">1.162744</td>
<td align="right">0.0047777</td>
<td align="right">3.164221</td>
</tr>
<tr class="odd">
<td align="left">856</td>
<td align="right">8.731498</td>
<td align="right">-4.8</td>
<td align="right">23.04</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">8</td>
<td align="right">4.707686</td>
<td align="right">4.023811</td>
<td align="right">0.0053392</td>
<td align="right">1.161708</td>
<td align="right">0.0080121</td>
<td align="right">3.455545</td>
</tr>
<tr class="even">
<td align="left">444</td>
<td align="right">8.575462</td>
<td align="right">-1.8</td>
<td align="right">3.24</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">8</td>
<td align="right">4.536343</td>
<td align="right">4.039119</td>
<td align="right">0.0050420</td>
<td align="right">1.161661</td>
<td align="right">0.0076191</td>
<td align="right">3.468173</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> Il y a seulement 4 observations extrêmes. Seulement des résiduels positifs (i.e. le modèle sous-estime la vraie valeur). Toutes des 1ère lactation. Un cellcount élevé (i.e. &gt; 3,000,000 cell./ml), mais des production assez moyennes. Différentes races. Le modèle à donc de la difficulté (i.e. il sous estime) la valeur de <em>cellcount</em> pour les 1ère lactation avec un <em>cellcount</em> élevé.</p>
<p>10.3. Vérifiez maintenant les 10 observations avec les leviers les plus grands. Ont-elles quelquechose en commun?</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="régression-linéaire.html#cb142-1" aria-hidden="true" tabindex="-1"></a>diag_hat <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.hat),]</span>
<span id="cb142-2"><a href="régression-linéaire.html#cb142-2" aria-hidden="true" tabindex="-1"></a>levier <span class="ot">&lt;-</span> <span class="fu">head</span>(diag_hat, <span class="dv">10</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-174">Table 6.8: </span>Observations avec les leviers les plus grands.</caption>
<colgroup>
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="9%" />
<col width="7%" />
<col width="9%" />
<col width="4%" />
<col width="6%" />
<col width="8%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">.rownames</th>
<th align="right">log_cell</th>
<th align="right">kgmilk_ct</th>
<th align="right">kgmilk_ct_sq</th>
<th align="right">parity_ct</th>
<th align="right">parity_ct_sq</th>
<th align="left">breed</th>
<th align="right">.fitted</th>
<th align="right">.resid</th>
<th align="right">.hat</th>
<th align="right">.sigma</th>
<th align="right">.cooksd</th>
<th align="right">.std.resid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">445</td>
<td align="right">6.975414</td>
<td align="right">14.0</td>
<td align="right">196.00</td>
<td align="right">7</td>
<td align="right">49</td>
<td align="left">2</td>
<td align="right">5.248804</td>
<td align="right">1.7266102</td>
<td align="right">0.0842281</td>
<td align="right">1.166829</td>
<td align="right">0.0274545</td>
<td align="right">1.5453153</td>
</tr>
<tr class="even">
<td align="left">812</td>
<td align="right">6.042633</td>
<td align="right">-5.4</td>
<td align="right">29.16</td>
<td align="right">7</td>
<td align="right">49</td>
<td align="left">3</td>
<td align="right">5.241207</td>
<td align="right">0.8014259</td>
<td align="right">0.0815466</td>
<td align="right">1.167832</td>
<td align="right">0.0056933</td>
<td align="right">0.7162279</td>
</tr>
<tr class="odd">
<td align="left">84</td>
<td align="right">5.669881</td>
<td align="right">-3.8</td>
<td align="right">14.44</td>
<td align="right">7</td>
<td align="right">49</td>
<td align="left">3</td>
<td align="right">5.143628</td>
<td align="right">0.5262528</td>
<td align="right">0.0814274</td>
<td align="right">1.167988</td>
<td align="right">0.0024506</td>
<td align="right">0.4702774</td>
</tr>
<tr class="even">
<td align="left">761</td>
<td align="right">5.669881</td>
<td align="right">-3.8</td>
<td align="right">14.44</td>
<td align="right">7</td>
<td align="right">49</td>
<td align="left">3</td>
<td align="right">5.143628</td>
<td align="right">0.5262528</td>
<td align="right">0.0814274</td>
<td align="right">1.167988</td>
<td align="right">0.0024506</td>
<td align="right">0.4702774</td>
</tr>
<tr class="odd">
<td align="left">446</td>
<td align="right">3.688880</td>
<td align="right">10.8</td>
<td align="right">116.64</td>
<td align="right">7</td>
<td align="right">49</td>
<td align="left">2</td>
<td align="right">5.281918</td>
<td align="right">-1.5930382</td>
<td align="right">0.0801917</td>
<td align="right">1.167024</td>
<td align="right">0.0220562</td>
<td align="right">-1.4226366</td>
</tr>
<tr class="even">
<td align="left">500</td>
<td align="right">3.912023</td>
<td align="right">23.1</td>
<td align="right">533.61</td>
<td align="right">4</td>
<td align="right">16</td>
<td align="left">2</td>
<td align="right">5.630969</td>
<td align="right">-1.7189460</td>
<td align="right">0.0571116</td>
<td align="right">1.166877</td>
<td align="right">0.0174049</td>
<td align="right">-1.5161721</td>
</tr>
<tr class="odd">
<td align="left">1116</td>
<td align="right">4.499810</td>
<td align="right">21.8</td>
<td align="right">475.24</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="left">2</td>
<td align="right">5.470710</td>
<td align="right">-0.9709003</td>
<td align="right">0.0447326</td>
<td align="right">1.167719</td>
<td align="right">0.0042371</td>
<td align="right">-0.8508022</td>
</tr>
<tr class="even">
<td align="left">733</td>
<td align="right">6.327937</td>
<td align="right">-1.0</td>
<td align="right">1.00</td>
<td align="right">6</td>
<td align="right">36</td>
<td align="left">1</td>
<td align="right">5.813870</td>
<td align="right">0.5140673</td>
<td align="right">0.0403140</td>
<td align="right">1.167998</td>
<td align="right">0.0010607</td>
<td align="right">0.4494401</td>
</tr>
<tr class="odd">
<td align="left">813</td>
<td align="right">4.812184</td>
<td align="right">0.4</td>
<td align="right">0.16</td>
<td align="right">6</td>
<td align="right">36</td>
<td align="left">8</td>
<td align="right">5.593501</td>
<td align="right">-0.7813167</td>
<td align="right">0.0380738</td>
<td align="right">1.167857</td>
<td align="right">0.0023032</td>
<td align="right">-0.6822957</td>
</tr>
<tr class="even">
<td align="left">210</td>
<td align="right">4.663439</td>
<td align="right">20.9</td>
<td align="right">436.81</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="left">2</td>
<td align="right">5.456029</td>
<td align="right">-0.7925905</td>
<td align="right">0.0377796</td>
<td align="right">1.167850</td>
<td align="right">0.0023504</td>
<td align="right">-0.6920349</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> Beaucoup de parité 8, <em>production</em>, <em>race</em> et <em>cellcount</em> assez variés. En fait être une 8ième lactation, peu importe le niveau des autres prédicteurs, semble être une combinaison de prédicteurs inusitée.</p>
<p>10.4. Vérifiez maintenant les 10 observations les plus influentes. Ont-elles quelquechose en commun?</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="régression-linéaire.html#cb143-1" aria-hidden="true" tabindex="-1"></a>diag_cook <span class="ot">&lt;-</span> diag[<span class="fu">order</span>(<span class="sc">-</span>diag<span class="sc">$</span>.cooksd),]</span>
<span id="cb143-2"><a href="régression-linéaire.html#cb143-2" aria-hidden="true" tabindex="-1"></a>influent <span class="ot">&lt;-</span> <span class="fu">head</span>(diag_cook, <span class="dv">10</span>)</span></code></pre></div>
<table style="width:100%;">
<caption><span id="tab:unnamed-chunk-176">Table 6.9: </span>Observations les plus influentes.</caption>
<colgroup>
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
<col width="4%" />
<col width="6%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">.rownames</th>
<th align="right">log_cell</th>
<th align="right">kgmilk_ct</th>
<th align="right">kgmilk_ct_sq</th>
<th align="right">parity_ct</th>
<th align="right">parity_ct_sq</th>
<th align="left">breed</th>
<th align="right">.fitted</th>
<th align="right">.resid</th>
<th align="right">.hat</th>
<th align="right">.sigma</th>
<th align="right">.cooksd</th>
<th align="right">.std.resid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">445</td>
<td align="right">6.975414</td>
<td align="right">14.0</td>
<td align="right">196.00</td>
<td align="right">7</td>
<td align="right">49</td>
<td align="left">2</td>
<td align="right">5.248804</td>
<td align="right">1.726610</td>
<td align="right">0.0842281</td>
<td align="right">1.166829</td>
<td align="right">0.0274545</td>
<td align="right">1.545315</td>
</tr>
<tr class="even">
<td align="left">446</td>
<td align="right">3.688880</td>
<td align="right">10.8</td>
<td align="right">116.64</td>
<td align="right">7</td>
<td align="right">49</td>
<td align="left">2</td>
<td align="right">5.281918</td>
<td align="right">-1.593038</td>
<td align="right">0.0801917</td>
<td align="right">1.167024</td>
<td align="right">0.0220562</td>
<td align="right">-1.422637</td>
</tr>
<tr class="odd">
<td align="left">214</td>
<td align="right">7.634821</td>
<td align="right">20.2</td>
<td align="right">408.04</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="left">2</td>
<td align="right">5.192483</td>
<td align="right">2.442337</td>
<td align="right">0.0341968</td>
<td align="right">1.165683</td>
<td align="right">0.0200522</td>
<td align="right">2.128520</td>
</tr>
<tr class="even">
<td align="left">874</td>
<td align="right">7.903966</td>
<td align="right">9.8</td>
<td align="right">96.04</td>
<td align="right">6</td>
<td align="right">36</td>
<td align="left">2</td>
<td align="right">5.520732</td>
<td align="right">2.383233</td>
<td align="right">0.0344921</td>
<td align="right">1.165798</td>
<td align="right">0.0192701</td>
<td align="right">2.077328</td>
</tr>
<tr class="odd">
<td align="left">500</td>
<td align="right">3.912023</td>
<td align="right">23.1</td>
<td align="right">533.61</td>
<td align="right">4</td>
<td align="right">16</td>
<td align="left">2</td>
<td align="right">5.630969</td>
<td align="right">-1.718946</td>
<td align="right">0.0571116</td>
<td align="right">1.166877</td>
<td align="right">0.0174049</td>
<td align="right">-1.516172</td>
</tr>
<tr class="even">
<td align="left">916</td>
<td align="right">8.984318</td>
<td align="right">-14.0</td>
<td align="right">196.00</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">2</td>
<td align="right">5.629210</td>
<td align="right">3.355108</td>
<td align="right">0.0154246</td>
<td align="right">1.163616</td>
<td align="right">0.0164238</td>
<td align="right">2.895999</td>
</tr>
<tr class="odd">
<td align="left">488</td>
<td align="right">8.999619</td>
<td align="right">1.9</td>
<td align="right">3.61</td>
<td align="right">5</td>
<td align="right">25</td>
<td align="left">2</td>
<td align="right">5.859827</td>
<td align="right">3.139793</td>
<td align="right">0.0143365</td>
<td align="right">1.164179</td>
<td align="right">0.0133392</td>
<td align="right">2.708651</td>
</tr>
<tr class="even">
<td align="left">880</td>
<td align="right">6.853299</td>
<td align="right">18.8</td>
<td align="right">353.44</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="left">8</td>
<td align="right">4.948457</td>
<td align="right">1.904842</td>
<td align="right">0.0306928</td>
<td align="right">1.166638</td>
<td align="right">0.0108686</td>
<td align="right">1.657084</td>
</tr>
<tr class="odd">
<td align="left">1078</td>
<td align="right">8.214465</td>
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">1</td>
<td align="right">4.599325</td>
<td align="right">3.615140</td>
<td align="right">0.0083997</td>
<td align="right">1.162928</td>
<td align="right">0.0102372</td>
<td align="right">3.109376</td>
</tr>
<tr class="even">
<td align="left">1080</td>
<td align="right">3.850148</td>
<td align="right">11.4</td>
<td align="right">129.96</td>
<td align="right">6</td>
<td align="right">36</td>
<td align="left">2</td>
<td align="right">5.495597</td>
<td align="right">-1.645449</td>
<td align="right">0.0354268</td>
<td align="right">1.167005</td>
<td align="right">0.0094531</td>
<td align="right">-1.434938</td>
</tr>
</tbody>
</table>
<p><strong>Réponse:</strong> Il y a peu d’observations influentes et on voit difficilement un profil type en termes de parité, production, race (beaucoup de Holstein, mais c’est aussi la race la plus fréquente dans le jeu de données) ou de CCS.</p>
<ol start="11" style="list-style-type: decimal">
<li>Présentation des résultats.<br />
11.1. Présentez les résultats de votre modèle dans une table que vous pourriez soumettre dans une publication scientifique.</li>
</ol>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="régression-linéaire.html#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Le package jtools et la fonction summ permettent de générer des tables de résultats un peu plus attrayantes que la fonction summary</span></span>
<span id="cb144-2"><a href="régression-linéaire.html#cb144-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jtools)</span>
<span id="cb144-3"><a href="régression-linéaire.html#cb144-3" aria-hidden="true" tabindex="-1"></a>j <span class="ot">&lt;-</span> <span class="fu">summ</span>(model_final2, <span class="at">confint =</span> <span class="cn">TRUE</span>) <span class="co">#Je créer un objet j qui contiendra différents éléments. Ici j&#39;ai demandé d&#39;utiliser les IC95 (plutôt que les erreur-types).</span></span>
<span id="cb144-4"><a href="régression-linéaire.html#cb144-4" aria-hidden="true" tabindex="-1"></a>j<span class="sc">$</span>coeftable <span class="co">#L&#39;élément de j qui se nomme coeftable contient les coefficients, les IC95 (ou les erreur-types), les valeurs de T, las valeurs de P.</span></span></code></pre></div>
<pre><code>##                     Est.          2.5%        97.5%     t val.             p
## (Intercept)   4.59932473  4.3893612016  4.809288257 42.9812943 4.033724e-237
## kgmilk_ct    -0.04728450 -0.0590979988 -0.035471011 -7.8536177  9.609453e-15
## kgmilk_ct_sq  0.00148937  0.0003835792  0.002595162  2.6427669  8.340726e-03
## parity_ct     0.55130050  0.4259755597  0.676625440  8.6313784  2.110234e-17
## parity_ct_sq -0.05950089 -0.0860565013 -0.032945281 -4.3963925  1.207990e-05
## breed2        0.07598558 -0.1379004787  0.289871635  0.6970725  4.859056e-01
## breed3       -0.60044404 -0.8556607831 -0.345227288 -4.6162853  4.369817e-06
## breed8       -0.15291913 -0.3897495271  0.083911261 -1.2669331  2.054491e-01</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="régression-linéaire.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Dans RMarkdown, pour une sortie plus &#39;propre&#39;, je peux créer une table avec la fonction kable du package knitr. </span></span>
<span id="cb146-2"><a href="régression-linéaire.html#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb146-3"><a href="régression-linéaire.html#cb146-3" aria-hidden="true" tabindex="-1"></a>Pres_table <span class="ot">&lt;-</span> <span class="fu">kable</span>(j<span class="sc">$</span>coeftable,  <span class="at">caption=</span><span class="st">&quot;Table 1. Modèle de régression linéaire multiple sur l’effet de la production laitière journalière (en kg) sur le log du comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) basé sur l’étude de 1128 vaches.&quot;</span>, <span class="co">#Je peux spécifier un titre de table. </span></span>
<span id="cb146-4"><a href="régression-linéaire.html#cb146-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">digits=</span><span class="dv">3</span>, <span class="co">#J&#39;ai aussi indiqué le nombre de décimales que je veux présenter.</span></span>
<span id="cb146-5"><a href="régression-linéaire.html#cb146-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;Estimés&#39;</span>, <span class="st">&#39;IC 95 inférieure&#39;</span>, <span class="st">&#39;IC95 supérieure&#39;</span>, <span class="st">&#39;Statistique de T&#39;</span>,<span class="st">&#39;Valeur de P&#39;</span>)) <span class="co">#Je peux renommer les titre des colonnes</span></span>
<span id="cb146-6"><a href="régression-linéaire.html#cb146-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Le package KableExtra permet d&#39;ajouter des &#39;footnotes&#39; à la table que je viens de créer</span></span>
<span id="cb146-7"><a href="régression-linéaire.html#cb146-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb146-8"><a href="régression-linéaire.html#cb146-8" aria-hidden="true" tabindex="-1"></a><span class="fu">add_footnote</span>(</span>
<span id="cb146-9"><a href="régression-linéaire.html#cb146-9" aria-hidden="true" tabindex="-1"></a>  Pres_table, <span class="st">&quot;L&#39;intercept représente le log du CCS (en 1000 cellules/ml) pour une vache Ayrshire de 1ère lactation et produisant 20kg de lait. Les variables Parity et Breed sont incluses dans le modèle comme facteurs confondants. La race Ayrshire est utilisée comme valeur de référence pour la variable Breed; breed2=Holstein, breed3=Jersey et breed8=autre race.&quot;</span>,</span>
<span id="cb146-10"><a href="régression-linéaire.html#cb146-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">notation =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-178">Table 6.10: </span>Table 1. Modèle de régression linéaire multiple sur l’effet de la production laitière journalière (en kg) sur le log du comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) basé sur l’étude de 1128 vaches.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Estimés</th>
<th align="right">IC 95 inférieure</th>
<th align="right">IC95 supérieure</th>
<th align="right">Statistique de T</th>
<th align="right">Valeur de P</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">4.599</td>
<td align="right">4.389</td>
<td align="right">4.809</td>
<td align="right">42.981</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">kgmilk_ct</td>
<td align="right">-0.047</td>
<td align="right">-0.059</td>
<td align="right">-0.035</td>
<td align="right">-7.854</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">kgmilk_ct_sq</td>
<td align="right">0.001</td>
<td align="right">0.000</td>
<td align="right">0.003</td>
<td align="right">2.643</td>
<td align="right">0.008</td>
</tr>
<tr class="even">
<td align="left">parity_ct</td>
<td align="right">0.551</td>
<td align="right">0.426</td>
<td align="right">0.677</td>
<td align="right">8.631</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">parity_ct_sq</td>
<td align="right">-0.060</td>
<td align="right">-0.086</td>
<td align="right">-0.033</td>
<td align="right">-4.396</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">breed2</td>
<td align="right">0.076</td>
<td align="right">-0.138</td>
<td align="right">0.290</td>
<td align="right">0.697</td>
<td align="right">0.486</td>
</tr>
<tr class="odd">
<td align="left">breed3</td>
<td align="right">-0.600</td>
<td align="right">-0.856</td>
<td align="right">-0.345</td>
<td align="right">-4.616</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">breed8</td>
<td align="right">-0.153</td>
<td align="right">-0.390</td>
<td align="right">0.084</td>
<td align="right">-1.267</td>
<td align="right">0.205</td>
</tr>
</tbody>
</table>
<p><strong>Note:</strong>
^^ L’intercept représente le log du CCS (en 1000 cellules/ml) pour une vache Ayrshire de 1ère lactation et produisant 20kg de lait. Les variables Parity et Breed sont incluses dans le modèle comme facteurs confondants. La race Ayrshire est utilisée comme valeur de référence pour la variable Breed; breed2=Holstein, breed3=Jersey et breed8=autre race.</p>
<p>L’effet de la production laitière n’est plus sur l’échelle originale. En plus, la relation entre production et CCS n’est pas linéaire. Tout ça rend votre modèle difficile à interpréter et il faudrait possiblement trouver une manière de rendre l’information plus digestible pour vos lecteurs.</p>
<p>11.2. Vous pourriez présenter comment le CCS varie en fonction de la production laitière pour différents scénarios. Vous pourriez, par exemple, compléter la table suivante, en calculant la valeur prédite pour chaque scénario à l’aide de votre modèle, puis en retransformant ces valeurs sur l’échelle originale:</p>
<table>
<caption>
<span id="tab:unnamed-chunk-181">Table 6.11: </span>Table 2. Valeurs prédites de comptage des cellules somatiques (CCS) du lait (x1000 cell./ml) d’une vache Ayrshire pour différentes combinaisons de production et parité.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Production
</th>
<th style="text-align:center;">
1ère lactation
</th>
<th style="text-align:center;">
2ième lactation
</th>
<th style="text-align:center;">
3ième et plus
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
10kg/jour
</td>
<td style="text-align:center;">
72
</td>
<td style="text-align:center;">
118
</td>
<td style="text-align:center;">
171
</td>
</tr>
<tr>
<td style="text-align:left;">
20kg/jour
</td>
<td style="text-align:center;">
70
</td>
<td style="text-align:center;">
115
</td>
<td style="text-align:center;">
166
</td>
</tr>
<tr>
<td style="text-align:left;">
30kg/jour
</td>
<td style="text-align:center;">
92
</td>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
218
</td>
</tr>
</tbody>
</table>
<p>11.3. Encore mieux : à partir d’une table <code>R</code> contenant les valeurs prédites, retransformez la valeur prédite sur l’échelle originale en créant une nouvelle variable <span class="math inline">\(CCS=exp(valeur prédite)\)</span>. Ensuite, vous pourrez utiliser le package <code>ggplot2</code> pour représenter dans un graphique nuage de points la relation entre la production laitière (en x) et la valeur prédite de CCS (en y).<br />
C’est plus simple à comprendre ainsi n’est-ce pas?</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="régression-linéaire.html#cb147-1" aria-hidden="true" tabindex="-1"></a>diag<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">exp</span>(diag<span class="sc">$</span>.fitted) <span class="co">#Je créer une variable de CCS sur l&#39;échalle originale</span></span>
<span id="cb147-2"><a href="régression-linéaire.html#cb147-2" aria-hidden="true" tabindex="-1"></a>diag<span class="sc">$</span>kgmilk <span class="ot">&lt;-</span> diag<span class="sc">$</span>kgmilk_ct<span class="sc">+</span><span class="dv">20</span> <span class="co">#Je dois aussi recréer ma variable kgmilk</span></span>
<span id="cb147-3"><a href="régression-linéaire.html#cb147-3" aria-hidden="true" tabindex="-1"></a>diag<span class="sc">$</span>parity <span class="ot">&lt;-</span> <span class="fu">factor</span>(diag<span class="sc">$</span>parity_ct<span class="sc">+</span><span class="dv">1</span>) <span class="co">#Je dois aussi recréer ma variable parité</span></span>
<span id="cb147-4"><a href="régression-linéaire.html#cb147-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb147-5"><a href="régression-linéaire.html#cb147-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diag, <span class="fu">aes</span>(<span class="at">x=</span>kgmilk, <span class="at">y=</span>pred)) <span class="sc">+</span></span>
<span id="cb147-6"><a href="régression-linéaire.html#cb147-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">colour=</span>parity)) <span class="sc">+</span>  </span>
<span id="cb147-7"><a href="régression-linéaire.html#cb147-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;loess&quot;</span>, <span class="at">span=</span><span class="dv">2</span>)<span class="sc">+</span> </span>
<span id="cb147-8"><a href="régression-linéaire.html#cb147-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Production (en kg/j)&quot;</span>, <span class="at">y=</span><span class="st">&quot;CCS (en 1000 cellules/ml)&quot;</span>)<span class="sc">+</span> </span>
<span id="cb147-9"><a href="régression-linéaire.html#cb147-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-182"></span>
<img src="Labo-R-Bookdown-project_files/figure-html/unnamed-chunk-182-1.png" alt="FIGURE 1. Valeurs de CCS (par 1000 cell./ml) prédites par le modèle en fonction de la production laitière (en kg/j) et du nombre de lactation." width="672" />
<p class="caption">
Figure 6.10: FIGURE 1. Valeurs de CCS (par 1000 cell./ml) prédites par le modèle en fonction de la production laitière (en kg/j) et du nombre de lactation.
</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="r-markdown.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="régression-logistique.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Labo R Bookdown project.pdf", "Labo R Bookdown project.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
