---
title: "Épidémiologie 2 - Labo informatique R (PTM-6675)"
author: "Simon Dufour (Professeur à la Faculté de Médecine vétérinaire de l'Université de Montréal)"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: Chapitre 12
 
---


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```


## Travaux pratiques 5 - Régression logistique - Évaluation du modèle

### Exercices
Pour ce TP utilisez le fichier Nocardia (voir description VER p.823).   
  
Utilisez le modèle suivant: $logit(Pcasecont=1) = β_0 + β_1*dneo + β_2*dclox + β_3*dneo*dclox + β_4*dcpct$
  
1. Lorsqu’une interaction est présente, il devient difficile de présenter clairement vos résultats. À l’aide de la fonction `pairs` du package `emmeans` vous seriez cependant capable de créer une table comme proposée dans Knol et VanderWeele (2012) [^5]. Une autre manière consisterait à Présenter l’effet de vos prédicteurs graphiquement sur une échelle de probabilité. Présentez ce graphique. Quel groupe de troupeaux se démarque particulièrement des autres en terme de probabilité de nocardiose?
  
[^5]: [Recommendations for presenting analyses of effect modification and interaction. M. J. Knol and T. J. VanderWeele, Int J Epidemiol 2012 Vol. 41 Issue 2 Pages 514-20](https://pubmed.ncbi.nlm.nih.gov/22253321/)    
  
2. Évaluez l’adéquation du modèle. Quels sont les résultats et votre interprétation du test de Hosmer-Lemeshow et du test de Pearson?  
  
3. Dans ce cas, notez-vous un problème de sur-dispersion ou de sous-dispersion des données ? Cela-signifie que la variance observée est plus grande ou plus petite que la variance attendue?  
  
4. La valeur prédictive d’un modèle peut également être évaluée à l’aide d’une courbe ROC. Représenter graphiquement la courbe ROC. Quel est l’aire sous la courbe pour votre modèle ? Quelle serait la sensibilité et la spécificité de votre modèle si on fixe un seuil de 50% (i.e. si modèle prédit probabilité de nocardiose > 50% alors on diagnostique le troupeau comme nocardia positif)? 
  
5. Quel est le profil d’observation avec le résiduel de Pearson le plus élevé? Combien y-a-t’il d’observations dans ce profil?
  
6. Quel profil d’observation avait le plus d’influence sur le coefficient de régression de *dcpct*? Pourquoi à votre opinion?
   

### Code R et réponses
Pour ce TP utilisez le fichier Nocardia (voir description VER p.823).   
```{r}
#J'importe ce jeu de données
nocardia <-read.csv(file="nocardia.csv", header=TRUE, sep=";")
head(nocardia)
#J'indique les variables catégoriques dans mon jeu de données
nocardia$dbarn <- factor(nocardia$dbarn) 
nocardia$dneo <- factor(nocardia$dneo) 
nocardia$dclox <- factor(nocardia$dclox) 
nocardia$casecont <- factor(nocardia$casecont) 
```
  
Utilisez le modèle suivant: $logit(Pcasecont=1) = β_0 + β_1*dneo + β_2*dclox + β_3*dneo*dclox + β_4*dcpct$
```{r}
modele <- glm(data = nocardia, casecont ~ dneo*dclox + dcpct, family = binomial)
summary(modele)
```

  
1. Lorsqu’une interaction est présente, il devient difficile de présenter clairement vos résultats. À l’aide de la fonction `pairs` du package `emmeans` vous seriez cependant capable de créer une table comme proposée dans Knol et VanderWeele (2012) [^5]. Une autre manière consisterait à Présenter l’effet de vos prédicteurs graphiquement sur une échelle de probabilité. Présentez ce graphique. Quel groupe de troupeaux se démarque particulièrement des autres en terme de probabilité de nocardiose?
  
```{r, fig.cap="**Figure x.** Effet sur la probabilité de nocardia de l'utilisation de la neomycine et du % de vache traitées au tarissement par niveau d'utilisation de la cloxacilline."}
library(sjPlot)
plot_model(modele, type="eff", terms=c("dcpct", "dneo", "dclox"))
```
  
**Réponse:** Les troupeaux utilisant seulement la néomycine (sans cloxacilline) semblent avoir une probabilité beaucoup
plus élevée de nocardiose.  
  
2. Évaluez l’adéquation du modèle. Quels sont les résultats et votre interprétation du test de Hosmer-Lemeshow et du test de Pearson?  
  
**Réponse:**    
**Test de Homer-Lemeshow**
```{r, message=FALSE, warning=FALSE}
library(ResourceSelection)
hoslem.test(modele$y, fitted(modele), g=8)

```
  
Interprétation: Le modèle est adéquat.  
  
**Test de Pearson**
```{r, message=FALSE, warning=FALSE}
library(broom)
diag <- augment(modele, type.residuals = "pearson") #Je viens de créer une nouvelle table avec les résiduels, etc. 

library(dplyr)
#La fonction "distinct" me permet de ne conserver qu'une seule fois (i.e., une seule ligne) les valeurs prédites qui se répètent.   
profils <- distinct(diag, dcpct, dneo, dclox, .keep_all = TRUE)

#Dans ce cas, on voit avec la fonction "dim" qu'il y a 30 profils uniques.
n_prof <- dim(profils)
n_prof[1]

#Je calcule la somme de ces résiduels au carré. Dans ce cas, j'obtiens 37.75
s <- sum(profils$.std.resid^2)
s

#Je calcule le nombre de coefficients avec la fonction length
nb <- length(modele$coefficients)-1
nb

#Finalement, je vérifie à quelle probabilité la valeur 37.75 correspond dans une distribution de chi-carré avec 25 degrés de liberté (30 profils - 5 coefficients).
1-pchisq(s, (n_prof-nb-1))

```
Interprétation: Le modèle n'est pas adéquat.  
  
Avec seulement 108 observations pour 30 profils différents, il n’y a pas beaucoup
d’observations par profil. Le test d’Hosmer-Lemeshow est donc probablement préférable.
  
3. Dans ce cas, notez-vous un problème de sur-dispersion ou de sous-dispersion des données ? Cela-signifie que la variance observée est plus grande ou plus petite que la variance attendue?  
```{r}
dl <- n_prof-nb
disp <- s/dl
```
```{r, echo=FALSE}
s <- round(s, digits=2)
disp <- round(disp[1], digits=2)
disp
```
  
**Réponse: ** La somme des résiduels de Pearson (37.75) divisée par ses degrés de liberté (25) est > 1.0 et même que 1.2 (i.e. 37.75/25 = 1.51). Il y a donc sur-dispersion; la variance observée est plus grande que la variance attendue. Notez, cependant, que cela ne semble pas affecter l’adéquation du modèle (voir réponse précédente).  
  
4. La valeur prédictive d’un modèle peut également être évaluée à l’aide d’une courbe ROC. Représenter graphiquement la courbe ROC. Quel est l’aire sous la courbe pour votre modèle ? Quelle serait la sensibilité et la spécificité de votre modèle si on fixe un seuil de 50% (i.e. si modèle prédit probabilité de nocardiose > 50% alors on diagnostique le troupeau comme nocardia positif)? 
  
```{r, fig.cap="**Figure x.** Courbe ROC.", message=FALSE, warning=FALSE}
library(broom)
diag <- augment(modele) #Je viens de créer une nouvelle table dans laquelle les résiduels, distance de cook, etc se trouvent maintenant

#Je vais ajouter les valeurs prédites de mon objet modele
diag$pred_prob <- modele$fitted.values

#Je génère l'objet ROC.
library(pROC)
roc_data <- roc(data=diag, response="casecont", predictor="pred_prob")

#Je génère la courbe ROC
plot.roc(roc_data, print.auc = TRUE, grid = TRUE)
```
  
**Réponse:** L’aire sous la courbe est 0.850. Avec un graphique interactif, ce sera facile de trouver les Se et Sp pour différent seuils. 
  
```{r, fig.cap="**Figure x.** Sensibilité et spécificité en fonction du seuil choisi.", message=FALSE, warning=FALSE}
library(plotly)
x_axis <- list(title = "Seuil de probabilité choisi")
y_axis <- list(title = "Précision")
plot_ly(
  x=round((1-roc_data$thresholds), digits=2),
  y=round(roc_data$sensitivities, digits=2),
  type="scatter",
  mode="line",
  name="Sensibilité"
) %>%
  add_trace(
    x=round((1-roc_data$thresholds), digits=2),
     y=round(roc_data$specificities, digits=2),
    name="Spécificité"
    )%>%
  
  layout(
    title="Précision du modèle",
    xaxis=x_axis,
    yaxis=y_axis
        )

```
   
**Réponse:** Essayez l'onglet "Compare data on hover". En se déplacant sur la figure on note des Se et Sp de 0.76 et 0.83, respectivement lorsqu'on fixe le seuil de probabilité à >0.50.
  
5. Quel est le profil d’observations avec le résiduel de Pearson le plus élevé? Combien y-a-t’il d’observations dans ce profil?
```{r}
#Je pourrais maintenant ordonner cette table pour voir les 10 observations avec les résiduels les plus larges
diag_maxres <- diag[order(-diag$.resid),]
head(diag_maxres, 10)
```
  
**Réponse:** Le modèle prédit une probabilité de moins de 3% de nocardiose dans un troupeau qui n’utilise ni neomycine, ni cloxacilline et ou 10% des vaches sont traitées au tarissement. Il y a une seule observation dans ce profil et il s’agit d’un troupeau positif à nocardia (d’où le résiduel très large).  
  
6. Quel profil d’observations avait le plus d’influence sur le coefficient de régression de *dcpct*? Pourquoi à votre opinion?  
  
```{r}
#Je pourrais maintenant ordonner cette table pour voir les 10 observations avec les leviers les plus larges
diag_cook <- diag[order(-diag$.cooksd),]
head(diag_cook, 10)
```
  
**Réponse:** C'est le même profil identifié à la question 5. En général, une augmentation de dcpct résulte en une augmentation de la probabilité de nocardia, mais cette observation à un dcpct bas (10% ; le 15ième plus bas du jeu de donnée), mais le troupeau était tout de même un troupeau cas. Ce profil tire donc la droite de régression vers lui (et modifie donc le coefficient de régression).
  
